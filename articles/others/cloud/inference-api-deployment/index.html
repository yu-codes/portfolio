<!doctype html><html lang=en class=html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>推論 API 佈署策略：Blue-Green、Canary、KServe、Triton、EKS+Spot - Yu's Portfolio & Learning Hub</title><meta name=description content='現代 AI 推論服務需兼顧高可用、低延遲與彈性擴縮。從 Blue-Green/Canary/Shadow 部署策略，到 KServe、Triton、TensorRT-LLM 等推論框架，再到 EKS+Spot 的 DaemonSet Drain、PriorityClass、Checkpoint 恢復設計，本章將結合理論、實戰、面試熱點與常見誤區，幫助你打造高效穩健的推論 API 平台。
Blue-Green / Canary / Shadow 部署 Blue-Green 部署 維護兩套環境（藍/綠），流量切換，快速回滾 適合大規模升級、零停機部署 Canary 部署 新版本先導入部分流量，逐步擴大 監控指標，異常自動回滾 Shadow 部署 新模型僅接收流量，不回應用戶，觀察行為差異 適合新模型驗證、風險控制 KServe / Triton / TensorRT-LLM KServe K8s 原生推論框架，支援多模型、多框架（PyTorch、TF、SKLearn、XGBoost） 支援自動擴縮、A/B/Canary、GPU 調度、ModelMesh Triton Inference Server NVIDIA 高效推論框架，支援多模型、動態批次、TensorRT 加速 適合 GPU/多模型高吞吐應用 TensorRT-LLM 專為大語言模型（LLM）優化的推論框架 支援分布式推理、低延遲、FP8/INT8 加速 EKS + Spot：DaemonSet Drain、PriorityClass、Checkpoint 恢復 EKS + Spot 策略 利用 Spot 節點降低成本，需設計容錯與自動恢復 DaemonSet Drain：Spot 回收時自動驅逐 DaemonSet，釋放資源 PriorityClass：關鍵 Pod 設高優先權，保證資源分配 Checkpoint 恢復：推論狀態/快取定期保存，Spot 中斷自動恢復 apiVersion: scheduling.k8s.io/v1 kind: PriorityClass metadata: name: inference-critical value: 1000000 globalDefault: false description: "Critical inference pods" 設計實戰與最佳實踐 推論服務建議用 KServe/Triton，結合 GPU 調度與自動擴縮 部署建議用 Blue-Green/Canary，結合監控與自動回滾 EKS+Spot 建議設 PriorityClass、Checkpoint、自動恢復 Shadow 部署適合新模型驗證，避免直接影響用戶 理論直覺、應用場景與常見誤區 應用場景 LLM 推論、推薦系統、即時 API、金融/醫療 AI 服務 常見誤區 Canary 部署未設監控，異常未及時回滾 Spot 節點未設 PriorityClass，關鍵服務被搶佔 Checkpoint 未設計，Spot 中斷資料遺失 Shadow 部署未隔離資源，影響線上服務 面試熱點與經典問題 主題 常見問題 Blue-Green/Canary 部署策略與選型？ KServe/Triton 功能與差異？ EKS+Spot 容錯與恢復設計？ PriorityClass 如何設計與應用？ Checkpoint 推論狀態保存與恢復？ 使用注意事項 推論服務建議設監控、告警與自動回滾 Spot 策略需設 PriorityClass 與自動恢復 Shadow 部署建議隔離資源與流量 延伸閱讀與資源 KServe 官方文件 Triton Inference Server TensorRT-LLM EKS Spot 策略 K8s PriorityClass 經典面試題與解法提示 Blue-Green/Canary/Shadow 部署差異？ KServe/Triton/TensorRT-LLM 選型？ EKS+Spot 容錯與恢復設計？ PriorityClass 實作細節？ Checkpoint 恢復策略？ 推論服務自動擴縮與監控？ Shadow 部署資源隔離？ 多模型推論與 GPU 調度？ Canary 部署監控與回滾？ 推論 API 佈署常見踩坑？ 結語 推論 API 佈署策略是 AI 服務穩健運營的關鍵。熟悉 Blue-Green/Canary、KServe、Triton、EKS+Spot 策略，能讓你打造高效可用的推論平台。下一章將進入 Auto-Scaling 與成本最佳化，敬請期待！
'><meta property="og:title" content="推論 API 佈署策略：Blue-Green、Canary、KServe、Triton、EKS+Spot"><meta property="og:description" content='現代 AI 推論服務需兼顧高可用、低延遲與彈性擴縮。從 Blue-Green/Canary/Shadow 部署策略，到 KServe、Triton、TensorRT-LLM 等推論框架，再到 EKS+Spot 的 DaemonSet Drain、PriorityClass、Checkpoint 恢復設計，本章將結合理論、實戰、面試熱點與常見誤區，幫助你打造高效穩健的推論 API 平台。
Blue-Green / Canary / Shadow 部署 Blue-Green 部署 維護兩套環境（藍/綠），流量切換，快速回滾 適合大規模升級、零停機部署 Canary 部署 新版本先導入部分流量，逐步擴大 監控指標，異常自動回滾 Shadow 部署 新模型僅接收流量，不回應用戶，觀察行為差異 適合新模型驗證、風險控制 KServe / Triton / TensorRT-LLM KServe K8s 原生推論框架，支援多模型、多框架（PyTorch、TF、SKLearn、XGBoost） 支援自動擴縮、A/B/Canary、GPU 調度、ModelMesh Triton Inference Server NVIDIA 高效推論框架，支援多模型、動態批次、TensorRT 加速 適合 GPU/多模型高吞吐應用 TensorRT-LLM 專為大語言模型（LLM）優化的推論框架 支援分布式推理、低延遲、FP8/INT8 加速 EKS + Spot：DaemonSet Drain、PriorityClass、Checkpoint 恢復 EKS + Spot 策略 利用 Spot 節點降低成本，需設計容錯與自動恢復 DaemonSet Drain：Spot 回收時自動驅逐 DaemonSet，釋放資源 PriorityClass：關鍵 Pod 設高優先權，保證資源分配 Checkpoint 恢復：推論狀態/快取定期保存，Spot 中斷自動恢復 apiVersion: scheduling.k8s.io/v1 kind: PriorityClass metadata: name: inference-critical value: 1000000 globalDefault: false description: "Critical inference pods" 設計實戰與最佳實踐 推論服務建議用 KServe/Triton，結合 GPU 調度與自動擴縮 部署建議用 Blue-Green/Canary，結合監控與自動回滾 EKS+Spot 建議設 PriorityClass、Checkpoint、自動恢復 Shadow 部署適合新模型驗證，避免直接影響用戶 理論直覺、應用場景與常見誤區 應用場景 LLM 推論、推薦系統、即時 API、金融/醫療 AI 服務 常見誤區 Canary 部署未設監控，異常未及時回滾 Spot 節點未設 PriorityClass，關鍵服務被搶佔 Checkpoint 未設計，Spot 中斷資料遺失 Shadow 部署未隔離資源，影響線上服務 面試熱點與經典問題 主題 常見問題 Blue-Green/Canary 部署策略與選型？ KServe/Triton 功能與差異？ EKS+Spot 容錯與恢復設計？ PriorityClass 如何設計與應用？ Checkpoint 推論狀態保存與恢復？ 使用注意事項 推論服務建議設監控、告警與自動回滾 Spot 策略需設 PriorityClass 與自動恢復 Shadow 部署建議隔離資源與流量 延伸閱讀與資源 KServe 官方文件 Triton Inference Server TensorRT-LLM EKS Spot 策略 K8s PriorityClass 經典面試題與解法提示 Blue-Green/Canary/Shadow 部署差異？ KServe/Triton/TensorRT-LLM 選型？ EKS+Spot 容錯與恢復設計？ PriorityClass 實作細節？ Checkpoint 恢復策略？ 推論服務自動擴縮與監控？ Shadow 部署資源隔離？ 多模型推論與 GPU 調度？ Canary 部署監控與回滾？ 推論 API 佈署常見踩坑？ 結語 推論 API 佈署策略是 AI 服務穩健運營的關鍵。熟悉 Blue-Green/Canary、KServe、Triton、EKS+Spot 策略，能讓你打造高效可用的推論平台。下一章將進入 Auto-Scaling 與成本最佳化，敬請期待！
'><meta property="og:url" content="https://yu-codes.github.io/portfolio/articles/others/cloud/inference-api-deployment/"><link rel=canonical href=https://yu-codes.github.io/portfolio/articles/others/cloud/inference-api-deployment/><link rel=stylesheet href=https://yu-codes.github.io/portfolio/css/main.css></head><body class=body><div class=container><aside class=sidebar><div class=sidebar-header><h1 class=name>Yu</h1><p class=tagline>Developer, dreamer, debugger.</p></div><nav class=sidebar-nav><a href=https://yu-codes.github.io/portfolio/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M3 9l9-7 9 7v11a2 2 0 01-2 2H5a2 2 0 01-2-2z"/><polyline points="9 22 9 12 15 12 15 22"/></svg>
<span>HOME</span>
</a><a href=https://yu-codes.github.io/portfolio/articles/ class="nav-item active"><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5.0 016.5 17H20"/><path d="M6.5 2H20v20H6.5A2.5 2.5.0 014 19.5v-15A2.5 2.5.0 016.5 2z"/></svg>
<span>ARTICLES</span>
</a><a href=https://yu-codes.github.io/portfolio/resume/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="12" y1="11" x2="12" y2="17"/><line x1="9" y1="14" x2="15" y2="14"/></svg>
<span>RESUME</span>
</a><a href=https://yu-codes.github.io/portfolio/projects/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="3" width="8" height="8"/><rect x="13" y="3" width="8" height="8"/><rect x="3" y="13" width="8" height="8"/><rect x="13" y="13" width="8" height="8"/></svg>
<span>PROJECTS</span>
</a><a href=https://yu-codes.github.io/portfolio/archives/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
<span>ARCHIVES</span></a></nav><div class=sidebar-footer><div class=controls><button class="control-btn theme-toggle" title="Toggle theme (light/dark)" aria-label="Toggle theme">
<svg class="icon-sun" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".25"/></svg>
<svg class="icon-moon" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".25"/></svg>
</button>
<button class="control-btn lang-toggle" title="Toggle language" aria-label="Toggle language">
<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"/><path d="M2 12h20"/><path d="M12 2a15.3 15.3.0 014 10 15.3 15.3.0 01-4 10A15.3 15.3.0 018 12a15.3 15.3.0 014-10z"/></svg></button></div><div class=social-links><a href=https://github.com/yu-codes target=_blank rel="noopener noreferrer" class=social-link title=GitHub><svg viewBox="0 0 24 24" fill="currentColor"><path d="M12 0C5.374.0.0 5.373.0 12c0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931.0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176.0.0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221.0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/></svg>
</a><a href=mailto:dylan.jhou1120@gmail.com class=social-link title=Email><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div></div></aside><div class=main-content><div class=topbar><div class=breadcrumb><a href=https://yu-codes.github.io/portfolio/>HOME</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/articles/>ARTICLES</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/articles/others/>Others</a><span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/articles/others/cloud/>Cloud</a><span class=separator>&#8250;</span>
<span>推論 API 佈署策略：Blue-Green、Canary、KServe、Triton、EKS+Spot</span></div></div><main class=content-area><article class=article-content><header class=article-header><h1>推論 API 佈署策略：Blue-Green、Canary、KServe、Triton、EKS+Spot</h1><div class=article-meta><span class=article-author><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20 21v-2a4 4 0 00-4-4H8a4 4 0 00-4 4v2"/><circle cx="12" cy="7" r="4"/></svg>
Yu-Han Jhou
</span><span class=article-updated><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>
Last updated: 2025-06-16</span></div></header><div class=article-body><p>現代 AI 推論服務需兼顧高可用、低延遲與彈性擴縮。從 Blue-Green/Canary/Shadow 部署策略，到 KServe、Triton、TensorRT-LLM 等推論框架，再到 EKS+Spot 的 DaemonSet Drain、PriorityClass、Checkpoint 恢復設計，本章將結合理論、實戰、面試熱點與常見誤區，幫助你打造高效穩健的推論 API 平台。</p><hr><nav class=article-toc><span class=toc-title>Table of Contents</span><nav id=TableOfContents><ul><li><a href=#blue-green--canary--shadow-部署>Blue-Green / Canary / Shadow 部署</a><ul><li><a href=#blue-green-部署>Blue-Green 部署</a></li><li><a href=#canary-部署>Canary 部署</a></li><li><a href=#shadow-部署>Shadow 部署</a></li></ul></li><li><a href=#kserve--triton--tensorrt-llm>KServe / Triton / TensorRT-LLM</a><ul><li><a href=#kserve>KServe</a></li><li><a href=#triton-inference-server>Triton Inference Server</a></li><li><a href=#tensorrt-llm>TensorRT-LLM</a></li></ul></li><li><a href=#eks--spotdaemonset-drainpriorityclasscheckpoint-恢復>EKS + Spot：DaemonSet Drain、PriorityClass、Checkpoint 恢復</a><ul><li><a href=#eks--spot-策略>EKS + Spot 策略</a></li></ul></li><li><a href=#設計實戰與最佳實踐>設計實戰與最佳實踐</a></li><li><a href=#理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</a><ul><li><a href=#應用場景>應用場景</a></li><li><a href=#常見誤區>常見誤區</a></li></ul></li><li><a href=#面試熱點與經典問題>面試熱點與經典問題</a></li><li><a href=#使用注意事項>使用注意事項</a></li><li><a href=#延伸閱讀與資源>延伸閱讀與資源</a></li><li><a href=#經典面試題與解法提示>經典面試題與解法提示</a></li><li><a href=#結語>結語</a></li></ul></nav></nav><h2 id=blue-green--canary--shadow-部署>Blue-Green / Canary / Shadow 部署</h2><h3 id=blue-green-部署>Blue-Green 部署</h3><ul><li>維護兩套環境（藍/綠），流量切換，快速回滾</li><li>適合大規模升級、零停機部署</li></ul><h3 id=canary-部署>Canary 部署</h3><ul><li>新版本先導入部分流量，逐步擴大</li><li>監控指標，異常自動回滾</li></ul><h3 id=shadow-部署>Shadow 部署</h3><ul><li>新模型僅接收流量，不回應用戶，觀察行為差異</li><li>適合新模型驗證、風險控制</li></ul><hr><h2 id=kserve--triton--tensorrt-llm>KServe / Triton / TensorRT-LLM</h2><h3 id=kserve>KServe</h3><ul><li>K8s 原生推論框架，支援多模型、多框架（PyTorch、TF、SKLearn、XGBoost）</li><li>支援自動擴縮、A/B/Canary、GPU 調度、ModelMesh</li></ul><h3 id=triton-inference-server>Triton Inference Server</h3><ul><li>NVIDIA 高效推論框架，支援多模型、動態批次、TensorRT 加速</li><li>適合 GPU/多模型高吞吐應用</li></ul><h3 id=tensorrt-llm>TensorRT-LLM</h3><ul><li>專為大語言模型（LLM）優化的推論框架</li><li>支援分布式推理、低延遲、FP8/INT8 加速</li></ul><hr><h2 id=eks--spotdaemonset-drainpriorityclasscheckpoint-恢復>EKS + Spot：DaemonSet Drain、PriorityClass、Checkpoint 恢復</h2><h3 id=eks--spot-策略>EKS + Spot 策略</h3><ul><li>利用 Spot 節點降低成本，需設計容錯與自動恢復</li><li>DaemonSet Drain：Spot 回收時自動驅逐 DaemonSet，釋放資源</li><li>PriorityClass：關鍵 Pod 設高優先權，保證資源分配</li><li>Checkpoint 恢復：推論狀態/快取定期保存，Spot 中斷自動恢復</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>scheduling.k8s.io/v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>PriorityClass</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>inference-critical</span>
</span></span><span style=display:flex><span><span style=color:#f92672>value</span>: <span style=color:#ae81ff>1000000</span>
</span></span><span style=display:flex><span><span style=color:#f92672>globalDefault</span>: <span style=color:#66d9ef>false</span>
</span></span><span style=display:flex><span><span style=color:#f92672>description</span>: <span style=color:#e6db74>&#34;Critical inference pods&#34;</span>
</span></span></code></pre></div><hr><h2 id=設計實戰與最佳實踐>設計實戰與最佳實踐</h2><ul><li>推論服務建議用 KServe/Triton，結合 GPU 調度與自動擴縮</li><li>部署建議用 Blue-Green/Canary，結合監控與自動回滾</li><li>EKS+Spot 建議設 PriorityClass、Checkpoint、自動恢復</li><li>Shadow 部署適合新模型驗證，避免直接影響用戶</li></ul><hr><h2 id=理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</h2><h3 id=應用場景>應用場景</h3><ul><li>LLM 推論、推薦系統、即時 API、金融/醫療 AI 服務</li></ul><h3 id=常見誤區>常見誤區</h3><ul><li>Canary 部署未設監控，異常未及時回滾</li><li>Spot 節點未設 PriorityClass，關鍵服務被搶佔</li><li>Checkpoint 未設計，Spot 中斷資料遺失</li><li>Shadow 部署未隔離資源，影響線上服務</li></ul><hr><h2 id=面試熱點與經典問題>面試熱點與經典問題</h2><table><thead><tr><th>主題</th><th>常見問題</th></tr></thead><tbody><tr><td>Blue-Green/Canary</td><td>部署策略與選型？</td></tr><tr><td>KServe/Triton</td><td>功能與差異？</td></tr><tr><td>EKS+Spot</td><td>容錯與恢復設計？</td></tr><tr><td>PriorityClass</td><td>如何設計與應用？</td></tr><tr><td>Checkpoint</td><td>推論狀態保存與恢復？</td></tr></tbody></table><hr><h2 id=使用注意事項>使用注意事項</h2><ul><li>推論服務建議設監控、告警與自動回滾</li><li>Spot 策略需設 PriorityClass 與自動恢復</li><li>Shadow 部署建議隔離資源與流量</li></ul><hr><h2 id=延伸閱讀與資源>延伸閱讀與資源</h2><ul><li><a href=https://kserve.github.io/website/>KServe 官方文件</a></li><li><a href=https://github.com/triton-inference-server/server>Triton Inference Server</a></li><li><a href=https://github.com/NVIDIA/TensorRT-LLM>TensorRT-LLM</a></li><li><a href=https://aws.amazon.com/tw/blogs/containers/eks-spot-capacity/>EKS Spot 策略</a></li><li><a href=https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/>K8s PriorityClass</a></li></ul><hr><h2 id=經典面試題與解法提示>經典面試題與解法提示</h2><ol><li>Blue-Green/Canary/Shadow 部署差異？</li><li>KServe/Triton/TensorRT-LLM 選型？</li><li>EKS+Spot 容錯與恢復設計？</li><li>PriorityClass 實作細節？</li><li>Checkpoint 恢復策略？</li><li>推論服務自動擴縮與監控？</li><li>Shadow 部署資源隔離？</li><li>多模型推論與 GPU 調度？</li><li>Canary 部署監控與回滾？</li><li>推論 API 佈署常見踩坑？</li></ol><hr><h2 id=結語>結語</h2><p>推論 API 佈署策略是 AI 服務穩健運營的關鍵。熟悉 Blue-Green/Canary、KServe、Triton、EKS+Spot 策略，能讓你打造高效可用的推論平台。下一章將進入 Auto-Scaling 與成本最佳化，敬請期待！</p></div><div class=article-tags><div class=tags><span class=tag>Blue-Green</span>
<span class=tag>Canary</span>
<span class=tag>Shadow</span>
<span class=tag>KServe</span>
<span class=tag>Triton</span>
<span class=tag>TensorRT-LLM</span>
<span class=tag>EKS</span>
<span class=tag>Spot</span>
<span class=tag>DaemonSet</span>
<span class=tag>PriorityClass</span>
<span class=tag>Checkpoint</span></div></div><footer class=article-footer><a href=/portfolio/articles/others/cloud/ class=back-link>← Back to Cloud</a></footer></article></main><footer class=site-footer><p>&copy; 2026 YuHan Jhou. All rights reserved.</p></footer></div></div><script src=https://yu-codes.github.io/portfolio/js/theme.js defer></script><script src=https://yu-codes.github.io/portfolio/js/roadmap.js defer></script><script src=https://yu-codes.github.io/portfolio/js/parallax.js defer></script><script src=https://yu-codes.github.io/portfolio/js/page-transition.js defer></script></body></html>