<!doctype html><html lang=en class=html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>GPU 叢集調度全攻略：NVIDIA Plugin、MIG、Slurm、Ray、GPU Sharing - Yu's Portfolio & Learning Hub</title><meta name=description content='現代 AI 訓練與推論高度依賴 GPU 叢集調度。從 Kubernetes NVIDIA Device Plugin、MIG、Node Affinity，到 Slurm、Ray、Kubeflow Training Operator、Multi-Instance GPU 與 GPU Sharing，本章將結合理論、功能比較、實戰設計、面試熱點與常見誤區，幫助你打造高效可擴展的 GPU 平台。
NVIDIA Device Plugin、MIG、Node Affinity NVIDIA Device Plugin K8s GPU 調度標配，支援自動發現與分配 GPU 支援 nvidia.com/gpu 資源限制，Pod 可指定卡數 監控 GPU 使用率，防止資源閒置 MIG（Multi-Instance GPU） 支援 A100/Hopper 等 GPU 一卡多用，分割為多個獨立實例 適合多租戶、推論混合訓練場景 K8s 支援 MIG Profile 調度，需設 Node Affinity Node Affinity 控制 Pod 部署到特定 GPU 型號/配置節點 適合異構 GPU 叢集、資源隔離 resources: limits: nvidia.com/gpu: 1 nodeSelector: gpu: "a100" Slurm, Ray, Kubeflow Training Operator Slurm HPC/AI 標準排程器，支援 GPU/CPU 任務、資源配額、佇列管理 適合超算中心、科研機構、混合雲 Ray 分散式運算框架，支援動態 GPU 資源分配、彈性調度 適合大規模分散式訓練、推論、RL Kubeflow Training Operator K8s 原生訓練排程，支援 PyTorchJob、TFJob、MPIJob 整合 GPU 調度、資源監控、彈性伸縮 Multi-Instance GPU 與 GPU Sharing Multi-Instance GPU（MIG）：一卡多用，提升 GPU 利用率 GPU Sharing：多 Pod/Job 共用單張 GPU（如 MIG、KubeShare、GPU Operator） 適合推論服務、低負載多租戶場景 建議監控 GPU 使用率與資源隔離 設計實戰與最佳實踐 大型訓練建議用 Slurm/Kubeflow，推論/混合場景用 Ray/MIG Node Affinity/Label 管理異構 GPU GPU Sharing 建議設資源配額與監控 定期審查 GPU 使用率，優化排程策略 理論直覺、應用場景與常見誤區 應用場景 大規模 AI 訓練、推論服務、科研 HPC、雲端 GPU 叢集 常見誤區 GPU 調度未設 affinity，Pod 排程失敗 MIG 配置錯誤，資源閒置或衝突 Slurm/Ray 未設資源配額，任務搶佔 GPU Sharing 權限設計不當，資料外洩風險 面試熱點與經典問題 主題 常見問題 NVIDIA Plugin/MIG 原理與應用場景？ Slurm vs Ray 差異與選型？ Kubeflow Training Operator 功能與優勢？ GPU Sharing 如何實現與監控？ Node Affinity 異構 GPU 管理？ 使用注意事項 GPU/MIG 配置建議自動化與監控 Slurm/Ray/Kubeflow 建議設資源配額 GPU Sharing 需設權限與隔離策略 延伸閱讀與資源 NVIDIA Device Plugin MIG 官方文件 Slurm 官方文件 Ray 官方文件 Kubeflow Training Operator 經典面試題與解法提示 NVIDIA Device Plugin/MIG 原理與應用？ Slurm/Ray/Kubeflow 差異與選型？ GPU Sharing/MIG 配置挑戰？ Node Affinity/Label 管理異構 GPU？ GPU 資源配額與監控？ 如何用 YAML 實作 MIG 調度？ Slurm/Ray 資源搶佔如何防範？ GPU Sharing 權限與隔離？ Kubeflow Training Operator 部署細節？ GPU 叢集調度常見踩坑？ 結語 GPU 叢集調度是 AI 訓練與推論平台的核心。熟悉 NVIDIA Plugin、MIG、Slurm、Ray、GPU Sharing，能讓你打造高效可擴展的 GPU 平台。下一章將進入推論 API 佈署策略，敬請期待！
'><meta property="og:title" content="GPU 叢集調度全攻略：NVIDIA Plugin、MIG、Slurm、Ray、GPU Sharing"><meta property="og:description" content='現代 AI 訓練與推論高度依賴 GPU 叢集調度。從 Kubernetes NVIDIA Device Plugin、MIG、Node Affinity，到 Slurm、Ray、Kubeflow Training Operator、Multi-Instance GPU 與 GPU Sharing，本章將結合理論、功能比較、實戰設計、面試熱點與常見誤區，幫助你打造高效可擴展的 GPU 平台。
NVIDIA Device Plugin、MIG、Node Affinity NVIDIA Device Plugin K8s GPU 調度標配，支援自動發現與分配 GPU 支援 nvidia.com/gpu 資源限制，Pod 可指定卡數 監控 GPU 使用率，防止資源閒置 MIG（Multi-Instance GPU） 支援 A100/Hopper 等 GPU 一卡多用，分割為多個獨立實例 適合多租戶、推論混合訓練場景 K8s 支援 MIG Profile 調度，需設 Node Affinity Node Affinity 控制 Pod 部署到特定 GPU 型號/配置節點 適合異構 GPU 叢集、資源隔離 resources: limits: nvidia.com/gpu: 1 nodeSelector: gpu: "a100" Slurm, Ray, Kubeflow Training Operator Slurm HPC/AI 標準排程器，支援 GPU/CPU 任務、資源配額、佇列管理 適合超算中心、科研機構、混合雲 Ray 分散式運算框架，支援動態 GPU 資源分配、彈性調度 適合大規模分散式訓練、推論、RL Kubeflow Training Operator K8s 原生訓練排程，支援 PyTorchJob、TFJob、MPIJob 整合 GPU 調度、資源監控、彈性伸縮 Multi-Instance GPU 與 GPU Sharing Multi-Instance GPU（MIG）：一卡多用，提升 GPU 利用率 GPU Sharing：多 Pod/Job 共用單張 GPU（如 MIG、KubeShare、GPU Operator） 適合推論服務、低負載多租戶場景 建議監控 GPU 使用率與資源隔離 設計實戰與最佳實踐 大型訓練建議用 Slurm/Kubeflow，推論/混合場景用 Ray/MIG Node Affinity/Label 管理異構 GPU GPU Sharing 建議設資源配額與監控 定期審查 GPU 使用率，優化排程策略 理論直覺、應用場景與常見誤區 應用場景 大規模 AI 訓練、推論服務、科研 HPC、雲端 GPU 叢集 常見誤區 GPU 調度未設 affinity，Pod 排程失敗 MIG 配置錯誤，資源閒置或衝突 Slurm/Ray 未設資源配額，任務搶佔 GPU Sharing 權限設計不當，資料外洩風險 面試熱點與經典問題 主題 常見問題 NVIDIA Plugin/MIG 原理與應用場景？ Slurm vs Ray 差異與選型？ Kubeflow Training Operator 功能與優勢？ GPU Sharing 如何實現與監控？ Node Affinity 異構 GPU 管理？ 使用注意事項 GPU/MIG 配置建議自動化與監控 Slurm/Ray/Kubeflow 建議設資源配額 GPU Sharing 需設權限與隔離策略 延伸閱讀與資源 NVIDIA Device Plugin MIG 官方文件 Slurm 官方文件 Ray 官方文件 Kubeflow Training Operator 經典面試題與解法提示 NVIDIA Device Plugin/MIG 原理與應用？ Slurm/Ray/Kubeflow 差異與選型？ GPU Sharing/MIG 配置挑戰？ Node Affinity/Label 管理異構 GPU？ GPU 資源配額與監控？ 如何用 YAML 實作 MIG 調度？ Slurm/Ray 資源搶佔如何防範？ GPU Sharing 權限與隔離？ Kubeflow Training Operator 部署細節？ GPU 叢集調度常見踩坑？ 結語 GPU 叢集調度是 AI 訓練與推論平台的核心。熟悉 NVIDIA Plugin、MIG、Slurm、Ray、GPU Sharing，能讓你打造高效可擴展的 GPU 平台。下一章將進入推論 API 佈署策略，敬請期待！
'><meta property="og:url" content="https://yu-codes.github.io/portfolio/articles/others/cloud/gpu-cluster-scheduling/"><link rel=canonical href=https://yu-codes.github.io/portfolio/articles/others/cloud/gpu-cluster-scheduling/><link rel=stylesheet href=https://yu-codes.github.io/portfolio/css/main.css></head><body class=body><div class=container><aside class=sidebar><div class=sidebar-header><h1 class=name>Yu</h1><p class=tagline>Developer, dreamer, debugger.</p></div><nav class=sidebar-nav><a href=https://yu-codes.github.io/portfolio/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M3 9l9-7 9 7v11a2 2 0 01-2 2H5a2 2 0 01-2-2z"/><polyline points="9 22 9 12 15 12 15 22"/></svg>
<span>HOME</span>
</a><a href=https://yu-codes.github.io/portfolio/articles/ class="nav-item active"><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5.0 016.5 17H20"/><path d="M6.5 2H20v20H6.5A2.5 2.5.0 014 19.5v-15A2.5 2.5.0 016.5 2z"/></svg>
<span>ARTICLES</span>
</a><a href=https://yu-codes.github.io/portfolio/resume/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="12" y1="11" x2="12" y2="17"/><line x1="9" y1="14" x2="15" y2="14"/></svg>
<span>RESUME</span>
</a><a href=https://yu-codes.github.io/portfolio/projects/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="3" width="8" height="8"/><rect x="13" y="3" width="8" height="8"/><rect x="3" y="13" width="8" height="8"/><rect x="13" y="13" width="8" height="8"/></svg>
<span>PROJECTS</span>
</a><a href=https://yu-codes.github.io/portfolio/archives/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
<span>ARCHIVES</span></a></nav><div class=sidebar-footer><div class=controls><button class="control-btn theme-toggle" title="Toggle theme (light/dark)" aria-label="Toggle theme">
<svg class="icon-sun" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".25"/></svg>
<svg class="icon-moon" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".25"/></svg>
</button>
<button class="control-btn lang-toggle" title="Toggle language" aria-label="Toggle language">
<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"/><path d="M2 12h20"/><path d="M12 2a15.3 15.3.0 014 10 15.3 15.3.0 01-4 10A15.3 15.3.0 018 12a15.3 15.3.0 014-10z"/></svg></button></div><div class=social-links><a href=https://github.com/yu-codes target=_blank rel="noopener noreferrer" class=social-link title=GitHub><svg viewBox="0 0 24 24" fill="currentColor"><path d="M12 0C5.374.0.0 5.373.0 12c0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931.0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176.0.0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221.0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/></svg>
</a><a href=mailto:dylan.jhou1120@gmail.com class=social-link title=Email><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div></div></aside><div class=main-content><div class=topbar><div class=breadcrumb><a href=https://yu-codes.github.io/portfolio/>HOME</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/articles/>ARTICLES</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/articles/others/>Others</a><span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/articles/others/cloud/>Cloud</a><span class=separator>&#8250;</span>
<span>GPU 叢集調度全攻略：NVIDIA Plugin、MIG、Slurm、Ray、GPU Sharing</span></div></div><main class=content-area><article class=article-content><header class=article-header><h1>GPU 叢集調度全攻略：NVIDIA Plugin、MIG、Slurm、Ray、GPU Sharing</h1><div class=article-meta><span class=article-author><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20 21v-2a4 4 0 00-4-4H8a4 4 0 00-4 4v2"/><circle cx="12" cy="7" r="4"/></svg>
Yu-Han Jhou
</span><span class=article-updated><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>
Last updated: 2025-09-18</span></div></header><div class=article-body><p>現代 AI 訓練與推論高度依賴 GPU 叢集調度。從 Kubernetes NVIDIA Device Plugin、MIG、Node Affinity，到 Slurm、Ray、Kubeflow Training Operator、Multi-Instance GPU 與 GPU Sharing，本章將結合理論、功能比較、實戰設計、面試熱點與常見誤區，幫助你打造高效可擴展的 GPU 平台。</p><hr><nav class=article-toc><span class=toc-title>Table of Contents</span><nav id=TableOfContents><ul><li><a href=#nvidia-device-pluginmignode-affinity>NVIDIA Device Plugin、MIG、Node Affinity</a><ul><li><a href=#nvidia-device-plugin>NVIDIA Device Plugin</a></li><li><a href=#migmulti-instance-gpu>MIG（Multi-Instance GPU）</a></li><li><a href=#node-affinity>Node Affinity</a></li></ul></li><li><a href=#slurm-ray-kubeflow-training-operator>Slurm, Ray, Kubeflow Training Operator</a><ul><li><a href=#slurm>Slurm</a></li><li><a href=#ray>Ray</a></li><li><a href=#kubeflow-training-operator>Kubeflow Training Operator</a></li></ul></li><li><a href=#multi-instance-gpu-與-gpu-sharing>Multi-Instance GPU 與 GPU Sharing</a></li><li><a href=#設計實戰與最佳實踐>設計實戰與最佳實踐</a></li><li><a href=#理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</a><ul><li><a href=#應用場景>應用場景</a></li><li><a href=#常見誤區>常見誤區</a></li></ul></li><li><a href=#面試熱點與經典問題>面試熱點與經典問題</a></li><li><a href=#使用注意事項>使用注意事項</a></li><li><a href=#延伸閱讀與資源>延伸閱讀與資源</a></li><li><a href=#經典面試題與解法提示>經典面試題與解法提示</a></li><li><a href=#結語>結語</a></li></ul></nav></nav><h2 id=nvidia-device-pluginmignode-affinity>NVIDIA Device Plugin、MIG、Node Affinity</h2><h3 id=nvidia-device-plugin>NVIDIA Device Plugin</h3><ul><li>K8s GPU 調度標配，支援自動發現與分配 GPU</li><li>支援 nvidia.com/gpu 資源限制，Pod 可指定卡數</li><li>監控 GPU 使用率，防止資源閒置</li></ul><h3 id=migmulti-instance-gpu>MIG（Multi-Instance GPU）</h3><ul><li>支援 A100/Hopper 等 GPU 一卡多用，分割為多個獨立實例</li><li>適合多租戶、推論混合訓練場景</li><li>K8s 支援 MIG Profile 調度，需設 Node Affinity</li></ul><h3 id=node-affinity>Node Affinity</h3><ul><li>控制 Pod 部署到特定 GPU 型號/配置節點</li><li>適合異構 GPU 叢集、資源隔離</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>limits</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>nvidia.com/gpu</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>nodeSelector</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>gpu</span>: <span style=color:#e6db74>&#34;a100&#34;</span>
</span></span></code></pre></div><hr><h2 id=slurm-ray-kubeflow-training-operator>Slurm, Ray, Kubeflow Training Operator</h2><h3 id=slurm>Slurm</h3><ul><li>HPC/AI 標準排程器，支援 GPU/CPU 任務、資源配額、佇列管理</li><li>適合超算中心、科研機構、混合雲</li></ul><h3 id=ray>Ray</h3><ul><li>分散式運算框架，支援動態 GPU 資源分配、彈性調度</li><li>適合大規模分散式訓練、推論、RL</li></ul><h3 id=kubeflow-training-operator>Kubeflow Training Operator</h3><ul><li>K8s 原生訓練排程，支援 PyTorchJob、TFJob、MPIJob</li><li>整合 GPU 調度、資源監控、彈性伸縮</li></ul><hr><h2 id=multi-instance-gpu-與-gpu-sharing>Multi-Instance GPU 與 GPU Sharing</h2><ul><li>Multi-Instance GPU（MIG）：一卡多用，提升 GPU 利用率</li><li>GPU Sharing：多 Pod/Job 共用單張 GPU（如 MIG、KubeShare、GPU Operator）</li><li>適合推論服務、低負載多租戶場景</li><li>建議監控 GPU 使用率與資源隔離</li></ul><hr><h2 id=設計實戰與最佳實踐>設計實戰與最佳實踐</h2><ul><li>大型訓練建議用 Slurm/Kubeflow，推論/混合場景用 Ray/MIG</li><li>Node Affinity/Label 管理異構 GPU</li><li>GPU Sharing 建議設資源配額與監控</li><li>定期審查 GPU 使用率，優化排程策略</li></ul><hr><h2 id=理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</h2><h3 id=應用場景>應用場景</h3><ul><li>大規模 AI 訓練、推論服務、科研 HPC、雲端 GPU 叢集</li></ul><h3 id=常見誤區>常見誤區</h3><ul><li>GPU 調度未設 affinity，Pod 排程失敗</li><li>MIG 配置錯誤，資源閒置或衝突</li><li>Slurm/Ray 未設資源配額，任務搶佔</li><li>GPU Sharing 權限設計不當，資料外洩風險</li></ul><hr><h2 id=面試熱點與經典問題>面試熱點與經典問題</h2><table><thead><tr><th>主題</th><th>常見問題</th></tr></thead><tbody><tr><td>NVIDIA Plugin/MIG</td><td>原理與應用場景？</td></tr><tr><td>Slurm vs Ray</td><td>差異與選型？</td></tr><tr><td>Kubeflow Training Operator</td><td>功能與優勢？</td></tr><tr><td>GPU Sharing</td><td>如何實現與監控？</td></tr><tr><td>Node Affinity</td><td>異構 GPU 管理？</td></tr></tbody></table><hr><h2 id=使用注意事項>使用注意事項</h2><ul><li>GPU/MIG 配置建議自動化與監控</li><li>Slurm/Ray/Kubeflow 建議設資源配額</li><li>GPU Sharing 需設權限與隔離策略</li></ul><hr><h2 id=延伸閱讀與資源>延伸閱讀與資源</h2><ul><li><a href=https://github.com/NVIDIA/k8s-device-plugin>NVIDIA Device Plugin</a></li><li><a href=https://docs.nvidia.com/datacenter/tesla/mig-user-guide/>MIG 官方文件</a></li><li><a href=https://slurm.schedmd.com/documentation.html>Slurm 官方文件</a></li><li><a href=https://docs.ray.io/en/latest/>Ray 官方文件</a></li><li><a href=https://www.kubeflow.org/docs/components/training/>Kubeflow Training Operator</a></li></ul><hr><h2 id=經典面試題與解法提示>經典面試題與解法提示</h2><ol><li>NVIDIA Device Plugin/MIG 原理與應用？</li><li>Slurm/Ray/Kubeflow 差異與選型？</li><li>GPU Sharing/MIG 配置挑戰？</li><li>Node Affinity/Label 管理異構 GPU？</li><li>GPU 資源配額與監控？</li><li>如何用 YAML 實作 MIG 調度？</li><li>Slurm/Ray 資源搶佔如何防範？</li><li>GPU Sharing 權限與隔離？</li><li>Kubeflow Training Operator 部署細節？</li><li>GPU 叢集調度常見踩坑？</li></ol><hr><h2 id=結語>結語</h2><p>GPU 叢集調度是 AI 訓練與推論平台的核心。熟悉 NVIDIA Plugin、MIG、Slurm、Ray、GPU Sharing，能讓你打造高效可擴展的 GPU 平台。下一章將進入推論 API 佈署策略，敬請期待！</p></div><div class=article-tags><div class=tags><span class=tag>GPU</span>
<span class=tag>Cluster Scheduling</span>
<span class=tag>NVIDIA Device Plugin</span>
<span class=tag>MIG</span>
<span class=tag>Node Affinity</span>
<span class=tag>Slurm</span>
<span class=tag>Ray</span>
<span class=tag>Kubeflow</span>
<span class=tag>GPU Sharing</span>
<span class=tag>Multi-Instance GPU</span></div></div><footer class=article-footer><a href=/portfolio/articles/others/cloud/ class=back-link>← Back to Cloud</a></footer></article></main><footer class=site-footer><p>&copy; 2026 YuHan Jhou. All rights reserved.</p></footer></div></div><script src=https://yu-codes.github.io/portfolio/js/theme.js defer></script><script src=https://yu-codes.github.io/portfolio/js/roadmap.js defer></script><script src=https://yu-codes.github.io/portfolio/js/parallax.js defer></script><script src=https://yu-codes.github.io/portfolio/js/page-transition.js defer></script></body></html>