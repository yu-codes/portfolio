<!doctype html><html lang=en class=html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>分散式與大規模訓練全攻略：Data/Model/Pipeline Parallel, ZeRO, FSDP, Elastic Training - Yu's Portfolio & Learning Hub</title><meta name=description content="隨著模型規模不斷擴大，單機訓練已無法滿足需求。分散式與大規模訓練技術（Data/Model/Pipeline Parallel, ZeRO, FSDP, Megatron-LM, Elastic Training）成為現代 AI 訓練的核心。本章將深入原理、架構圖解、PyTorch/Hugging Face 實作、資源管理、面試熱點與常見誤區，幫助你掌握大模型訓練的關鍵技術。
Data / Model / Pipeline Parallelism Data Parallel 每台機器訓練同一模型，分配不同 mini-batch，梯度同步 適合大資料集、模型較小 Model Parallel 將模型切分到多台機器/卡上，適合超大模型（如 GPT-3） 需手動劃分模型結構 Pipeline Parallel 將模型分為多個 stage，資料流經各 stage，提升硬體利用率 常與 Data/Model Parallel 結合 import torch.distributed as dist # PyTorch DDP 範例 dist.init_process_group(backend='nccl') model = torch.nn.parallel.DistributedDataParallel(model) ZeRO Stage 1-3, FSDP, Megatron-LM ZeRO (Zero Redundancy Optimizer) Stage 1：優化器狀態分散 Stage 2：加上梯度分散 Stage 3：參數分散，極致節省記憶體 適合超大模型（如 GPT-3、T5） FSDP（Fully Sharded Data Parallel） PyTorch 官方，參數/梯度/優化器狀態全分片 支援動態層、低記憶體佔用 Megatron-LM NVIDIA 開源，支援 Model/Pipeline Parallel，訓練千億參數模型 Gradient Accumulation vs. Micro-Batch Gradient Accumulation：多個 mini-batch 累積梯度再更新，等效大 batch Micro-Batch：每個 pipeline stage 處理小 batch，提升吞吐 Checkpoint Sharding & Elastic Training Checkpoint Sharding 將模型權重分片存儲，減少單機 I/O 壓力，加速恢復 Elastic Training 支援動態增減節點，提升容錯與資源利用率 PyTorch Elastic、DeepSpeed Elastic 理論直覺、應用場景與常見誤區 應用場景 超大模型訓練（GPT-3、T5、Llama）、企業內部大規模預訓練、雲端分散式訓練 常見誤區 Data Parallel 過多導致通訊瓶頸 Model/Pipeline Parallel 劃分不均，造成資源閒置 ZeRO/FSDP 配置錯誤導致 OOM Checkpoint Sharding 未測試恢復流程 面試熱點與經典問題 主題 常見問題 Data/Model/Pipeline 差異與適用場景？ ZeRO Stage 1-3 有何不同？ FSDP 與 DDP/ZeRO 差異？ Gradient Accumulation 作用與實作？ Elastic Training 如何提升容錯？ 使用注意事項 分散式訓練需正確設置通訊後端與網路 ZeRO/FSDP 需根據模型大小與硬體調整 stage Checkpoint Sharding/Elastic Training 建議多做容錯測試 延伸閱讀與資源 PyTorch Distributed 官方文件 DeepSpeed ZeRO 論文 FSDP 官方文件 Megatron-LM GitHub PyTorch Elastic 官方文件 經典面試題與解法提示 Data/Model/Pipeline Parallel 差異與組合？ ZeRO Stage 1-3 原理與應用？ FSDP 與 ZeRO/ DDP 差異？ Gradient Accumulation 實作細節？ Checkpoint Sharding 如何加速恢復？ Elastic Training 如何提升容錯？ Megatron-LM 支援哪些並行方式？ 分散式訓練常見瓶頸與解法？ 如何用 Python 實作 DDP/FSDP？ 分散式訓練的資源管理挑戰？ 結語 分散式與大規模訓練是現代 AI 的基石。熟悉 Data/Model/Pipeline Parallel、ZeRO、FSDP、Elastic Training 等技術，能讓你高效訓練超大模型並在面試中展現專業素養。下一章將進入超參數尋優進階，敬請期待！
"><meta property="og:title" content="分散式與大規模訓練全攻略：Data/Model/Pipeline Parallel, ZeRO, FSDP, Elastic Training"><meta property="og:description" content="隨著模型規模不斷擴大，單機訓練已無法滿足需求。分散式與大規模訓練技術（Data/Model/Pipeline Parallel, ZeRO, FSDP, Megatron-LM, Elastic Training）成為現代 AI 訓練的核心。本章將深入原理、架構圖解、PyTorch/Hugging Face 實作、資源管理、面試熱點與常見誤區，幫助你掌握大模型訓練的關鍵技術。
Data / Model / Pipeline Parallelism Data Parallel 每台機器訓練同一模型，分配不同 mini-batch，梯度同步 適合大資料集、模型較小 Model Parallel 將模型切分到多台機器/卡上，適合超大模型（如 GPT-3） 需手動劃分模型結構 Pipeline Parallel 將模型分為多個 stage，資料流經各 stage，提升硬體利用率 常與 Data/Model Parallel 結合 import torch.distributed as dist # PyTorch DDP 範例 dist.init_process_group(backend='nccl') model = torch.nn.parallel.DistributedDataParallel(model) ZeRO Stage 1-3, FSDP, Megatron-LM ZeRO (Zero Redundancy Optimizer) Stage 1：優化器狀態分散 Stage 2：加上梯度分散 Stage 3：參數分散，極致節省記憶體 適合超大模型（如 GPT-3、T5） FSDP（Fully Sharded Data Parallel） PyTorch 官方，參數/梯度/優化器狀態全分片 支援動態層、低記憶體佔用 Megatron-LM NVIDIA 開源，支援 Model/Pipeline Parallel，訓練千億參數模型 Gradient Accumulation vs. Micro-Batch Gradient Accumulation：多個 mini-batch 累積梯度再更新，等效大 batch Micro-Batch：每個 pipeline stage 處理小 batch，提升吞吐 Checkpoint Sharding & Elastic Training Checkpoint Sharding 將模型權重分片存儲，減少單機 I/O 壓力，加速恢復 Elastic Training 支援動態增減節點，提升容錯與資源利用率 PyTorch Elastic、DeepSpeed Elastic 理論直覺、應用場景與常見誤區 應用場景 超大模型訓練（GPT-3、T5、Llama）、企業內部大規模預訓練、雲端分散式訓練 常見誤區 Data Parallel 過多導致通訊瓶頸 Model/Pipeline Parallel 劃分不均，造成資源閒置 ZeRO/FSDP 配置錯誤導致 OOM Checkpoint Sharding 未測試恢復流程 面試熱點與經典問題 主題 常見問題 Data/Model/Pipeline 差異與適用場景？ ZeRO Stage 1-3 有何不同？ FSDP 與 DDP/ZeRO 差異？ Gradient Accumulation 作用與實作？ Elastic Training 如何提升容錯？ 使用注意事項 分散式訓練需正確設置通訊後端與網路 ZeRO/FSDP 需根據模型大小與硬體調整 stage Checkpoint Sharding/Elastic Training 建議多做容錯測試 延伸閱讀與資源 PyTorch Distributed 官方文件 DeepSpeed ZeRO 論文 FSDP 官方文件 Megatron-LM GitHub PyTorch Elastic 官方文件 經典面試題與解法提示 Data/Model/Pipeline Parallel 差異與組合？ ZeRO Stage 1-3 原理與應用？ FSDP 與 ZeRO/ DDP 差異？ Gradient Accumulation 實作細節？ Checkpoint Sharding 如何加速恢復？ Elastic Training 如何提升容錯？ Megatron-LM 支援哪些並行方式？ 分散式訓練常見瓶頸與解法？ 如何用 Python 實作 DDP/FSDP？ 分散式訓練的資源管理挑戰？ 結語 分散式與大規模訓練是現代 AI 的基石。熟悉 Data/Model/Pipeline Parallel、ZeRO、FSDP、Elastic Training 等技術，能讓你高效訓練超大模型並在面試中展現專業素養。下一章將進入超參數尋優進階，敬請期待！
"><meta property="og:url" content="https://yu-codes.github.io/portfolio/articles/others/machine-learning/distributed-training/"><link rel=canonical href=https://yu-codes.github.io/portfolio/articles/others/machine-learning/distributed-training/><link rel=stylesheet href=https://yu-codes.github.io/portfolio/css/main.css></head><body class=body><div class=container><aside class=sidebar><div class=sidebar-header><h1 class=name>Yu</h1><p class=tagline>Developer, dreamer, debugger.</p></div><nav class=sidebar-nav><a href=https://yu-codes.github.io/portfolio/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M3 9l9-7 9 7v11a2 2 0 01-2 2H5a2 2 0 01-2-2z"/><polyline points="9 22 9 12 15 12 15 22"/></svg>
<span>HOME</span>
</a><a href=https://yu-codes.github.io/portfolio/articles/ class="nav-item active"><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5.0 016.5 17H20"/><path d="M6.5 2H20v20H6.5A2.5 2.5.0 014 19.5v-15A2.5 2.5.0 016.5 2z"/></svg>
<span>ARTICLES</span>
</a><a href=https://yu-codes.github.io/portfolio/resume/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="12" y1="11" x2="12" y2="17"/><line x1="9" y1="14" x2="15" y2="14"/></svg>
<span>RESUME</span>
</a><a href=https://yu-codes.github.io/portfolio/projects/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="3" width="8" height="8"/><rect x="13" y="3" width="8" height="8"/><rect x="3" y="13" width="8" height="8"/><rect x="13" y="13" width="8" height="8"/></svg>
<span>PROJECTS</span>
</a><a href=https://yu-codes.github.io/portfolio/archives/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
<span>ARCHIVES</span></a></nav><div class=sidebar-footer><div class=controls><button class="control-btn theme-toggle" title="Toggle theme (light/dark)" aria-label="Toggle theme">
<svg class="icon-sun" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".25"/></svg>
<svg class="icon-moon" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".25"/></svg>
</button>
<button class="control-btn lang-toggle" title="Toggle language" aria-label="Toggle language">
<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"/><path d="M2 12h20"/><path d="M12 2a15.3 15.3.0 014 10 15.3 15.3.0 01-4 10A15.3 15.3.0 018 12a15.3 15.3.0 014-10z"/></svg></button></div><div class=social-links><a href=https://github.com/yu-codes target=_blank rel="noopener noreferrer" class=social-link title=GitHub><svg viewBox="0 0 24 24" fill="currentColor"><path d="M12 0C5.374.0.0 5.373.0 12c0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931.0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176.0.0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221.0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/></svg>
</a><a href=mailto:dylan.jhou1120@gmail.com class=social-link title=Email><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div></div></aside><div class=main-content><div class=topbar><div class=breadcrumb><a href=https://yu-codes.github.io/portfolio/>HOME</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/articles/>ARTICLES</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/articles/others/>Others</a><span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/articles/others/machine-learning/>Machine Learning</a><span class=separator>&#8250;</span>
<span>分散式與大規模訓練全攻略：Data/Model/Pipeline Parallel, ZeRO, FSDP, Elastic Training</span></div></div><main class=content-area><article class=article-content><header class=article-header><h1>分散式與大規模訓練全攻略：Data/Model/Pipeline Parallel, ZeRO, FSDP, Elastic Training</h1><div class=article-meta><span class=article-author><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20 21v-2a4 4 0 00-4-4H8a4 4 0 00-4 4v2"/><circle cx="12" cy="7" r="4"/></svg>
Yu-Han Jhou
</span><span class=article-updated><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>
Last updated: 2025-06-22</span></div></header><div class=article-body><p>隨著模型規模不斷擴大，單機訓練已無法滿足需求。分散式與大規模訓練技術（Data/Model/Pipeline Parallel, ZeRO, FSDP, Megatron-LM, Elastic Training）成為現代 AI 訓練的核心。本章將深入原理、架構圖解、PyTorch/Hugging Face 實作、資源管理、面試熱點與常見誤區，幫助你掌握大模型訓練的關鍵技術。</p><hr><nav class=article-toc><span class=toc-title>Table of Contents</span><nav id=TableOfContents><ul><li><a href=#data--model--pipeline-parallelism>Data / Model / Pipeline Parallelism</a><ul><li><a href=#data-parallel>Data Parallel</a></li><li><a href=#model-parallel>Model Parallel</a></li><li><a href=#pipeline-parallel>Pipeline Parallel</a></li></ul></li><li><a href=#zero-stage-1-3-fsdp-megatron-lm>ZeRO Stage 1-3, FSDP, Megatron-LM</a><ul><li><a href=#zero-zero-redundancy-optimizer>ZeRO (Zero Redundancy Optimizer)</a></li><li><a href=#fsdpfully-sharded-data-parallel>FSDP（Fully Sharded Data Parallel）</a></li><li><a href=#megatron-lm>Megatron-LM</a></li></ul></li><li><a href=#gradient-accumulation-vs-micro-batch>Gradient Accumulation vs. Micro-Batch</a></li><li><a href=#checkpoint-sharding--elastic-training>Checkpoint Sharding & Elastic Training</a><ul><li><a href=#checkpoint-sharding>Checkpoint Sharding</a></li><li><a href=#elastic-training>Elastic Training</a></li></ul></li><li><a href=#理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</a><ul><li><a href=#應用場景>應用場景</a></li><li><a href=#常見誤區>常見誤區</a></li></ul></li><li><a href=#面試熱點與經典問題>面試熱點與經典問題</a></li><li><a href=#使用注意事項>使用注意事項</a></li><li><a href=#延伸閱讀與資源>延伸閱讀與資源</a></li><li><a href=#經典面試題與解法提示>經典面試題與解法提示</a></li><li><a href=#結語>結語</a></li></ul></nav></nav><h2 id=data--model--pipeline-parallelism>Data / Model / Pipeline Parallelism</h2><h3 id=data-parallel>Data Parallel</h3><ul><li>每台機器訓練同一模型，分配不同 mini-batch，梯度同步</li><li>適合大資料集、模型較小</li></ul><h3 id=model-parallel>Model Parallel</h3><ul><li>將模型切分到多台機器/卡上，適合超大模型（如 GPT-3）</li><li>需手動劃分模型結構</li></ul><h3 id=pipeline-parallel>Pipeline Parallel</h3><ul><li>將模型分為多個 stage，資料流經各 stage，提升硬體利用率</li><li>常與 Data/Model Parallel 結合</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch.distributed <span style=color:#66d9ef>as</span> dist
</span></span><span style=display:flex><span><span style=color:#75715e># PyTorch DDP 範例</span>
</span></span><span style=display:flex><span>dist<span style=color:#f92672>.</span>init_process_group(backend<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;nccl&#39;</span>)
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>nn<span style=color:#f92672>.</span>parallel<span style=color:#f92672>.</span>DistributedDataParallel(model)
</span></span></code></pre></div><hr><h2 id=zero-stage-1-3-fsdp-megatron-lm>ZeRO Stage 1-3, FSDP, Megatron-LM</h2><h3 id=zero-zero-redundancy-optimizer>ZeRO (Zero Redundancy Optimizer)</h3><ul><li>Stage 1：優化器狀態分散</li><li>Stage 2：加上梯度分散</li><li>Stage 3：參數分散，極致節省記憶體</li><li>適合超大模型（如 GPT-3、T5）</li></ul><h3 id=fsdpfully-sharded-data-parallel>FSDP（Fully Sharded Data Parallel）</h3><ul><li>PyTorch 官方，參數/梯度/優化器狀態全分片</li><li>支援動態層、低記憶體佔用</li></ul><h3 id=megatron-lm>Megatron-LM</h3><ul><li>NVIDIA 開源，支援 Model/Pipeline Parallel，訓練千億參數模型</li></ul><hr><h2 id=gradient-accumulation-vs-micro-batch>Gradient Accumulation vs. Micro-Batch</h2><ul><li>Gradient Accumulation：多個 mini-batch 累積梯度再更新，等效大 batch</li><li>Micro-Batch：每個 pipeline stage 處理小 batch，提升吞吐</li></ul><hr><h2 id=checkpoint-sharding--elastic-training>Checkpoint Sharding & Elastic Training</h2><h3 id=checkpoint-sharding>Checkpoint Sharding</h3><ul><li>將模型權重分片存儲，減少單機 I/O 壓力，加速恢復</li></ul><h3 id=elastic-training>Elastic Training</h3><ul><li>支援動態增減節點，提升容錯與資源利用率</li><li>PyTorch Elastic、DeepSpeed Elastic</li></ul><hr><h2 id=理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</h2><h3 id=應用場景>應用場景</h3><ul><li>超大模型訓練（GPT-3、T5、Llama）、企業內部大規模預訓練、雲端分散式訓練</li></ul><h3 id=常見誤區>常見誤區</h3><ul><li>Data Parallel 過多導致通訊瓶頸</li><li>Model/Pipeline Parallel 劃分不均，造成資源閒置</li><li>ZeRO/FSDP 配置錯誤導致 OOM</li><li>Checkpoint Sharding 未測試恢復流程</li></ul><hr><h2 id=面試熱點與經典問題>面試熱點與經典問題</h2><table><thead><tr><th>主題</th><th>常見問題</th></tr></thead><tbody><tr><td>Data/Model/Pipeline</td><td>差異與適用場景？</td></tr><tr><td>ZeRO</td><td>Stage 1-3 有何不同？</td></tr><tr><td>FSDP</td><td>與 DDP/ZeRO 差異？</td></tr><tr><td>Gradient Accumulation</td><td>作用與實作？</td></tr><tr><td>Elastic Training</td><td>如何提升容錯？</td></tr></tbody></table><hr><h2 id=使用注意事項>使用注意事項</h2><ul><li>分散式訓練需正確設置通訊後端與網路</li><li>ZeRO/FSDP 需根據模型大小與硬體調整 stage</li><li>Checkpoint Sharding/Elastic Training 建議多做容錯測試</li></ul><hr><h2 id=延伸閱讀與資源>延伸閱讀與資源</h2><ul><li><a href=https://pytorch.org/docs/stable/distributed.html>PyTorch Distributed 官方文件</a></li><li><a href=https://arxiv.org/abs/1910.02054>DeepSpeed ZeRO 論文</a></li><li><a href=https://pytorch.org/docs/stable/fsdp.html>FSDP 官方文件</a></li><li><a href=https://github.com/NVIDIA/Megatron-LM>Megatron-LM GitHub</a></li><li><a href=https://pytorch.org/docs/stable/elastic.html>PyTorch Elastic 官方文件</a></li></ul><hr><h2 id=經典面試題與解法提示>經典面試題與解法提示</h2><ol><li>Data/Model/Pipeline Parallel 差異與組合？</li><li>ZeRO Stage 1-3 原理與應用？</li><li>FSDP 與 ZeRO/ DDP 差異？</li><li>Gradient Accumulation 實作細節？</li><li>Checkpoint Sharding 如何加速恢復？</li><li>Elastic Training 如何提升容錯？</li><li>Megatron-LM 支援哪些並行方式？</li><li>分散式訓練常見瓶頸與解法？</li><li>如何用 Python 實作 DDP/FSDP？</li><li>分散式訓練的資源管理挑戰？</li></ol><hr><h2 id=結語>結語</h2><p>分散式與大規模訓練是現代 AI 的基石。熟悉 Data/Model/Pipeline Parallel、ZeRO、FSDP、Elastic Training 等技術，能讓你高效訓練超大模型並在面試中展現專業素養。下一章將進入超參數尋優進階，敬請期待！</p></div><div class=article-tags><div class=tags><span class=tag>distributed-training</span>
<span class=tag>model-parallel</span>
<span class=tag>pipeline-parallel</span></div></div><footer class=article-footer><a href=/portfolio/articles/others/machine-learning/ class=back-link>← Back to Machine Learning</a></footer></article></main><footer class=site-footer><p>&copy; 2026 YuHan Jhou. All rights reserved.</p></footer></div></div><script src=https://yu-codes.github.io/portfolio/js/theme.js defer></script><script src=https://yu-codes.github.io/portfolio/js/roadmap.js defer></script><script src=https://yu-codes.github.io/portfolio/js/parallax.js defer></script><script src=https://yu-codes.github.io/portfolio/js/page-transition.js defer></script></body></html>