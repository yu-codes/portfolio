<!doctype html><html lang=en class=html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>生成模型百花齊放：自回歸、VAE、GAN、Diffusion 與應用全解析 - Yu's Portfolio & Learning Hub</title><meta name=description content="生成模型是現代 AI 最活躍的領域之一，從自回歸、VAE、GAN、Flow-based 到 Diffusion，各有理論基礎與應用場景。本章將深入數學推導、直覺圖解、Python 實作、應用案例、面試熱點與常見誤區，幫助你全面掌握生成模型。
自回歸 vs. 自編碼 vs. Diffusion 自回歸模型（Autoregressive） 逐步生成資料，每步條件於前一步（如 GPT、PixelRNN） 優點：生成品質高，缺點：推理慢 自編碼模型（Autoencoder, VAE） 編碼器將資料壓縮為潛在空間，解碼器重建資料 VAE 加入機率假設，能生成新樣本並量化不確定性 Diffusion Model 逐步將資料加噪聲，再學習反向去噪過程（如 Stable Diffusion） 優點：生成多樣性高，缺點：推理慢 GAN, VAE, Flow-based Model 核心 Loss GAN（生成對抗網路） 生成器與判別器對抗訓練，損失函數為 min-max 遊戲 常見問題：mode collapse、不穩定 import torch import torch.nn as nn D = nn.Sequential(nn.Linear(2, 16), nn.ReLU(), nn.Linear(16, 1), nn.Sigmoid()) G = nn.Sequential(nn.Linear(2, 16), nn.ReLU(), nn.Linear(16, 2)) loss_fn = nn.BCELoss() # ...訓練流程略... VAE（變分自編碼器） Evidence Lower Bound (ELBO) 作為損失，包含重建誤差與 KL 散度 能生成新樣本並量化潛在空間 class VAE(nn.Module): def __init__(self): super().__init__() self.enc = nn.Linear(2, 4) self.dec = nn.Linear(2, 2) def forward(self, x): mu = self.enc(x) z = mu # 簡化，實際應加隨機性 return self.dec(z) Flow-based Model 可逆變換，精確計算 likelihood（如 RealNVP、Glow） 適合密度估計與高品質生成 Diffusion Upsampler、Latent Diffusion & ControlNet Diffusion Upsampler 用於高解析度圖像生成，先低清再逐步升級 Latent Diffusion 在潛在空間進行 diffusion，提升效率（如 Stable Diffusion） ControlNet 在 diffusion 過程中加入條件控制（如姿態、邊緣圖），提升可控性 理論直覺、應用場景與常見誤區 應用場景 影像生成（Stable Diffusion、GAN）、語音合成、文本生成（GPT）、異常偵測、資料增強 常見誤區 GAN 訓練不穩定，需調參與技巧（如 label smoothing、gradient penalty） VAE 生成樣本模糊，需調整潛在空間維度 Diffusion 推理慢，可用 DDIM、Latent Diffusion 加速 Flow-based 模型參數多，訓練成本高 面試熱點與經典問題 主題 常見問題 GAN 損失函數推導？mode collapse？ VAE ELBO 結構與 KL 散度作用？ Diffusion 正向/反向過程數學原理？ Flow-based 可逆變換如何設計？ ControlNet 如何提升生成可控性？ 使用注意事項 生成模型需大量資料與算力，建議用預訓練權重微調 GAN/VAE/Diffusion 各有優缺點，根據任務選擇 訓練過程需監控生成品質與多樣性 延伸閱讀與資源 GAN 原論文 VAE 原論文 Glow: Flow-based Model Stable Diffusion 論文 ControlNet 論文 經典面試題與解法提示 GAN 損失函數與訓練技巧？ VAE 的 ELBO 推導與 KL 項作用？ Diffusion Model 的正向/反向過程？ Flow-based Model 如何保證可逆？ ControlNet 如何提升可控性？ 生成模型如何評估品質？ GAN mode collapse 如何解決？ Diffusion 推理加速方法？ VAE 潛在空間設計原則？ 如何用 Python 實作簡單 GAN/VAE？ 結語 生成模型是 AI 創造力的核心。熟悉自回歸、VAE、GAN、Diffusion、Flow-based 與 ControlNet，能讓你在影像、語音、文本生成等領域發揮深度學習威力。下一章將進入正規化與訓練技巧，敬請期待！
"><meta property="og:title" content="生成模型百花齊放：自回歸、VAE、GAN、Diffusion 與應用全解析"><meta property="og:description" content="生成模型是現代 AI 最活躍的領域之一，從自回歸、VAE、GAN、Flow-based 到 Diffusion，各有理論基礎與應用場景。本章將深入數學推導、直覺圖解、Python 實作、應用案例、面試熱點與常見誤區，幫助你全面掌握生成模型。
自回歸 vs. 自編碼 vs. Diffusion 自回歸模型（Autoregressive） 逐步生成資料，每步條件於前一步（如 GPT、PixelRNN） 優點：生成品質高，缺點：推理慢 自編碼模型（Autoencoder, VAE） 編碼器將資料壓縮為潛在空間，解碼器重建資料 VAE 加入機率假設，能生成新樣本並量化不確定性 Diffusion Model 逐步將資料加噪聲，再學習反向去噪過程（如 Stable Diffusion） 優點：生成多樣性高，缺點：推理慢 GAN, VAE, Flow-based Model 核心 Loss GAN（生成對抗網路） 生成器與判別器對抗訓練，損失函數為 min-max 遊戲 常見問題：mode collapse、不穩定 import torch import torch.nn as nn D = nn.Sequential(nn.Linear(2, 16), nn.ReLU(), nn.Linear(16, 1), nn.Sigmoid()) G = nn.Sequential(nn.Linear(2, 16), nn.ReLU(), nn.Linear(16, 2)) loss_fn = nn.BCELoss() # ...訓練流程略... VAE（變分自編碼器） Evidence Lower Bound (ELBO) 作為損失，包含重建誤差與 KL 散度 能生成新樣本並量化潛在空間 class VAE(nn.Module): def __init__(self): super().__init__() self.enc = nn.Linear(2, 4) self.dec = nn.Linear(2, 2) def forward(self, x): mu = self.enc(x) z = mu # 簡化，實際應加隨機性 return self.dec(z) Flow-based Model 可逆變換，精確計算 likelihood（如 RealNVP、Glow） 適合密度估計與高品質生成 Diffusion Upsampler、Latent Diffusion & ControlNet Diffusion Upsampler 用於高解析度圖像生成，先低清再逐步升級 Latent Diffusion 在潛在空間進行 diffusion，提升效率（如 Stable Diffusion） ControlNet 在 diffusion 過程中加入條件控制（如姿態、邊緣圖），提升可控性 理論直覺、應用場景與常見誤區 應用場景 影像生成（Stable Diffusion、GAN）、語音合成、文本生成（GPT）、異常偵測、資料增強 常見誤區 GAN 訓練不穩定，需調參與技巧（如 label smoothing、gradient penalty） VAE 生成樣本模糊，需調整潛在空間維度 Diffusion 推理慢，可用 DDIM、Latent Diffusion 加速 Flow-based 模型參數多，訓練成本高 面試熱點與經典問題 主題 常見問題 GAN 損失函數推導？mode collapse？ VAE ELBO 結構與 KL 散度作用？ Diffusion 正向/反向過程數學原理？ Flow-based 可逆變換如何設計？ ControlNet 如何提升生成可控性？ 使用注意事項 生成模型需大量資料與算力，建議用預訓練權重微調 GAN/VAE/Diffusion 各有優缺點，根據任務選擇 訓練過程需監控生成品質與多樣性 延伸閱讀與資源 GAN 原論文 VAE 原論文 Glow: Flow-based Model Stable Diffusion 論文 ControlNet 論文 經典面試題與解法提示 GAN 損失函數與訓練技巧？ VAE 的 ELBO 推導與 KL 項作用？ Diffusion Model 的正向/反向過程？ Flow-based Model 如何保證可逆？ ControlNet 如何提升可控性？ 生成模型如何評估品質？ GAN mode collapse 如何解決？ Diffusion 推理加速方法？ VAE 潛在空間設計原則？ 如何用 Python 實作簡單 GAN/VAE？ 結語 生成模型是 AI 創造力的核心。熟悉自回歸、VAE、GAN、Diffusion、Flow-based 與 ControlNet，能讓你在影像、語音、文本生成等領域發揮深度學習威力。下一章將進入正規化與訓練技巧，敬請期待！
"><meta property="og:url" content="https://yu-codes.github.io/portfolio/articles/others/machine-learning/generative-models/"><link rel=canonical href=https://yu-codes.github.io/portfolio/articles/others/machine-learning/generative-models/><link rel=stylesheet href=https://yu-codes.github.io/portfolio/css/main.css></head><body class=body><div class=container><aside class=sidebar><div class=sidebar-header><h1 class=name>Yu</h1><p class=tagline>Developer, dreamer, debugger.</p></div><nav class=sidebar-nav><a href=https://yu-codes.github.io/portfolio/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M3 9l9-7 9 7v11a2 2 0 01-2 2H5a2 2 0 01-2-2z"/><polyline points="9 22 9 12 15 12 15 22"/></svg>
<span>HOME</span>
</a><a href=https://yu-codes.github.io/portfolio/articles/ class="nav-item active"><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5.0 016.5 17H20"/><path d="M6.5 2H20v20H6.5A2.5 2.5.0 014 19.5v-15A2.5 2.5.0 016.5 2z"/></svg>
<span>ARTICLES</span>
</a><a href=https://yu-codes.github.io/portfolio/resume/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="12" y1="11" x2="12" y2="17"/><line x1="9" y1="14" x2="15" y2="14"/></svg>
<span>RESUME</span>
</a><a href=https://yu-codes.github.io/portfolio/projects/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="3" width="8" height="8"/><rect x="13" y="3" width="8" height="8"/><rect x="3" y="13" width="8" height="8"/><rect x="13" y="13" width="8" height="8"/></svg>
<span>PROJECTS</span>
</a><a href=https://yu-codes.github.io/portfolio/archives/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
<span>ARCHIVES</span></a></nav><div class=sidebar-footer><div class=controls><button class="control-btn theme-toggle" title="Toggle theme (light/dark)" aria-label="Toggle theme">
<svg class="icon-sun" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".25"/></svg>
<svg class="icon-moon" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".25"/></svg>
</button>
<button class="control-btn lang-toggle" title="Toggle language" aria-label="Toggle language">
<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"/><path d="M2 12h20"/><path d="M12 2a15.3 15.3.0 014 10 15.3 15.3.0 01-4 10A15.3 15.3.0 018 12a15.3 15.3.0 014-10z"/></svg></button></div><div class=social-links><a href=https://github.com/yu-codes target=_blank rel="noopener noreferrer" class=social-link title=GitHub><svg viewBox="0 0 24 24" fill="currentColor"><path d="M12 0C5.374.0.0 5.373.0 12c0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931.0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176.0.0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221.0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/></svg>
</a><a href=mailto:dylan.jhou1120@gmail.com class=social-link title=Email><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div></div></aside><div class=main-content><div class=topbar><div class=breadcrumb><a href=https://yu-codes.github.io/portfolio/>HOME</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/articles/>ARTICLES</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/articles/others/>Others</a><span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/articles/others/machine-learning/>Machine Learning</a><span class=separator>&#8250;</span>
<span>生成模型百花齊放：自回歸、VAE、GAN、Diffusion 與應用全解析</span></div></div><main class=content-area><article class=article-content><header class=article-header><h1>生成模型百花齊放：自回歸、VAE、GAN、Diffusion 與應用全解析</h1><div class=article-meta><span class=article-author><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20 21v-2a4 4 0 00-4-4H8a4 4 0 00-4 4v2"/><circle cx="12" cy="7" r="4"/></svg>
Yu-Han Jhou
</span><span class=article-updated><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>
Last updated: 2025-07-09</span></div></header><div class=article-body><p>生成模型是現代 AI 最活躍的領域之一，從自回歸、VAE、GAN、Flow-based 到 Diffusion，各有理論基礎與應用場景。本章將深入數學推導、直覺圖解、Python 實作、應用案例、面試熱點與常見誤區，幫助你全面掌握生成模型。</p><hr><nav class=article-toc><span class=toc-title>Table of Contents</span><nav id=TableOfContents><ul><li><a href=#自回歸-vs-自編碼-vs-diffusion>自回歸 vs. 自編碼 vs. Diffusion</a><ul><li><a href=#自回歸模型autoregressive>自回歸模型（Autoregressive）</a></li><li><a href=#自編碼模型autoencoder-vae>自編碼模型（Autoencoder, VAE）</a></li><li><a href=#diffusion-model>Diffusion Model</a></li></ul></li><li><a href=#gan-vae-flow-based-model-核心-loss>GAN, VAE, Flow-based Model 核心 Loss</a><ul><li><a href=#gan生成對抗網路>GAN（生成對抗網路）</a></li><li><a href=#vae變分自編碼器>VAE（變分自編碼器）</a></li><li><a href=#flow-based-model>Flow-based Model</a></li></ul></li><li><a href=#diffusion-upsamplerlatent-diffusion--controlnet>Diffusion Upsampler、Latent Diffusion & ControlNet</a><ul><li><a href=#diffusion-upsampler>Diffusion Upsampler</a></li><li><a href=#latent-diffusion>Latent Diffusion</a></li><li><a href=#controlnet>ControlNet</a></li></ul></li><li><a href=#理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</a><ul><li><a href=#應用場景>應用場景</a></li><li><a href=#常見誤區>常見誤區</a></li></ul></li><li><a href=#面試熱點與經典問題>面試熱點與經典問題</a></li><li><a href=#使用注意事項>使用注意事項</a></li><li><a href=#延伸閱讀與資源>延伸閱讀與資源</a></li><li><a href=#經典面試題與解法提示>經典面試題與解法提示</a></li><li><a href=#結語>結語</a></li></ul></nav></nav><h2 id=自回歸-vs-自編碼-vs-diffusion>自回歸 vs. 自編碼 vs. Diffusion</h2><h3 id=自回歸模型autoregressive>自回歸模型（Autoregressive）</h3><ul><li>逐步生成資料，每步條件於前一步（如 GPT、PixelRNN）</li><li>優點：生成品質高，缺點：推理慢</li></ul><h3 id=自編碼模型autoencoder-vae>自編碼模型（Autoencoder, VAE）</h3><ul><li>編碼器將資料壓縮為潛在空間，解碼器重建資料</li><li>VAE 加入機率假設，能生成新樣本並量化不確定性</li></ul><h3 id=diffusion-model>Diffusion Model</h3><ul><li>逐步將資料加噪聲，再學習反向去噪過程（如 Stable Diffusion）</li><li>優點：生成多樣性高，缺點：推理慢</li></ul><hr><h2 id=gan-vae-flow-based-model-核心-loss>GAN, VAE, Flow-based Model 核心 Loss</h2><h3 id=gan生成對抗網路>GAN（生成對抗網路）</h3><ul><li>生成器與判別器對抗訓練，損失函數為 min-max 遊戲</li><li>常見問題：mode collapse、不穩定</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>D <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>16</span>), nn<span style=color:#f92672>.</span>ReLU(), nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>16</span>, <span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>Sigmoid())
</span></span><span style=display:flex><span>G <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>16</span>), nn<span style=color:#f92672>.</span>ReLU(), nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>16</span>, <span style=color:#ae81ff>2</span>))
</span></span><span style=display:flex><span>loss_fn <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>BCELoss()
</span></span><span style=display:flex><span><span style=color:#75715e># ...訓練流程略...</span>
</span></span></code></pre></div><h3 id=vae變分自編碼器>VAE（變分自編碼器）</h3><ul><li>Evidence Lower Bound (ELBO) 作為損失，包含重建誤差與 KL 散度</li><li>能生成新樣本並量化潛在空間</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>VAE</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__init__</span>(self):
</span></span><span style=display:flex><span>        super()<span style=color:#f92672>.</span><span style=color:#a6e22e>__init__</span>()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>enc <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>4</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>dec <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        mu <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>enc(x)
</span></span><span style=display:flex><span>        z <span style=color:#f92672>=</span> mu  <span style=color:#75715e># 簡化，實際應加隨機性</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>dec(z)
</span></span></code></pre></div><h3 id=flow-based-model>Flow-based Model</h3><ul><li>可逆變換，精確計算 likelihood（如 RealNVP、Glow）</li><li>適合密度估計與高品質生成</li></ul><hr><h2 id=diffusion-upsamplerlatent-diffusion--controlnet>Diffusion Upsampler、Latent Diffusion & ControlNet</h2><h3 id=diffusion-upsampler>Diffusion Upsampler</h3><ul><li>用於高解析度圖像生成，先低清再逐步升級</li></ul><h3 id=latent-diffusion>Latent Diffusion</h3><ul><li>在潛在空間進行 diffusion，提升效率（如 Stable Diffusion）</li></ul><h3 id=controlnet>ControlNet</h3><ul><li>在 diffusion 過程中加入條件控制（如姿態、邊緣圖），提升可控性</li></ul><hr><h2 id=理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</h2><h3 id=應用場景>應用場景</h3><ul><li>影像生成（Stable Diffusion、GAN）、語音合成、文本生成（GPT）、異常偵測、資料增強</li></ul><h3 id=常見誤區>常見誤區</h3><ul><li>GAN 訓練不穩定，需調參與技巧（如 label smoothing、gradient penalty）</li><li>VAE 生成樣本模糊，需調整潛在空間維度</li><li>Diffusion 推理慢，可用 DDIM、Latent Diffusion 加速</li><li>Flow-based 模型參數多，訓練成本高</li></ul><hr><h2 id=面試熱點與經典問題>面試熱點與經典問題</h2><table><thead><tr><th>主題</th><th>常見問題</th></tr></thead><tbody><tr><td>GAN</td><td>損失函數推導？mode collapse？</td></tr><tr><td>VAE</td><td>ELBO 結構與 KL 散度作用？</td></tr><tr><td>Diffusion</td><td>正向/反向過程數學原理？</td></tr><tr><td>Flow-based</td><td>可逆變換如何設計？</td></tr><tr><td>ControlNet</td><td>如何提升生成可控性？</td></tr></tbody></table><hr><h2 id=使用注意事項>使用注意事項</h2><ul><li>生成模型需大量資料與算力，建議用預訓練權重微調</li><li>GAN/VAE/Diffusion 各有優缺點，根據任務選擇</li><li>訓練過程需監控生成品質與多樣性</li></ul><hr><h2 id=延伸閱讀與資源>延伸閱讀與資源</h2><ul><li><a href=https://arxiv.org/abs/1406.2661>GAN 原論文</a></li><li><a href=https://arxiv.org/abs/1312.6114>VAE 原論文</a></li><li><a href=https://arxiv.org/abs/1807.03039>Glow: Flow-based Model</a></li><li><a href=https://arxiv.org/abs/2112.10752>Stable Diffusion 論文</a></li><li><a href=https://arxiv.org/abs/2302.05543>ControlNet 論文</a></li></ul><hr><h2 id=經典面試題與解法提示>經典面試題與解法提示</h2><ol><li>GAN 損失函數與訓練技巧？</li><li>VAE 的 ELBO 推導與 KL 項作用？</li><li>Diffusion Model 的正向/反向過程？</li><li>Flow-based Model 如何保證可逆？</li><li>ControlNet 如何提升可控性？</li><li>生成模型如何評估品質？</li><li>GAN mode collapse 如何解決？</li><li>Diffusion 推理加速方法？</li><li>VAE 潛在空間設計原則？</li><li>如何用 Python 實作簡單 GAN/VAE？</li></ol><hr><h2 id=結語>結語</h2><p>生成模型是 AI 創造力的核心。熟悉自回歸、VAE、GAN、Diffusion、Flow-based 與 ControlNet，能讓你在影像、語音、文本生成等領域發揮深度學習威力。下一章將進入正規化與訓練技巧，敬請期待！</p></div><div class=article-tags><div class=tags><span class=tag>VAE</span>
<span class=tag>GAN</span>
<span class=tag>Diffusion</span>
<span class=tag>Flow-based</span>
<span class=tag>ControlNet</span></div></div><footer class=article-footer><a href=/portfolio/articles/others/machine-learning/ class=back-link>← Back to Machine Learning</a></footer></article></main><footer class=site-footer><p>&copy; 2026 YuHan Jhou. All rights reserved.</p></footer></div></div><script src=https://yu-codes.github.io/portfolio/js/theme.js defer></script><script src=https://yu-codes.github.io/portfolio/js/roadmap.js defer></script><script src=https://yu-codes.github.io/portfolio/js/parallax.js defer></script><script src=https://yu-codes.github.io/portfolio/js/page-transition.js defer></script></body></html>