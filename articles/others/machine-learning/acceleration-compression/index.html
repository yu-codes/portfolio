<!doctype html><html lang=en class=html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>加速與壓縮實戰：混合精度、知識蒸餾、量化、推論優化與邊緣部署 - Yu's Portfolio & Learning Hub</title><meta name=description content="深度學習模型越來越大，推論與訓練的效率、資源消耗與部署成為關鍵挑戰。本章將深入混合精度（AMP）、梯度累積、知識蒸餾、量化感知訓練、TensorRT/ONNX Runtime、Flash-Attention、xFormers、Edge AI 部署與 Streaming 生成，結合理論、實作、應用場景、面試熱點與常見誤區，幫助你打造高效能深度學習系統。
混合精度 (AMP) 與梯度累積 混合精度訓練（Automatic Mixed Precision, AMP） 結合 float16/bfloat16 與 float32，提升訓練速度、降低顯存 需注意數值穩定性，常用於大模型 import torch scaler = torch.cuda.amp.GradScaler() for data, target in dataloader: optimizer.zero_grad() with torch.cuda.amp.autocast(): output = model(data) loss = loss_fn(output, target) scaler.scale(loss).backward() scaler.step(optimizer) scaler.update() 梯度累積 多個 mini-batch 累積梯度再更新參數，等效於大 batch 訓練 解決顯存不足問題 Knowledge Distillation, Quantization-Aware Training 知識蒸餾（Knowledge Distillation） 用大模型（Teacher）指導小模型（Student）學習 soft label 提升小模型表現，常用於壓縮與部署 import torch.nn.functional as F teacher_logits = torch.randn(8, 10) student_logits = torch.randn(8, 10) T = 2.0 # 溫度 loss = F.kl_div( F.log_softmax(student_logits / T, dim=1), F.softmax(teacher_logits / T, dim=1), reduction='batchmean' ) * (T * T) 量化感知訓練（Quantization-Aware Training, QAT） 在訓練時模擬低精度（如 int8），提升推論效率 支援 PyTorch、TensorFlow 等主流框架 TensorRT / ONNX Runtime、Flash-Attention / xFormers TensorRT / ONNX Runtime TensorRT：NVIDIA 推出的推論加速引擎，支援 FP16/INT8 ONNX Runtime：跨平台推論，支援多種硬體與優化 Flash-Attention / xFormers Flash-Attention：高效計算長序列 Self-Attention，降低記憶體與計算量 xFormers：Meta 開源高效 Transformer 組件庫 Edge 部署 & Streaming 生成 Edge AI 部署 量化、裁剪、知識蒸餾等技術壓縮模型，適合手機、IoT、嵌入式設備 工具：TensorRT、ONNX、TFLite Streaming 生成 分段生成長序列，降低延遲與記憶體需求 應用：語音合成、長文本生成 理論直覺、應用場景與常見誤區 應用場景 大模型訓練與推論加速、邊緣設備部署、低延遲應用、資源受限場景 常見誤區 混合精度未檢查數值穩定性，導致 NaN 量化後精度下降未調整 QAT 知識蒸餾忽略溫度設置，效果不佳 Edge 部署未考慮硬體兼容性 面試熱點與經典問題 主題 常見問題 AMP 原理與數值風險？ 知識蒸餾 Teacher/Student 設計？ 量化 QAT 與 Post-training 差異？ TensorRT/ONNX 如何加速推論？ Flash-Attention 如何降低複雜度？ Edge AI 部署挑戰與解法？ 使用注意事項 AMP、QAT、蒸餾等需根據任務與硬體調整 推論優化需測試多種引擎與格式 Edge 部署需考慮模型大小、延遲與功耗 延伸閱讀與資源 PyTorch AMP 官方文件 TensorRT 官方文件 ONNX Runtime FlashAttention 論文 Knowledge Distillation 論文 經典面試題與解法提示 AMP 的原理與數值風險？ 知識蒸餾如何設計 Teacher/Student？ QAT 與 Post-training Quantization 差異？ TensorRT/ONNX 如何加速推論？ Flash-Attention 計算複雜度與優勢？ Edge AI 部署常見挑戰？ Streaming 生成的應用與限制？ 如何用 Python 實作 AMP/QAT？ 量化後精度下降如何調整？ 推論優化與壓縮技術如何組合應用？ 結語 加速與壓縮是深度學習落地的關鍵。熟悉 AMP、知識蒸餾、量化、推論優化與 Edge 部署，能讓你打造高效能、低資源消耗的深度學習系統。下一章將進入多模態與視覺語言模型，敬請期待！
"><meta property="og:title" content="加速與壓縮實戰：混合精度、知識蒸餾、量化、推論優化與邊緣部署"><meta property="og:description" content="深度學習模型越來越大，推論與訓練的效率、資源消耗與部署成為關鍵挑戰。本章將深入混合精度（AMP）、梯度累積、知識蒸餾、量化感知訓練、TensorRT/ONNX Runtime、Flash-Attention、xFormers、Edge AI 部署與 Streaming 生成，結合理論、實作、應用場景、面試熱點與常見誤區，幫助你打造高效能深度學習系統。
混合精度 (AMP) 與梯度累積 混合精度訓練（Automatic Mixed Precision, AMP） 結合 float16/bfloat16 與 float32，提升訓練速度、降低顯存 需注意數值穩定性，常用於大模型 import torch scaler = torch.cuda.amp.GradScaler() for data, target in dataloader: optimizer.zero_grad() with torch.cuda.amp.autocast(): output = model(data) loss = loss_fn(output, target) scaler.scale(loss).backward() scaler.step(optimizer) scaler.update() 梯度累積 多個 mini-batch 累積梯度再更新參數，等效於大 batch 訓練 解決顯存不足問題 Knowledge Distillation, Quantization-Aware Training 知識蒸餾（Knowledge Distillation） 用大模型（Teacher）指導小模型（Student）學習 soft label 提升小模型表現，常用於壓縮與部署 import torch.nn.functional as F teacher_logits = torch.randn(8, 10) student_logits = torch.randn(8, 10) T = 2.0 # 溫度 loss = F.kl_div( F.log_softmax(student_logits / T, dim=1), F.softmax(teacher_logits / T, dim=1), reduction='batchmean' ) * (T * T) 量化感知訓練（Quantization-Aware Training, QAT） 在訓練時模擬低精度（如 int8），提升推論效率 支援 PyTorch、TensorFlow 等主流框架 TensorRT / ONNX Runtime、Flash-Attention / xFormers TensorRT / ONNX Runtime TensorRT：NVIDIA 推出的推論加速引擎，支援 FP16/INT8 ONNX Runtime：跨平台推論，支援多種硬體與優化 Flash-Attention / xFormers Flash-Attention：高效計算長序列 Self-Attention，降低記憶體與計算量 xFormers：Meta 開源高效 Transformer 組件庫 Edge 部署 & Streaming 生成 Edge AI 部署 量化、裁剪、知識蒸餾等技術壓縮模型，適合手機、IoT、嵌入式設備 工具：TensorRT、ONNX、TFLite Streaming 生成 分段生成長序列，降低延遲與記憶體需求 應用：語音合成、長文本生成 理論直覺、應用場景與常見誤區 應用場景 大模型訓練與推論加速、邊緣設備部署、低延遲應用、資源受限場景 常見誤區 混合精度未檢查數值穩定性，導致 NaN 量化後精度下降未調整 QAT 知識蒸餾忽略溫度設置，效果不佳 Edge 部署未考慮硬體兼容性 面試熱點與經典問題 主題 常見問題 AMP 原理與數值風險？ 知識蒸餾 Teacher/Student 設計？ 量化 QAT 與 Post-training 差異？ TensorRT/ONNX 如何加速推論？ Flash-Attention 如何降低複雜度？ Edge AI 部署挑戰與解法？ 使用注意事項 AMP、QAT、蒸餾等需根據任務與硬體調整 推論優化需測試多種引擎與格式 Edge 部署需考慮模型大小、延遲與功耗 延伸閱讀與資源 PyTorch AMP 官方文件 TensorRT 官方文件 ONNX Runtime FlashAttention 論文 Knowledge Distillation 論文 經典面試題與解法提示 AMP 的原理與數值風險？ 知識蒸餾如何設計 Teacher/Student？ QAT 與 Post-training Quantization 差異？ TensorRT/ONNX 如何加速推論？ Flash-Attention 計算複雜度與優勢？ Edge AI 部署常見挑戰？ Streaming 生成的應用與限制？ 如何用 Python 實作 AMP/QAT？ 量化後精度下降如何調整？ 推論優化與壓縮技術如何組合應用？ 結語 加速與壓縮是深度學習落地的關鍵。熟悉 AMP、知識蒸餾、量化、推論優化與 Edge 部署，能讓你打造高效能、低資源消耗的深度學習系統。下一章將進入多模態與視覺語言模型，敬請期待！
"><meta property="og:url" content="https://yu-codes.github.io/portfolio/articles/others/machine-learning/acceleration-compression/"><link rel=canonical href=https://yu-codes.github.io/portfolio/articles/others/machine-learning/acceleration-compression/><link rel=stylesheet href=https://yu-codes.github.io/portfolio/css/main.css></head><body class=body><div class=container><aside class=sidebar><div class=sidebar-header><h1 class=name>Yu</h1><p class=tagline>Developer, dreamer, debugger.</p></div><nav class=sidebar-nav><a href=https://yu-codes.github.io/portfolio/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M3 9l9-7 9 7v11a2 2 0 01-2 2H5a2 2 0 01-2-2z"/><polyline points="9 22 9 12 15 12 15 22"/></svg>
<span>HOME</span>
</a><a href=https://yu-codes.github.io/portfolio/articles/ class="nav-item active"><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5.0 016.5 17H20"/><path d="M6.5 2H20v20H6.5A2.5 2.5.0 014 19.5v-15A2.5 2.5.0 016.5 2z"/></svg>
<span>ARTICLES</span>
</a><a href=https://yu-codes.github.io/portfolio/resume/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="12" y1="11" x2="12" y2="17"/><line x1="9" y1="14" x2="15" y2="14"/></svg>
<span>RESUME</span>
</a><a href=https://yu-codes.github.io/portfolio/projects/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="3" width="8" height="8"/><rect x="13" y="3" width="8" height="8"/><rect x="3" y="13" width="8" height="8"/><rect x="13" y="13" width="8" height="8"/></svg>
<span>PROJECTS</span>
</a><a href=https://yu-codes.github.io/portfolio/archives/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
<span>ARCHIVES</span></a></nav><div class=sidebar-footer><div class=controls><button class="control-btn theme-toggle" title="Toggle theme (light/dark)" aria-label="Toggle theme">
<svg class="icon-sun" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".25"/></svg>
<svg class="icon-moon" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".25"/></svg>
</button>
<button class="control-btn lang-toggle" title="Toggle language" aria-label="Toggle language">
<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"/><path d="M2 12h20"/><path d="M12 2a15.3 15.3.0 014 10 15.3 15.3.0 01-4 10A15.3 15.3.0 018 12a15.3 15.3.0 014-10z"/></svg></button></div><div class=social-links><a href=https://github.com/yu-codes target=_blank rel="noopener noreferrer" class=social-link title=GitHub><svg viewBox="0 0 24 24" fill="currentColor"><path d="M12 0C5.374.0.0 5.373.0 12c0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931.0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176.0.0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221.0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/></svg>
</a><a href=mailto:dylan.jhou1120@gmail.com class=social-link title=Email><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div></div></aside><div class=main-content><div class=topbar><div class=breadcrumb><a href=https://yu-codes.github.io/portfolio/>HOME</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/articles/>ARTICLES</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/articles/others/>Others</a><span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/articles/others/machine-learning/>Machine Learning</a><span class=separator>&#8250;</span>
<span>加速與壓縮實戰：混合精度、知識蒸餾、量化、推論優化與邊緣部署</span></div></div><main class=content-area><article class=article-content><header class=article-header><h1>加速與壓縮實戰：混合精度、知識蒸餾、量化、推論優化與邊緣部署</h1><div class=article-meta><span class=article-author><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20 21v-2a4 4 0 00-4-4H8a4 4 0 00-4 4v2"/><circle cx="12" cy="7" r="4"/></svg>
Yu-Han Jhou
</span><span class=article-updated><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>
Last updated: 2025-03-09</span></div></header><div class=article-body><p>深度學習模型越來越大，推論與訓練的效率、資源消耗與部署成為關鍵挑戰。本章將深入混合精度（AMP）、梯度累積、知識蒸餾、量化感知訓練、TensorRT/ONNX Runtime、Flash-Attention、xFormers、Edge AI 部署與 Streaming 生成，結合理論、實作、應用場景、面試熱點與常見誤區，幫助你打造高效能深度學習系統。</p><hr><nav class=article-toc><span class=toc-title>Table of Contents</span><nav id=TableOfContents><ul><li><a href=#混合精度-amp-與梯度累積>混合精度 (AMP) 與梯度累積</a><ul><li><a href=#混合精度訓練automatic-mixed-precision-amp>混合精度訓練（Automatic Mixed Precision, AMP）</a></li><li><a href=#梯度累積>梯度累積</a></li></ul></li><li><a href=#knowledge-distillation-quantization-aware-training>Knowledge Distillation, Quantization-Aware Training</a><ul><li><a href=#知識蒸餾knowledge-distillation>知識蒸餾（Knowledge Distillation）</a></li><li><a href=#量化感知訓練quantization-aware-training-qat>量化感知訓練（Quantization-Aware Training, QAT）</a></li></ul></li><li><a href=#tensorrt--onnx-runtimeflash-attention--xformers>TensorRT / ONNX Runtime、Flash-Attention / xFormers</a><ul><li><a href=#tensorrt--onnx-runtime>TensorRT / ONNX Runtime</a></li><li><a href=#flash-attention--xformers>Flash-Attention / xFormers</a></li></ul></li><li><a href=#edge-部署--streaming-生成>Edge 部署 & Streaming 生成</a><ul><li><a href=#edge-ai-部署>Edge AI 部署</a></li><li><a href=#streaming-生成>Streaming 生成</a></li></ul></li><li><a href=#理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</a><ul><li><a href=#應用場景>應用場景</a></li><li><a href=#常見誤區>常見誤區</a></li></ul></li><li><a href=#面試熱點與經典問題>面試熱點與經典問題</a></li><li><a href=#使用注意事項>使用注意事項</a></li><li><a href=#延伸閱讀與資源>延伸閱讀與資源</a></li><li><a href=#經典面試題與解法提示>經典面試題與解法提示</a></li><li><a href=#結語>結語</a></li></ul></nav></nav><h2 id=混合精度-amp-與梯度累積>混合精度 (AMP) 與梯度累積</h2><h3 id=混合精度訓練automatic-mixed-precision-amp>混合精度訓練（Automatic Mixed Precision, AMP）</h3><ul><li>結合 float16/bfloat16 與 float32，提升訓練速度、降低顯存</li><li>需注意數值穩定性，常用於大模型</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span>scaler <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>amp<span style=color:#f92672>.</span>GradScaler()
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> data, target <span style=color:#f92672>in</span> dataloader:
</span></span><span style=display:flex><span>    optimizer<span style=color:#f92672>.</span>zero_grad()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>with</span> torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>amp<span style=color:#f92672>.</span>autocast():
</span></span><span style=display:flex><span>        output <span style=color:#f92672>=</span> model(data)
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> loss_fn(output, target)
</span></span><span style=display:flex><span>    scaler<span style=color:#f92672>.</span>scale(loss)<span style=color:#f92672>.</span>backward()
</span></span><span style=display:flex><span>    scaler<span style=color:#f92672>.</span>step(optimizer)
</span></span><span style=display:flex><span>    scaler<span style=color:#f92672>.</span>update()
</span></span></code></pre></div><h3 id=梯度累積>梯度累積</h3><ul><li>多個 mini-batch 累積梯度再更新參數，等效於大 batch 訓練</li><li>解決顯存不足問題</li></ul><hr><h2 id=knowledge-distillation-quantization-aware-training>Knowledge Distillation, Quantization-Aware Training</h2><h3 id=知識蒸餾knowledge-distillation>知識蒸餾（Knowledge Distillation）</h3><ul><li>用大模型（Teacher）指導小模型（Student）學習 soft label</li><li>提升小模型表現，常用於壓縮與部署</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn.functional <span style=color:#66d9ef>as</span> F
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>teacher_logits <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>8</span>, <span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>student_logits <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>8</span>, <span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>T <span style=color:#f92672>=</span> <span style=color:#ae81ff>2.0</span>  <span style=color:#75715e># 溫度</span>
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>kl_div(
</span></span><span style=display:flex><span>    F<span style=color:#f92672>.</span>log_softmax(student_logits <span style=color:#f92672>/</span> T, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>    F<span style=color:#f92672>.</span>softmax(teacher_logits <span style=color:#f92672>/</span> T, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>    reduction<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;batchmean&#39;</span>
</span></span><span style=display:flex><span>) <span style=color:#f92672>*</span> (T <span style=color:#f92672>*</span> T)
</span></span></code></pre></div><h3 id=量化感知訓練quantization-aware-training-qat>量化感知訓練（Quantization-Aware Training, QAT）</h3><ul><li>在訓練時模擬低精度（如 int8），提升推論效率</li><li>支援 PyTorch、TensorFlow 等主流框架</li></ul><hr><h2 id=tensorrt--onnx-runtimeflash-attention--xformers>TensorRT / ONNX Runtime、Flash-Attention / xFormers</h2><h3 id=tensorrt--onnx-runtime>TensorRT / ONNX Runtime</h3><ul><li>TensorRT：NVIDIA 推出的推論加速引擎，支援 FP16/INT8</li><li>ONNX Runtime：跨平台推論，支援多種硬體與優化</li></ul><h3 id=flash-attention--xformers>Flash-Attention / xFormers</h3><ul><li>Flash-Attention：高效計算長序列 Self-Attention，降低記憶體與計算量</li><li>xFormers：Meta 開源高效 Transformer 組件庫</li></ul><hr><h2 id=edge-部署--streaming-生成>Edge 部署 & Streaming 生成</h2><h3 id=edge-ai-部署>Edge AI 部署</h3><ul><li>量化、裁剪、知識蒸餾等技術壓縮模型，適合手機、IoT、嵌入式設備</li><li>工具：TensorRT、ONNX、TFLite</li></ul><h3 id=streaming-生成>Streaming 生成</h3><ul><li>分段生成長序列，降低延遲與記憶體需求</li><li>應用：語音合成、長文本生成</li></ul><hr><h2 id=理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</h2><h3 id=應用場景>應用場景</h3><ul><li>大模型訓練與推論加速、邊緣設備部署、低延遲應用、資源受限場景</li></ul><h3 id=常見誤區>常見誤區</h3><ul><li>混合精度未檢查數值穩定性，導致 NaN</li><li>量化後精度下降未調整 QAT</li><li>知識蒸餾忽略溫度設置，效果不佳</li><li>Edge 部署未考慮硬體兼容性</li></ul><hr><h2 id=面試熱點與經典問題>面試熱點與經典問題</h2><table><thead><tr><th>主題</th><th>常見問題</th></tr></thead><tbody><tr><td>AMP</td><td>原理與數值風險？</td></tr><tr><td>知識蒸餾</td><td>Teacher/Student 設計？</td></tr><tr><td>量化</td><td>QAT 與 Post-training 差異？</td></tr><tr><td>TensorRT/ONNX</td><td>如何加速推論？</td></tr><tr><td>Flash-Attention</td><td>如何降低複雜度？</td></tr><tr><td>Edge AI</td><td>部署挑戰與解法？</td></tr></tbody></table><hr><h2 id=使用注意事項>使用注意事項</h2><ul><li>AMP、QAT、蒸餾等需根據任務與硬體調整</li><li>推論優化需測試多種引擎與格式</li><li>Edge 部署需考慮模型大小、延遲與功耗</li></ul><hr><h2 id=延伸閱讀與資源>延伸閱讀與資源</h2><ul><li><a href=https://pytorch.org/docs/stable/amp.html>PyTorch AMP 官方文件</a></li><li><a href=https://docs.nvidia.com/deeplearning/tensorrt/>TensorRT 官方文件</a></li><li><a href=https://onnxruntime.ai/>ONNX Runtime</a></li><li><a href=https://arxiv.org/abs/2205.14135>FlashAttention 論文</a></li><li><a href=https://arxiv.org/abs/1503.02531>Knowledge Distillation 論文</a></li></ul><hr><h2 id=經典面試題與解法提示>經典面試題與解法提示</h2><ol><li>AMP 的原理與數值風險？</li><li>知識蒸餾如何設計 Teacher/Student？</li><li>QAT 與 Post-training Quantization 差異？</li><li>TensorRT/ONNX 如何加速推論？</li><li>Flash-Attention 計算複雜度與優勢？</li><li>Edge AI 部署常見挑戰？</li><li>Streaming 生成的應用與限制？</li><li>如何用 Python 實作 AMP/QAT？</li><li>量化後精度下降如何調整？</li><li>推論優化與壓縮技術如何組合應用？</li></ol><hr><h2 id=結語>結語</h2><p>加速與壓縮是深度學習落地的關鍵。熟悉 AMP、知識蒸餾、量化、推論優化與 Edge 部署，能讓你打造高效能、低資源消耗的深度學習系統。下一章將進入多模態與視覺語言模型，敬請期待！</p></div><footer class=article-footer><a href=/portfolio/articles/others/machine-learning/ class=back-link>← Back to Machine Learning</a></footer></article></main><footer class=site-footer><p>&copy; 2026 YuHan Jhou. All rights reserved.</p></footer></div></div><script src=https://yu-codes.github.io/portfolio/js/theme.js defer></script><script src=https://yu-codes.github.io/portfolio/js/roadmap.js defer></script><script src=https://yu-codes.github.io/portfolio/js/parallax.js defer></script><script src=https://yu-codes.github.io/portfolio/js/page-transition.js defer></script></body></html>