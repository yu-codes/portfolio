<!doctype html><html lang=en class=html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>容器化與 Kubernetes：Pod 資源、GPU 調度、HPA/VPA/Autoscaler 全攻略 - Yu's Portfolio & Learning Hub</title><meta name=description content='容器化與 Kubernetes 是現代 AI 與大規模系統部署的基石。本章將深入 Pod Spec 資源限制、Node Selector、GPU 調度（NVIDIA Device Plugin, Share-GPU）、自動擴縮（HPA/VPA/Cluster Autoscaler），結合理論、實作、面試熱點與常見誤區，幫助你打造高效可擴展的運算平台。
Pod Spec：資源限制 & Node Selector 每個 Pod 可設置 CPU/記憶體 requests/limits，防止資源爭用 Node Selector/Node Affinity 控制 Pod 部署到特定節點（如 GPU/SSD 節點） 建議設置 liveness/readiness probe，提升服務穩定性 apiVersion: v1 kind: Pod metadata: name: ml-infer spec: containers: - name: infer image: myrepo/ml-infer:latest resources: requests: cpu: "2" memory: "4Gi" limits: cpu: "4" memory: "8Gi" livenessProbe: httpGet: path: /health port: 8080 nodeSelector: gpu: "true" GPU 調度 (NVIDIA Device Plugin, Share-GPU) NVIDIA Device Plugin 支援 GPU 自動發現與分配 支援 GPU requests/limits，Pod 可指定需幾張卡 Share-GPU（如 MIG、KubeShare）支援多 Pod 共用單張 GPU 建議監控 GPU 使用率，防止資源閒置或爭用 resources: limits: nvidia.com/gpu: 1 HPA / VPA / Cluster Autoscaler HPA（Horizontal Pod Autoscaler） 根據 CPU/GPU/自訂指標自動調整 Pod 數量 適合流量波動大、需自動擴縮的服務 VPA（Vertical Pod Autoscaler） 根據歷史資源使用自動調整 Pod requests/limits 適合長期運行、資源需求變化大的任務 Cluster Autoscaler 根據 Pod 排程需求自動擴縮節點數量 支援多雲、混合雲環境 設計實戰與最佳實踐 建議結合 HPA+VPA+Cluster Autoscaler，兼顧彈性與成本 GPU 任務建議設置 node affinity 與資源限制 定期監控資源使用，調整 requests/limits 多租戶環境建議設置 namespace 資源配額 理論直覺、應用場景與常見誤區 應用場景 AI 推論服務、分散式訓練、批次 ETL、彈性 API 平台 常見誤區 Pod 未設資源限制，導致資源爭用或 OOM GPU 調度未設 affinity，Pod 排程失敗 HPA/VPA 參數設置不當，擴縮不及時 Cluster Autoscaler 未設預留，節點啟動延遲 面試熱點與經典問題 主題 常見問題 Pod 資源限制 如何設計？ GPU 調度 NVIDIA Plugin/Share-GPU 原理？ HPA/VPA 適用場景與設計細節？ Cluster Autoscaler 如何自動擴縮？ Node Selector 有何作用與限制？ 使用注意事項 Pod/Node 資源建議定期審查與調整 GPU 調度需結合監控與資源隔離 HPA/VPA/Autoscaler 需根據業務特性調參 延伸閱讀與資源 Kubernetes 官方文件 NVIDIA Device Plugin KubeShare GPU Sharing HPA 官方文件 VPA 官方文件 Cluster Autoscaler 經典面試題與解法提示 Pod 資源 requests/limits 設計原則？ GPU 調度與資源隔離如何實現？ HPA/VPA/Cluster Autoscaler 差異與組合？ Node Selector/Affinity 實作細節？ 多租戶資源配額如何設計？ 如何用 YAML 實作 GPU 調度？ HPA/VPA 監控指標如何選擇？ Cluster Autoscaler 啟動延遲如何優化？ GPU 資源監控與告警？ 容器化部署常見踩坑與解法？ 結語 容器化與 Kubernetes 是現代 AI 與大規模系統部署的基石。熟悉 Pod 資源、GPU 調度、HPA/VPA/Autoscaler，能讓你打造高效可擴展的運算平台。下一章將進入 Kubeflow 與生態系，敬請期待！
'><meta property="og:title" content="容器化與 Kubernetes：Pod 資源、GPU 調度、HPA/VPA/Autoscaler 全攻略"><meta property="og:description" content='容器化與 Kubernetes 是現代 AI 與大規模系統部署的基石。本章將深入 Pod Spec 資源限制、Node Selector、GPU 調度（NVIDIA Device Plugin, Share-GPU）、自動擴縮（HPA/VPA/Cluster Autoscaler），結合理論、實作、面試熱點與常見誤區，幫助你打造高效可擴展的運算平台。
Pod Spec：資源限制 & Node Selector 每個 Pod 可設置 CPU/記憶體 requests/limits，防止資源爭用 Node Selector/Node Affinity 控制 Pod 部署到特定節點（如 GPU/SSD 節點） 建議設置 liveness/readiness probe，提升服務穩定性 apiVersion: v1 kind: Pod metadata: name: ml-infer spec: containers: - name: infer image: myrepo/ml-infer:latest resources: requests: cpu: "2" memory: "4Gi" limits: cpu: "4" memory: "8Gi" livenessProbe: httpGet: path: /health port: 8080 nodeSelector: gpu: "true" GPU 調度 (NVIDIA Device Plugin, Share-GPU) NVIDIA Device Plugin 支援 GPU 自動發現與分配 支援 GPU requests/limits，Pod 可指定需幾張卡 Share-GPU（如 MIG、KubeShare）支援多 Pod 共用單張 GPU 建議監控 GPU 使用率，防止資源閒置或爭用 resources: limits: nvidia.com/gpu: 1 HPA / VPA / Cluster Autoscaler HPA（Horizontal Pod Autoscaler） 根據 CPU/GPU/自訂指標自動調整 Pod 數量 適合流量波動大、需自動擴縮的服務 VPA（Vertical Pod Autoscaler） 根據歷史資源使用自動調整 Pod requests/limits 適合長期運行、資源需求變化大的任務 Cluster Autoscaler 根據 Pod 排程需求自動擴縮節點數量 支援多雲、混合雲環境 設計實戰與最佳實踐 建議結合 HPA+VPA+Cluster Autoscaler，兼顧彈性與成本 GPU 任務建議設置 node affinity 與資源限制 定期監控資源使用，調整 requests/limits 多租戶環境建議設置 namespace 資源配額 理論直覺、應用場景與常見誤區 應用場景 AI 推論服務、分散式訓練、批次 ETL、彈性 API 平台 常見誤區 Pod 未設資源限制，導致資源爭用或 OOM GPU 調度未設 affinity，Pod 排程失敗 HPA/VPA 參數設置不當，擴縮不及時 Cluster Autoscaler 未設預留，節點啟動延遲 面試熱點與經典問題 主題 常見問題 Pod 資源限制 如何設計？ GPU 調度 NVIDIA Plugin/Share-GPU 原理？ HPA/VPA 適用場景與設計細節？ Cluster Autoscaler 如何自動擴縮？ Node Selector 有何作用與限制？ 使用注意事項 Pod/Node 資源建議定期審查與調整 GPU 調度需結合監控與資源隔離 HPA/VPA/Autoscaler 需根據業務特性調參 延伸閱讀與資源 Kubernetes 官方文件 NVIDIA Device Plugin KubeShare GPU Sharing HPA 官方文件 VPA 官方文件 Cluster Autoscaler 經典面試題與解法提示 Pod 資源 requests/limits 設計原則？ GPU 調度與資源隔離如何實現？ HPA/VPA/Cluster Autoscaler 差異與組合？ Node Selector/Affinity 實作細節？ 多租戶資源配額如何設計？ 如何用 YAML 實作 GPU 調度？ HPA/VPA 監控指標如何選擇？ Cluster Autoscaler 啟動延遲如何優化？ GPU 資源監控與告警？ 容器化部署常見踩坑與解法？ 結語 容器化與 Kubernetes 是現代 AI 與大規模系統部署的基石。熟悉 Pod 資源、GPU 調度、HPA/VPA/Autoscaler，能讓你打造高效可擴展的運算平台。下一章將進入 Kubeflow 與生態系，敬請期待！
'><meta property="og:url" content="https://yu-codes.github.io/portfolio/articles/others/system-design/container-k8s/"><link rel=canonical href=https://yu-codes.github.io/portfolio/articles/others/system-design/container-k8s/><link rel=stylesheet href=https://yu-codes.github.io/portfolio/css/main.css></head><body class=body><div class=container><aside class=sidebar><div class=sidebar-header><h1 class=name>Yu</h1><p class=tagline>Developer, dreamer, debugger.</p></div><nav class=sidebar-nav><a href=https://yu-codes.github.io/portfolio/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M3 9l9-7 9 7v11a2 2 0 01-2 2H5a2 2 0 01-2-2z"/><polyline points="9 22 9 12 15 12 15 22"/></svg>
<span>HOME</span>
</a><a href=https://yu-codes.github.io/portfolio/articles/ class="nav-item active"><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5.0 016.5 17H20"/><path d="M6.5 2H20v20H6.5A2.5 2.5.0 014 19.5v-15A2.5 2.5.0 016.5 2z"/></svg>
<span>ARTICLES</span>
</a><a href=https://yu-codes.github.io/portfolio/resume/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="12" y1="11" x2="12" y2="17"/><line x1="9" y1="14" x2="15" y2="14"/></svg>
<span>RESUME</span>
</a><a href=https://yu-codes.github.io/portfolio/projects/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="3" width="8" height="8"/><rect x="13" y="3" width="8" height="8"/><rect x="3" y="13" width="8" height="8"/><rect x="13" y="13" width="8" height="8"/></svg>
<span>PROJECTS</span>
</a><a href=https://yu-codes.github.io/portfolio/archives/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
<span>ARCHIVES</span></a></nav><div class=sidebar-footer><div class=controls><button class="control-btn theme-toggle" title="Toggle theme (light/dark)" aria-label="Toggle theme">
<svg class="icon-sun" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".25"/></svg>
<svg class="icon-moon" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".25"/></svg>
</button>
<button class="control-btn lang-toggle" title="Toggle language" aria-label="Toggle language">
<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"/><path d="M2 12h20"/><path d="M12 2a15.3 15.3.0 014 10 15.3 15.3.0 01-4 10A15.3 15.3.0 018 12a15.3 15.3.0 014-10z"/></svg></button></div><div class=social-links><a href=https://github.com/yu-codes target=_blank rel="noopener noreferrer" class=social-link title=GitHub><svg viewBox="0 0 24 24" fill="currentColor"><path d="M12 0C5.374.0.0 5.373.0 12c0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931.0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176.0.0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221.0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/></svg>
</a><a href=mailto:dylan.jhou1120@gmail.com class=social-link title=Email><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div></div></aside><div class=main-content><div class=topbar><div class=breadcrumb><a href=https://yu-codes.github.io/portfolio/>HOME</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/articles/>ARTICLES</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/articles/others/>Others</a><span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/articles/others/system-design/>System Design</a><span class=separator>&#8250;</span>
<span>容器化與 Kubernetes：Pod 資源、GPU 調度、HPA/VPA/Autoscaler 全攻略</span></div></div><main class=content-area><article class=article-content><header class=article-header><h1>容器化與 Kubernetes：Pod 資源、GPU 調度、HPA/VPA/Autoscaler 全攻略</h1><div class=article-meta><span class=article-author><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20 21v-2a4 4 0 00-4-4H8a4 4 0 00-4 4v2"/><circle cx="12" cy="7" r="4"/></svg>
Yu-Han Jhou
</span><span class=article-updated><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>
Last updated: 2025-06-12</span></div></header><div class=article-body><p>容器化與 Kubernetes 是現代 AI 與大規模系統部署的基石。本章將深入 Pod Spec 資源限制、Node Selector、GPU 調度（NVIDIA Device Plugin, Share-GPU）、自動擴縮（HPA/VPA/Cluster Autoscaler），結合理論、實作、面試熱點與常見誤區，幫助你打造高效可擴展的運算平台。</p><hr><nav class=article-toc><span class=toc-title>Table of Contents</span><nav id=TableOfContents><ul><li><a href=#pod-spec資源限制--node-selector>Pod Spec：資源限制 & Node Selector</a></li><li><a href=#gpu-調度-nvidia-device-plugin-share-gpu>GPU 調度 (NVIDIA Device Plugin, Share-GPU)</a></li><li><a href=#hpa--vpa--cluster-autoscaler>HPA / VPA / Cluster Autoscaler</a><ul><li><a href=#hpahorizontal-pod-autoscaler>HPA（Horizontal Pod Autoscaler）</a></li><li><a href=#vpavertical-pod-autoscaler>VPA（Vertical Pod Autoscaler）</a></li><li><a href=#cluster-autoscaler>Cluster Autoscaler</a></li></ul></li><li><a href=#設計實戰與最佳實踐>設計實戰與最佳實踐</a></li><li><a href=#理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</a><ul><li><a href=#應用場景>應用場景</a></li><li><a href=#常見誤區>常見誤區</a></li></ul></li><li><a href=#面試熱點與經典問題>面試熱點與經典問題</a></li><li><a href=#使用注意事項>使用注意事項</a></li><li><a href=#延伸閱讀與資源>延伸閱讀與資源</a></li><li><a href=#經典面試題與解法提示>經典面試題與解法提示</a></li><li><a href=#結語>結語</a></li></ul></nav></nav><h2 id=pod-spec資源限制--node-selector>Pod Spec：資源限制 & Node Selector</h2><ul><li>每個 Pod 可設置 CPU/記憶體 requests/limits，防止資源爭用</li><li>Node Selector/Node Affinity 控制 Pod 部署到特定節點（如 GPU/SSD 節點）</li><li>建議設置 liveness/readiness probe，提升服務穩定性</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Pod</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>ml-infer</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>containers</span>:
</span></span><span style=display:flex><span>    - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>infer</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>image</span>: <span style=color:#ae81ff>myrepo/ml-infer:latest</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>requests</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>cpu</span>: <span style=color:#e6db74>&#34;2&#34;</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>memory</span>: <span style=color:#e6db74>&#34;4Gi&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>limits</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>cpu</span>: <span style=color:#e6db74>&#34;4&#34;</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>memory</span>: <span style=color:#e6db74>&#34;8Gi&#34;</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>livenessProbe</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>httpGet</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>path</span>: <span style=color:#ae81ff>/health</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>port</span>: <span style=color:#ae81ff>8080</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>nodeSelector</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>gpu</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span></code></pre></div><hr><h2 id=gpu-調度-nvidia-device-plugin-share-gpu>GPU 調度 (NVIDIA Device Plugin, Share-GPU)</h2><ul><li>NVIDIA Device Plugin 支援 GPU 自動發現與分配</li><li>支援 GPU requests/limits，Pod 可指定需幾張卡</li><li>Share-GPU（如 MIG、KubeShare）支援多 Pod 共用單張 GPU</li><li>建議監控 GPU 使用率，防止資源閒置或爭用</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>limits</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>nvidia.com/gpu</span>: <span style=color:#ae81ff>1</span>
</span></span></code></pre></div><hr><h2 id=hpa--vpa--cluster-autoscaler>HPA / VPA / Cluster Autoscaler</h2><h3 id=hpahorizontal-pod-autoscaler>HPA（Horizontal Pod Autoscaler）</h3><ul><li>根據 CPU/GPU/自訂指標自動調整 Pod 數量</li><li>適合流量波動大、需自動擴縮的服務</li></ul><h3 id=vpavertical-pod-autoscaler>VPA（Vertical Pod Autoscaler）</h3><ul><li>根據歷史資源使用自動調整 Pod requests/limits</li><li>適合長期運行、資源需求變化大的任務</li></ul><h3 id=cluster-autoscaler>Cluster Autoscaler</h3><ul><li>根據 Pod 排程需求自動擴縮節點數量</li><li>支援多雲、混合雲環境</li></ul><hr><h2 id=設計實戰與最佳實踐>設計實戰與最佳實踐</h2><ul><li>建議結合 HPA+VPA+Cluster Autoscaler，兼顧彈性與成本</li><li>GPU 任務建議設置 node affinity 與資源限制</li><li>定期監控資源使用，調整 requests/limits</li><li>多租戶環境建議設置 namespace 資源配額</li></ul><hr><h2 id=理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</h2><h3 id=應用場景>應用場景</h3><ul><li>AI 推論服務、分散式訓練、批次 ETL、彈性 API 平台</li></ul><h3 id=常見誤區>常見誤區</h3><ul><li>Pod 未設資源限制，導致資源爭用或 OOM</li><li>GPU 調度未設 affinity，Pod 排程失敗</li><li>HPA/VPA 參數設置不當，擴縮不及時</li><li>Cluster Autoscaler 未設預留，節點啟動延遲</li></ul><hr><h2 id=面試熱點與經典問題>面試熱點與經典問題</h2><table><thead><tr><th>主題</th><th>常見問題</th></tr></thead><tbody><tr><td>Pod 資源限制</td><td>如何設計？</td></tr><tr><td>GPU 調度</td><td>NVIDIA Plugin/Share-GPU 原理？</td></tr><tr><td>HPA/VPA</td><td>適用場景與設計細節？</td></tr><tr><td>Cluster Autoscaler</td><td>如何自動擴縮？</td></tr><tr><td>Node Selector</td><td>有何作用與限制？</td></tr></tbody></table><hr><h2 id=使用注意事項>使用注意事項</h2><ul><li>Pod/Node 資源建議定期審查與調整</li><li>GPU 調度需結合監控與資源隔離</li><li>HPA/VPA/Autoscaler 需根據業務特性調參</li></ul><hr><h2 id=延伸閱讀與資源>延伸閱讀與資源</h2><ul><li><a href=https://kubernetes.io/docs/home/>Kubernetes 官方文件</a></li><li><a href=https://github.com/NVIDIA/k8s-device-plugin>NVIDIA Device Plugin</a></li><li><a href=https://github.com/ICLUE/kubeshare>KubeShare GPU Sharing</a></li><li><a href=https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/>HPA 官方文件</a></li><li><a href=https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler>VPA 官方文件</a></li><li><a href=https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler>Cluster Autoscaler</a></li></ul><hr><h2 id=經典面試題與解法提示>經典面試題與解法提示</h2><ol><li>Pod 資源 requests/limits 設計原則？</li><li>GPU 調度與資源隔離如何實現？</li><li>HPA/VPA/Cluster Autoscaler 差異與組合？</li><li>Node Selector/Affinity 實作細節？</li><li>多租戶資源配額如何設計？</li><li>如何用 YAML 實作 GPU 調度？</li><li>HPA/VPA 監控指標如何選擇？</li><li>Cluster Autoscaler 啟動延遲如何優化？</li><li>GPU 資源監控與告警？</li><li>容器化部署常見踩坑與解法？</li></ol><hr><h2 id=結語>結語</h2><p>容器化與 Kubernetes 是現代 AI 與大規模系統部署的基石。熟悉 Pod 資源、GPU 調度、HPA/VPA/Autoscaler，能讓你打造高效可擴展的運算平台。下一章將進入 Kubeflow 與生態系，敬請期待！</p></div><div class=article-tags><div class=tags><span class=tag>kubernetes</span>
<span class=tag>containerization</span>
<span class=tag>gpu-scheduling</span></div></div><footer class=article-footer><a href=/portfolio/articles/others/system-design/ class=back-link>← Back to System Design</a></footer></article></main><footer class=site-footer><p>&copy; 2026 YuHan Jhou. All rights reserved.</p></footer></div></div><script src=https://yu-codes.github.io/portfolio/js/theme.js defer></script><script src=https://yu-codes.github.io/portfolio/js/roadmap.js defer></script><script src=https://yu-codes.github.io/portfolio/js/parallax.js defer></script><script src=https://yu-codes.github.io/portfolio/js/page-transition.js defer></script></body></html>