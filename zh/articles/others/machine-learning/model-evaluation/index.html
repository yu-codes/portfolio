<!doctype html><html lang=zh class=html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>模型評估與驗證全攻略：交叉驗證、分類/迴歸指標、資料洩漏與早停 - Yu's Portfolio & Learning Hub</title><meta name=description content='模型評估與驗證是機器學習流程中不可或缺的一環。正確的評估策略能幫助我們選擇最佳模型、避免過擬合、提升泛化能力。本章將深入交叉驗證策略、分類與迴歸指標、資料洩漏與早停技巧，結合理論、實作、面試熱點與常見誤區，讓你在專案與面試中都能精準評估模型表現。
交叉驗證策略 (K-Fold, Stratified, TimeSeriesSplit) K-Fold Cross-Validation 將資料分成 K 份，輪流用一份驗證，其餘訓練，平均結果。 適合資料量有限時提升評估穩定性。 Stratified K-Fold 分層抽樣，確保每折類別比例與原資料一致。 適合分類任務，避免類別不平衡影響。 TimeSeriesSplit 適合時間序列資料，保留時間順序，避免未來資料洩漏到過去。 from sklearn.model_selection import KFold, StratifiedKFold, TimeSeriesSplit X = [[i] for i in range(10)] y = [0, 1]*5 kf = KFold(n_splits=5) skf = StratifiedKFold(n_splits=2) tscv = TimeSeriesSplit(n_splits=3) for train, test in kf.split(X): print("KFold:", train, test) for train, test in skf.split(X, y): print("StratifiedKFold:", train, test) for train, test in tscv.split(X): print("TimeSeriesSplit:", train, test) 分類指標：Precision-Recall / ROC-AUC / F1 Precision, Recall, F1 Precision：預測為正的樣本中有多少是真的正。 Recall：所有正樣本中有多少被正確預測。 F1 Score：Precision 與 Recall 的調和平均。 ROC-AUC ROC 曲線：TPR vs FPR，AUC 為曲線下方面積。 適合不平衡資料，反映模型區分正負樣本能力。 from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score y_true = [0, 1, 1, 0, 1] y_pred = [0, 1, 0, 0, 1] y_prob = [0.1, 0.8, 0.4, 0.3, 0.9] print("Precision:", precision_score(y_true, y_pred)) print("Recall:", recall_score(y_true, y_pred)) print("F1:", f1_score(y_true, y_pred)) print("ROC-AUC:", roc_auc_score(y_true, y_prob)) 迴歸指標：MSE / MAE / R² 指標 公式 適用場景 直覺說明 MSE $\frac{1}{n}\sum(y_i-\hat{y}_i)^2$ 回歸 懲罰大誤差 MAE $\frac{1}{n}\sum y_i-\hat{y}_i $ R² $1-\frac{\sum(y_i-\hat{y}_i)^2}{\sum(y_i-\bar{y})^2}$ 回歸 解釋變異比例 from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score y_true = [3, -0.5, 2, 7] y_pred = [2.5, 0.0, 2, 8] print("MSE:", mean_squared_error(y_true, y_pred)) print("MAE:", mean_absolute_error(y_true, y_pred)) print("R²:", r2_score(y_true, y_pred)) Data Leakage & 早停 (Early Stopping) Data Leakage（資料洩漏） 訓練時不小心用到未來或驗證資料，導致評估過於樂觀。 常見於特徵工程、標準化、目標編碼時未分開處理。 Early Stopping（早停） 監控驗證集表現，若多輪未提升則提前停止訓練，防止過擬合。 常用於深度學習、Boosting 類模型。 from sklearn.ensemble import GradientBoostingClassifier gb = GradientBoostingClassifier(n_estimators=100, validation_fraction=0.1, n_iter_no_change=5) gb.fit(X, y) print("最佳迭代數:", gb.n_estimators_) 理論直覺、應用場景與常見誤區 應用場景 交叉驗證：模型選擇、調參、泛化能力評估 Precision-Recall：醫療、金融等高風險領域 ROC-AUC：不平衡分類、模型比較 Early Stopping：深度學習、Boosting 常見誤區 交叉驗證未分層，導致類別不平衡。 評估指標選錯，誤導模型選擇。 特徵工程未分開訓練/驗證集，產生資料洩漏。 早停監控訓練集而非驗證集，無法防止過擬合。 面試熱點與經典問題 主題 常見問題 交叉驗證 為何能提升泛化？K-Fold 與 Stratified 差異？ Precision/Recall 何時優先考慮？有何 trade-off？ ROC-AUC 如何解讀？何時不適用？ Data Leakage 常見來源？如何避免？ Early Stopping 如何設計？有何風險？ 使用注意事項 評估指標需根據任務選擇，避免單一指標誤導。 交叉驗證與特徵工程順序需正確，防止資料洩漏。 Early Stopping 須監控驗證集，並設合理 patience。 延伸閱讀與資源 StatQuest: Model Evaluation Scikit-learn Model Selection Early Stopping in Deep Learning 經典面試題與解法提示 K-Fold 與 Stratified K-Fold 差異？ Precision 與 Recall 何時優先考慮？ ROC-AUC 有哪些限制？ Data Leakage 常見來源與防範？ Early Stopping 如何設計與調參？ 交叉驗證如何提升泛化能力？ 何時用 MAE 而非 MSE？ R² 何時不適用？ 如何用 Python 畫 ROC 曲線？ 多指標綜合評估的策略？ 結語 模型評估與驗證是 ML 成敗關鍵。熟悉交叉驗證、分類/迴歸指標、資料洩漏與早停技巧，能讓你打造更可靠的模型並在面試中展現專業素養。下一章將進入正則化與泛化理論，敬請期待！
'><meta property="og:title" content="模型評估與驗證全攻略：交叉驗證、分類/迴歸指標、資料洩漏與早停"><meta property="og:description" content='模型評估與驗證是機器學習流程中不可或缺的一環。正確的評估策略能幫助我們選擇最佳模型、避免過擬合、提升泛化能力。本章將深入交叉驗證策略、分類與迴歸指標、資料洩漏與早停技巧，結合理論、實作、面試熱點與常見誤區，讓你在專案與面試中都能精準評估模型表現。
交叉驗證策略 (K-Fold, Stratified, TimeSeriesSplit) K-Fold Cross-Validation 將資料分成 K 份，輪流用一份驗證，其餘訓練，平均結果。 適合資料量有限時提升評估穩定性。 Stratified K-Fold 分層抽樣，確保每折類別比例與原資料一致。 適合分類任務，避免類別不平衡影響。 TimeSeriesSplit 適合時間序列資料，保留時間順序，避免未來資料洩漏到過去。 from sklearn.model_selection import KFold, StratifiedKFold, TimeSeriesSplit X = [[i] for i in range(10)] y = [0, 1]*5 kf = KFold(n_splits=5) skf = StratifiedKFold(n_splits=2) tscv = TimeSeriesSplit(n_splits=3) for train, test in kf.split(X): print("KFold:", train, test) for train, test in skf.split(X, y): print("StratifiedKFold:", train, test) for train, test in tscv.split(X): print("TimeSeriesSplit:", train, test) 分類指標：Precision-Recall / ROC-AUC / F1 Precision, Recall, F1 Precision：預測為正的樣本中有多少是真的正。 Recall：所有正樣本中有多少被正確預測。 F1 Score：Precision 與 Recall 的調和平均。 ROC-AUC ROC 曲線：TPR vs FPR，AUC 為曲線下方面積。 適合不平衡資料，反映模型區分正負樣本能力。 from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score y_true = [0, 1, 1, 0, 1] y_pred = [0, 1, 0, 0, 1] y_prob = [0.1, 0.8, 0.4, 0.3, 0.9] print("Precision:", precision_score(y_true, y_pred)) print("Recall:", recall_score(y_true, y_pred)) print("F1:", f1_score(y_true, y_pred)) print("ROC-AUC:", roc_auc_score(y_true, y_prob)) 迴歸指標：MSE / MAE / R² 指標 公式 適用場景 直覺說明 MSE $\frac{1}{n}\sum(y_i-\hat{y}_i)^2$ 回歸 懲罰大誤差 MAE $\frac{1}{n}\sum y_i-\hat{y}_i $ R² $1-\frac{\sum(y_i-\hat{y}_i)^2}{\sum(y_i-\bar{y})^2}$ 回歸 解釋變異比例 from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score y_true = [3, -0.5, 2, 7] y_pred = [2.5, 0.0, 2, 8] print("MSE:", mean_squared_error(y_true, y_pred)) print("MAE:", mean_absolute_error(y_true, y_pred)) print("R²:", r2_score(y_true, y_pred)) Data Leakage & 早停 (Early Stopping) Data Leakage（資料洩漏） 訓練時不小心用到未來或驗證資料，導致評估過於樂觀。 常見於特徵工程、標準化、目標編碼時未分開處理。 Early Stopping（早停） 監控驗證集表現，若多輪未提升則提前停止訓練，防止過擬合。 常用於深度學習、Boosting 類模型。 from sklearn.ensemble import GradientBoostingClassifier gb = GradientBoostingClassifier(n_estimators=100, validation_fraction=0.1, n_iter_no_change=5) gb.fit(X, y) print("最佳迭代數:", gb.n_estimators_) 理論直覺、應用場景與常見誤區 應用場景 交叉驗證：模型選擇、調參、泛化能力評估 Precision-Recall：醫療、金融等高風險領域 ROC-AUC：不平衡分類、模型比較 Early Stopping：深度學習、Boosting 常見誤區 交叉驗證未分層，導致類別不平衡。 評估指標選錯，誤導模型選擇。 特徵工程未分開訓練/驗證集，產生資料洩漏。 早停監控訓練集而非驗證集，無法防止過擬合。 面試熱點與經典問題 主題 常見問題 交叉驗證 為何能提升泛化？K-Fold 與 Stratified 差異？ Precision/Recall 何時優先考慮？有何 trade-off？ ROC-AUC 如何解讀？何時不適用？ Data Leakage 常見來源？如何避免？ Early Stopping 如何設計？有何風險？ 使用注意事項 評估指標需根據任務選擇，避免單一指標誤導。 交叉驗證與特徵工程順序需正確，防止資料洩漏。 Early Stopping 須監控驗證集，並設合理 patience。 延伸閱讀與資源 StatQuest: Model Evaluation Scikit-learn Model Selection Early Stopping in Deep Learning 經典面試題與解法提示 K-Fold 與 Stratified K-Fold 差異？ Precision 與 Recall 何時優先考慮？ ROC-AUC 有哪些限制？ Data Leakage 常見來源與防範？ Early Stopping 如何設計與調參？ 交叉驗證如何提升泛化能力？ 何時用 MAE 而非 MSE？ R² 何時不適用？ 如何用 Python 畫 ROC 曲線？ 多指標綜合評估的策略？ 結語 模型評估與驗證是 ML 成敗關鍵。熟悉交叉驗證、分類/迴歸指標、資料洩漏與早停技巧，能讓你打造更可靠的模型並在面試中展現專業素養。下一章將進入正則化與泛化理論，敬請期待！
'><meta property="og:url" content="https://yu-codes.github.io/portfolio/zh/articles/others/machine-learning/model-evaluation/"><link rel=canonical href=https://yu-codes.github.io/portfolio/zh/articles/others/machine-learning/model-evaluation/><link rel=stylesheet href=https://yu-codes.github.io/portfolio/css/main.css></head><body class=body><div class=container><aside class=sidebar><div class=sidebar-header><h1 class=name>Yu</h1><p class=tagline>Developer, dreamer, debugger.</p></div><nav class=sidebar-nav><a href=https://yu-codes.github.io/portfolio/zh/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M3 9l9-7 9 7v11a2 2 0 01-2 2H5a2 2 0 01-2-2z"/><polyline points="9 22 9 12 15 12 15 22"/></svg>
<span>首頁</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/articles/ class="nav-item active"><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5.0 016.5 17H20"/><path d="M6.5 2H20v20H6.5A2.5 2.5.0 014 19.5v-15A2.5 2.5.0 016.5 2z"/></svg>
<span>文章</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/resume/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="12" y1="11" x2="12" y2="17"/><line x1="9" y1="14" x2="15" y2="14"/></svg>
<span>履歷</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/projects/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="3" width="8" height="8"/><rect x="13" y="3" width="8" height="8"/><rect x="3" y="13" width="8" height="8"/><rect x="13" y="13" width="8" height="8"/></svg>
<span>專案</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/archives/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
<span>歸檔</span></a></nav><div class=sidebar-footer><div class=controls><button class="control-btn theme-toggle" title=切換主題（淺色/深色） aria-label="Toggle theme">
<svg class="icon-sun" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".25"/></svg>
<svg class="icon-moon" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".25"/></svg>
</button>
<button class="control-btn lang-toggle" title=切換語言 aria-label="Toggle language">
<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"/><path d="M2 12h20"/><path d="M12 2a15.3 15.3.0 014 10 15.3 15.3.0 01-4 10A15.3 15.3.0 018 12a15.3 15.3.0 014-10z"/></svg></button></div><div class=social-links><a href=https://github.com/yu-codes target=_blank rel="noopener noreferrer" class=social-link title=GitHub><svg viewBox="0 0 24 24" fill="currentColor"><path d="M12 0C5.374.0.0 5.373.0 12c0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931.0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176.0.0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221.0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/></svg>
</a><a href=mailto:dylan.jhou1120@gmail.com class=social-link title=Email><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div></div></aside><div class=main-content><div class=topbar><div class=breadcrumb><a href=https://yu-codes.github.io/portfolio/zh/>首頁</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/>文章</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/others/>其他</a><span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/others/machine-learning/>機器學習</a><span class=separator>&#8250;</span>
<span>模型評估與驗證全攻略：交叉驗證、分類/迴歸指標、資料洩漏與早停</span></div></div><main class=content-area><article class=article-content><header class=article-header><h1>模型評估與驗證全攻略：交叉驗證、分類/迴歸指標、資料洩漏與早停</h1><div class=article-meta><span class=article-author><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20 21v-2a4 4 0 00-4-4H8a4 4 0 00-4 4v2"/><circle cx="12" cy="7" r="4"/></svg>
Yu-Han Jhou
</span><span class=article-updated><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>
最後更新: 2025-02-13</span></div></header><div class=article-body><p>模型評估與驗證是機器學習流程中不可或缺的一環。正確的評估策略能幫助我們選擇最佳模型、避免過擬合、提升泛化能力。本章將深入交叉驗證策略、分類與迴歸指標、資料洩漏與早停技巧，結合理論、實作、面試熱點與常見誤區，讓你在專案與面試中都能精準評估模型表現。</p><hr><nav class=article-toc><span class=toc-title>目錄</span><nav id=TableOfContents><ul><li><a href=#交叉驗證策略-k-fold-stratified-timeseriessplit>交叉驗證策略 (K-Fold, Stratified, TimeSeriesSplit)</a><ul><li><a href=#k-fold-cross-validation>K-Fold Cross-Validation</a></li><li><a href=#stratified-k-fold>Stratified K-Fold</a></li><li><a href=#timeseriessplit>TimeSeriesSplit</a></li></ul></li><li><a href=#分類指標precision-recall--roc-auc--f1>分類指標：Precision-Recall / ROC-AUC / F1</a><ul><li><a href=#precision-recall-f1>Precision, Recall, F1</a></li><li><a href=#roc-auc>ROC-AUC</a></li></ul></li><li><a href=#迴歸指標mse--mae--r>迴歸指標：MSE / MAE / R²</a></li><li><a href=#data-leakage--早停-early-stopping>Data Leakage & 早停 (Early Stopping)</a><ul><li><a href=#data-leakage資料洩漏>Data Leakage（資料洩漏）</a></li><li><a href=#early-stopping早停>Early Stopping（早停）</a></li></ul></li><li><a href=#理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</a><ul><li><a href=#應用場景>應用場景</a></li><li><a href=#常見誤區>常見誤區</a></li></ul></li><li><a href=#面試熱點與經典問題>面試熱點與經典問題</a></li><li><a href=#使用注意事項>使用注意事項</a></li><li><a href=#延伸閱讀與資源>延伸閱讀與資源</a></li><li><a href=#經典面試題與解法提示>經典面試題與解法提示</a></li><li><a href=#結語>結語</a></li></ul></nav></nav><h2 id=交叉驗證策略-k-fold-stratified-timeseriessplit>交叉驗證策略 (K-Fold, Stratified, TimeSeriesSplit)</h2><h3 id=k-fold-cross-validation>K-Fold Cross-Validation</h3><ul><li>將資料分成 K 份，輪流用一份驗證，其餘訓練，平均結果。</li><li>適合資料量有限時提升評估穩定性。</li></ul><h3 id=stratified-k-fold>Stratified K-Fold</h3><ul><li>分層抽樣，確保每折類別比例與原資料一致。</li><li>適合分類任務，避免類別不平衡影響。</li></ul><h3 id=timeseriessplit>TimeSeriesSplit</h3><ul><li>適合時間序列資料，保留時間順序，避免未來資料洩漏到過去。</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> KFold, StratifiedKFold, TimeSeriesSplit
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> [[i] <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>10</span>)]
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>]<span style=color:#f92672>*</span><span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kf <span style=color:#f92672>=</span> KFold(n_splits<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>)
</span></span><span style=display:flex><span>skf <span style=color:#f92672>=</span> StratifiedKFold(n_splits<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>tscv <span style=color:#f92672>=</span> TimeSeriesSplit(n_splits<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> train, test <span style=color:#f92672>in</span> kf<span style=color:#f92672>.</span>split(X):
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;KFold:&#34;</span>, train, test)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> train, test <span style=color:#f92672>in</span> skf<span style=color:#f92672>.</span>split(X, y):
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;StratifiedKFold:&#34;</span>, train, test)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> train, test <span style=color:#f92672>in</span> tscv<span style=color:#f92672>.</span>split(X):
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;TimeSeriesSplit:&#34;</span>, train, test)
</span></span></code></pre></div><hr><h2 id=分類指標precision-recall--roc-auc--f1>分類指標：Precision-Recall / ROC-AUC / F1</h2><h3 id=precision-recall-f1>Precision, Recall, F1</h3><ul><li><strong>Precision</strong>：預測為正的樣本中有多少是真的正。</li><li><strong>Recall</strong>：所有正樣本中有多少被正確預測。</li><li><strong>F1 Score</strong>：Precision 與 Recall 的調和平均。</li></ul><h3 id=roc-auc>ROC-AUC</h3><ul><li>ROC 曲線：TPR vs FPR，AUC 為曲線下方面積。</li><li>適合不平衡資料，反映模型區分正負樣本能力。</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.metrics <span style=color:#f92672>import</span> precision_score, recall_score, f1_score, roc_auc_score
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>y_true <span style=color:#f92672>=</span> [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>y_prob <span style=color:#f92672>=</span> [<span style=color:#ae81ff>0.1</span>, <span style=color:#ae81ff>0.8</span>, <span style=color:#ae81ff>0.4</span>, <span style=color:#ae81ff>0.3</span>, <span style=color:#ae81ff>0.9</span>]
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Precision:&#34;</span>, precision_score(y_true, y_pred))
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Recall:&#34;</span>, recall_score(y_true, y_pred))
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;F1:&#34;</span>, f1_score(y_true, y_pred))
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;ROC-AUC:&#34;</span>, roc_auc_score(y_true, y_prob))
</span></span></code></pre></div><hr><h2 id=迴歸指標mse--mae--r>迴歸指標：MSE / MAE / R²</h2><table><thead><tr><th>指標</th><th>公式</th><th>適用場景</th><th>直覺說明</th></tr></thead><tbody><tr><td>MSE</td><td>$\frac{1}{n}\sum(y_i-\hat{y}_i)^2$</td><td>回歸</td><td>懲罰大誤差</td></tr><tr><td>MAE</td><td>$\frac{1}{n}\sum</td><td>y_i-\hat{y}_i</td><td>$</td></tr><tr><td>R²</td><td>$1-\frac{\sum(y_i-\hat{y}_i)^2}{\sum(y_i-\bar{y})^2}$</td><td>回歸</td><td>解釋變異比例</td></tr></tbody></table><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.metrics <span style=color:#f92672>import</span> mean_squared_error, mean_absolute_error, r2_score
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>y_true <span style=color:#f92672>=</span> [<span style=color:#ae81ff>3</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.5</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>7</span>]
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> [<span style=color:#ae81ff>2.5</span>, <span style=color:#ae81ff>0.0</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>8</span>]
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;MSE:&#34;</span>, mean_squared_error(y_true, y_pred))
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;MAE:&#34;</span>, mean_absolute_error(y_true, y_pred))
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;R²:&#34;</span>, r2_score(y_true, y_pred))
</span></span></code></pre></div><hr><h2 id=data-leakage--早停-early-stopping>Data Leakage & 早停 (Early Stopping)</h2><h3 id=data-leakage資料洩漏>Data Leakage（資料洩漏）</h3><ul><li>訓練時不小心用到未來或驗證資料，導致評估過於樂觀。</li><li>常見於特徵工程、標準化、目標編碼時未分開處理。</li></ul><h3 id=early-stopping早停>Early Stopping（早停）</h3><ul><li>監控驗證集表現，若多輪未提升則提前停止訓練，防止過擬合。</li><li>常用於深度學習、Boosting 類模型。</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.ensemble <span style=color:#f92672>import</span> GradientBoostingClassifier
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>gb <span style=color:#f92672>=</span> GradientBoostingClassifier(n_estimators<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>, validation_fraction<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>, n_iter_no_change<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>)
</span></span><span style=display:flex><span>gb<span style=color:#f92672>.</span>fit(X, y)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;最佳迭代數:&#34;</span>, gb<span style=color:#f92672>.</span>n_estimators_)
</span></span></code></pre></div><hr><h2 id=理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</h2><h3 id=應用場景>應用場景</h3><ul><li>交叉驗證：模型選擇、調參、泛化能力評估</li><li>Precision-Recall：醫療、金融等高風險領域</li><li>ROC-AUC：不平衡分類、模型比較</li><li>Early Stopping：深度學習、Boosting</li></ul><h3 id=常見誤區>常見誤區</h3><ul><li>交叉驗證未分層，導致類別不平衡。</li><li>評估指標選錯，誤導模型選擇。</li><li>特徵工程未分開訓練/驗證集，產生資料洩漏。</li><li>早停監控訓練集而非驗證集，無法防止過擬合。</li></ul><hr><h2 id=面試熱點與經典問題>面試熱點與經典問題</h2><table><thead><tr><th>主題</th><th>常見問題</th></tr></thead><tbody><tr><td>交叉驗證</td><td>為何能提升泛化？K-Fold 與 Stratified 差異？</td></tr><tr><td>Precision/Recall</td><td>何時優先考慮？有何 trade-off？</td></tr><tr><td>ROC-AUC</td><td>如何解讀？何時不適用？</td></tr><tr><td>Data Leakage</td><td>常見來源？如何避免？</td></tr><tr><td>Early Stopping</td><td>如何設計？有何風險？</td></tr></tbody></table><hr><h2 id=使用注意事項>使用注意事項</h2><ul><li>評估指標需根據任務選擇，避免單一指標誤導。</li><li>交叉驗證與特徵工程順序需正確，防止資料洩漏。</li><li>Early Stopping 須監控驗證集，並設合理 patience。</li></ul><hr><h2 id=延伸閱讀與資源>延伸閱讀與資源</h2><ul><li><a href=https://www.youtube.com/c/joshstarmer>StatQuest: Model Evaluation</a></li><li><a href=https://scikit-learn.org/stable/modules/model_selection.html>Scikit-learn Model Selection</a></li><li><a href=https://keras.io/api/callbacks/early_stopping/>Early Stopping in Deep Learning</a></li></ul><hr><h2 id=經典面試題與解法提示>經典面試題與解法提示</h2><ol><li>K-Fold 與 Stratified K-Fold 差異？</li><li>Precision 與 Recall 何時優先考慮？</li><li>ROC-AUC 有哪些限制？</li><li>Data Leakage 常見來源與防範？</li><li>Early Stopping 如何設計與調參？</li><li>交叉驗證如何提升泛化能力？</li><li>何時用 MAE 而非 MSE？</li><li>R² 何時不適用？</li><li>如何用 Python 畫 ROC 曲線？</li><li>多指標綜合評估的策略？</li></ol><hr><h2 id=結語>結語</h2><p>模型評估與驗證是 ML 成敗關鍵。熟悉交叉驗證、分類/迴歸指標、資料洩漏與早停技巧，能讓你打造更可靠的模型並在面試中展現專業素養。下一章將進入正則化與泛化理論，敬請期待！</p></div><div class=article-tags><div class=tags><span class=tag>Precision</span>
<span class=tag>Recall</span>
<span class=tag>ROC-AUC</span>
<span class=tag>F1</span>
<span class=tag>MSE</span>
<span class=tag>MAE</span>
<span class=tag>Data Leakage</span>
<span class=tag>Early Stopping</span></div></div><footer class=article-footer><a href=/portfolio/zh/articles/others/machine-learning/ class=back-link>← 返回 機器學習</a></footer></article></main><footer class=site-footer><p>&copy; 2026 YuHan Jhou. All rights reserved.</p></footer></div></div><script src=https://yu-codes.github.io/portfolio/js/theme.js defer></script><script src=https://yu-codes.github.io/portfolio/js/roadmap.js defer></script><script src=https://yu-codes.github.io/portfolio/js/parallax.js defer></script><script src=https://yu-codes.github.io/portfolio/js/page-transition.js defer></script></body></html>