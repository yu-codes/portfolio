<!doctype html><html lang=zh class=html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>ML 數學經典面試題庫：10 章精選題與解法直覺 - Yu's Portfolio & Learning Hub</title><meta name=description content="ML 數學經典面試題庫：精選題與解法直覺 本章彙整AI 數學基礎的經典面試題，每章精選 10-15 題，涵蓋計算、推導、直覺解釋與實務應用。每題附上解法提示與常見誤區，幫助你在面試與實戰中脫穎而出。
M1 線性代數快攻 什麼是矩陣的 Rank？如何計算？ 提示：行（或列）線性獨立數量，可用高斯消去法。 PCA 為何要用特徵分解或 SVD？ 提示：找主成分方向，最大化資料變異。 *Hadamard 乘積與 Kronecker 乘積差異？舉例說明。 如何判斷一組向量是否為基底？ 提示：檢查線性獨立與張成空間。 廣播機制在 Numpy 如何運作？ 提示：自動擴展維度，規則？ 特徵值、特徵向量的幾何意義？ 提示：變換後方向不變，縮放倍數。 SVD 分解的三個矩陣分別代表什麼？ 提示：左奇異向量、奇異值、右奇異向量。 Rank 與資料降維的關係？ 提示：Rank 決定最大可降維度。 如何用 Python 求解矩陣 Rank？ 提示：np.linalg.matrix_rank。 PCA 如何選擇主成分數量？ 提示：累積解釋變異量。 M2 微積分與連鎖法則 極限的定義與在 ML 中的應用？ 提示：收斂、損失函數極小化。 導數與梯度有何不同？ 提示：單變數 vs 多變數。 Jacobian 矩陣在神經網路中的角色？ 提示：多輸入多輸出偏導。 連鎖法則如何應用於反向傳播？ 提示：逐層傳遞梯度。 泰勒展開在優化中的意義？ 提示：近似損失曲面，牛頓法。 如何手算 $f(x) = x^3 + 2x$ 在 $x=2$ 的導數？ 提示：微分規則。 偏導數與全導數差異？ 提示：多變數函數。 梯度下降法的數學推導？ 提示：沿負梯度方向更新。 什麼是鞍點？在優化中有何影響？ 提示：一階導數為零但非極值。 自動微分的原理？ 提示：鏈式法則、計算圖。 M3 最適化基石 凸函數的定義與圖形特徵？ 提示：任意兩點連線不高於函數值。 Lagrange 乘子法的應用場景？ 提示：有約束最適化。 SGD 與 Adam 差異？何時選用？ 提示：收斂速度、適應性。 Learning Rate Schedule 有哪些？優缺點？ 提示：Step, Cosine, Warm-up。 Momentum 如何幫助跳出局部極小？ 提示：累積動量。 Mini-Batch 訓練的優勢？ 提示：效率、泛化。 牛頓法與梯度下降法差異？ 提示：二階導數、收斂速度。 如何選擇最佳學習率？ 提示：實驗、學習率搜尋。 Adam 優化器的數學公式？ 提示：一階、二階動量。 SGD 可能遇到哪些問題？ 提示：震盪、收斂慢。 M4 機率論 Essentials *PMF、PDF、CDF 差異？舉例說明。 常態分布的數學公式與特性？ 提示：均值、變異數、鐘型曲線。 條件機率的定義與應用？ 提示：貝氏定理、生成模型。 全機率公式如何推導？ 提示：分解複雜事件。 貝氏定理的直覺解釋？ 提示：先驗、後驗。 獨立事件與條件獨立的差異？ 提示：聯合機率。 Beta 分布的應用場景？ 提示：機率建模、貝氏推論。 如何用 Python 產生高斯分布樣本？ 提示：np.random.normal。 A 與 B 事件獨立，P(A|B)=? 提示：P(A)。 機率分布選擇對模型有何影響？ 提示：假設、推論結果。 M5 統計推論 Toolkit MLE、MAP、貝氏估計差異？ t-test、卡方檢定、ANOVA 適用情境？ Bootstrap 的原理與優缺點？ 交叉驗證如何提升泛化能力？ p 值的意義與誤用？ 如何計算 95% 信賴區間？ 假設檢定的零假設與對立假設？ 點估計與區間估計的差異？ 何時用非參數檢定？ 如何用 Python 做交叉驗證？ M6 信息理論 & 損失函數 熵、交叉熵、KL 散度的數學定義與差異？ KL 散度為何非對稱？有何影響？ JS 散度的應用場景？ Softmax + Cross-Entropy 為何好用？ 資訊增益在決策樹的角色？ 如何用 Python 計算交叉熵？ KL 散度在 VAE 的應用？ 熵越大代表什麼？ 交叉熵損失的梯度推導？ 常見損失函數還有哪些？ M7 數值計算與穩定性 浮點誤差的來源與影響？ Underflow/Overflow 如何避免？ Log-Sum-Exp Trick 的數學推導？ Gradient Clipping 的原理與應用？ 稀疏矩陣的存儲格式？ PyTorch 如何支援稀疏運算？ Softmax 計算時的數值陷阱？ 如何檢查模型訓練時的數值穩定性？ 稀疏矩陣乘法的加速技巧？ 數值不穩定時的 debug 步驟？ M8 統計學在 ML 實務 Bias-Variance Trade-off 如何可視化？ MSE、MAE、AUC 各自適用場景？ 置信帶與預測區間的差異？ 高 R² 可能有哪些陷阱？ 如何用交叉驗證評估模型？ AUC 高但預測效果差的原因？ 如何解釋模型的泛化能力？ 置信帶如何計算？ 混淆矩陣的意義？ 如何用 Python 畫 ROC 曲線？ M9 機率圖模型 (選讀) Bayesian Network 如何分解聯合分布？ MRF 與 BN 差異？ EM 演算法的 E/M 步驟數學推導？ HMM 的前向-後向演算法流程？ GMM 如何自動分群？ PGM 在 NLP 的應用？ 隱變量模型的直覺解釋？ EM 為何只保證局部最優？ 如何用 Python 實作 HMM？ PGM 推理時遇到計算爆炸怎麼辦？ 解題技巧與常見誤區 計算題：先寫公式再帶數字，避免粗心。 推導題：分步驟寫清楚，標明假設。 直覺題：用圖解、生活例子輔助說明。 實作題：熟悉 numpy、scikit-learn、pytorch 等常用 API。 常見誤區：混淆定義、忽略假設、過度依賴單一指標。 結語 本題庫涵蓋 AI 數學基礎的經典面試題與解法直覺。建議每題都動手推導、實作與解釋，並多練習口頭表達。祝你面試順利、學習愉快！
"><meta property="og:title" content="ML 數學經典面試題庫：10 章精選題與解法直覺"><meta property="og:description" content="ML 數學經典面試題庫：精選題與解法直覺 本章彙整AI 數學基礎的經典面試題，每章精選 10-15 題，涵蓋計算、推導、直覺解釋與實務應用。每題附上解法提示與常見誤區，幫助你在面試與實戰中脫穎而出。
M1 線性代數快攻 什麼是矩陣的 Rank？如何計算？ 提示：行（或列）線性獨立數量，可用高斯消去法。 PCA 為何要用特徵分解或 SVD？ 提示：找主成分方向，最大化資料變異。 *Hadamard 乘積與 Kronecker 乘積差異？舉例說明。 如何判斷一組向量是否為基底？ 提示：檢查線性獨立與張成空間。 廣播機制在 Numpy 如何運作？ 提示：自動擴展維度，規則？ 特徵值、特徵向量的幾何意義？ 提示：變換後方向不變，縮放倍數。 SVD 分解的三個矩陣分別代表什麼？ 提示：左奇異向量、奇異值、右奇異向量。 Rank 與資料降維的關係？ 提示：Rank 決定最大可降維度。 如何用 Python 求解矩陣 Rank？ 提示：np.linalg.matrix_rank。 PCA 如何選擇主成分數量？ 提示：累積解釋變異量。 M2 微積分與連鎖法則 極限的定義與在 ML 中的應用？ 提示：收斂、損失函數極小化。 導數與梯度有何不同？ 提示：單變數 vs 多變數。 Jacobian 矩陣在神經網路中的角色？ 提示：多輸入多輸出偏導。 連鎖法則如何應用於反向傳播？ 提示：逐層傳遞梯度。 泰勒展開在優化中的意義？ 提示：近似損失曲面，牛頓法。 如何手算 $f(x) = x^3 + 2x$ 在 $x=2$ 的導數？ 提示：微分規則。 偏導數與全導數差異？ 提示：多變數函數。 梯度下降法的數學推導？ 提示：沿負梯度方向更新。 什麼是鞍點？在優化中有何影響？ 提示：一階導數為零但非極值。 自動微分的原理？ 提示：鏈式法則、計算圖。 M3 最適化基石 凸函數的定義與圖形特徵？ 提示：任意兩點連線不高於函數值。 Lagrange 乘子法的應用場景？ 提示：有約束最適化。 SGD 與 Adam 差異？何時選用？ 提示：收斂速度、適應性。 Learning Rate Schedule 有哪些？優缺點？ 提示：Step, Cosine, Warm-up。 Momentum 如何幫助跳出局部極小？ 提示：累積動量。 Mini-Batch 訓練的優勢？ 提示：效率、泛化。 牛頓法與梯度下降法差異？ 提示：二階導數、收斂速度。 如何選擇最佳學習率？ 提示：實驗、學習率搜尋。 Adam 優化器的數學公式？ 提示：一階、二階動量。 SGD 可能遇到哪些問題？ 提示：震盪、收斂慢。 M4 機率論 Essentials *PMF、PDF、CDF 差異？舉例說明。 常態分布的數學公式與特性？ 提示：均值、變異數、鐘型曲線。 條件機率的定義與應用？ 提示：貝氏定理、生成模型。 全機率公式如何推導？ 提示：分解複雜事件。 貝氏定理的直覺解釋？ 提示：先驗、後驗。 獨立事件與條件獨立的差異？ 提示：聯合機率。 Beta 分布的應用場景？ 提示：機率建模、貝氏推論。 如何用 Python 產生高斯分布樣本？ 提示：np.random.normal。 A 與 B 事件獨立，P(A|B)=? 提示：P(A)。 機率分布選擇對模型有何影響？ 提示：假設、推論結果。 M5 統計推論 Toolkit MLE、MAP、貝氏估計差異？ t-test、卡方檢定、ANOVA 適用情境？ Bootstrap 的原理與優缺點？ 交叉驗證如何提升泛化能力？ p 值的意義與誤用？ 如何計算 95% 信賴區間？ 假設檢定的零假設與對立假設？ 點估計與區間估計的差異？ 何時用非參數檢定？ 如何用 Python 做交叉驗證？ M6 信息理論 & 損失函數 熵、交叉熵、KL 散度的數學定義與差異？ KL 散度為何非對稱？有何影響？ JS 散度的應用場景？ Softmax + Cross-Entropy 為何好用？ 資訊增益在決策樹的角色？ 如何用 Python 計算交叉熵？ KL 散度在 VAE 的應用？ 熵越大代表什麼？ 交叉熵損失的梯度推導？ 常見損失函數還有哪些？ M7 數值計算與穩定性 浮點誤差的來源與影響？ Underflow/Overflow 如何避免？ Log-Sum-Exp Trick 的數學推導？ Gradient Clipping 的原理與應用？ 稀疏矩陣的存儲格式？ PyTorch 如何支援稀疏運算？ Softmax 計算時的數值陷阱？ 如何檢查模型訓練時的數值穩定性？ 稀疏矩陣乘法的加速技巧？ 數值不穩定時的 debug 步驟？ M8 統計學在 ML 實務 Bias-Variance Trade-off 如何可視化？ MSE、MAE、AUC 各自適用場景？ 置信帶與預測區間的差異？ 高 R² 可能有哪些陷阱？ 如何用交叉驗證評估模型？ AUC 高但預測效果差的原因？ 如何解釋模型的泛化能力？ 置信帶如何計算？ 混淆矩陣的意義？ 如何用 Python 畫 ROC 曲線？ M9 機率圖模型 (選讀) Bayesian Network 如何分解聯合分布？ MRF 與 BN 差異？ EM 演算法的 E/M 步驟數學推導？ HMM 的前向-後向演算法流程？ GMM 如何自動分群？ PGM 在 NLP 的應用？ 隱變量模型的直覺解釋？ EM 為何只保證局部最優？ 如何用 Python 實作 HMM？ PGM 推理時遇到計算爆炸怎麼辦？ 解題技巧與常見誤區 計算題：先寫公式再帶數字，避免粗心。 推導題：分步驟寫清楚，標明假設。 直覺題：用圖解、生活例子輔助說明。 實作題：熟悉 numpy、scikit-learn、pytorch 等常用 API。 常見誤區：混淆定義、忽略假設、過度依賴單一指標。 結語 本題庫涵蓋 AI 數學基礎的經典面試題與解法直覺。建議每題都動手推導、實作與解釋，並多練習口頭表達。祝你面試順利、學習愉快！
"><meta property="og:url" content="https://yu-codes.github.io/portfolio/zh/articles/others/machine-learning/math-interview-questions/"><link rel=canonical href=https://yu-codes.github.io/portfolio/zh/articles/others/machine-learning/math-interview-questions/><link rel=stylesheet href=https://yu-codes.github.io/portfolio/css/main.css></head><body class=body><div class=container><aside class=sidebar><div class=sidebar-header><h1 class=name>Yu</h1><p class=tagline>Developer, dreamer, debugger.</p></div><nav class=sidebar-nav><a href=https://yu-codes.github.io/portfolio/zh/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M3 9l9-7 9 7v11a2 2 0 01-2 2H5a2 2 0 01-2-2z"/><polyline points="9 22 9 12 15 12 15 22"/></svg>
<span>首頁</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/articles/ class="nav-item active"><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5.0 016.5 17H20"/><path d="M6.5 2H20v20H6.5A2.5 2.5.0 014 19.5v-15A2.5 2.5.0 016.5 2z"/></svg>
<span>文章</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/resume/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="12" y1="11" x2="12" y2="17"/><line x1="9" y1="14" x2="15" y2="14"/></svg>
<span>履歷</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/projects/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="3" width="8" height="8"/><rect x="13" y="3" width="8" height="8"/><rect x="3" y="13" width="8" height="8"/><rect x="13" y="13" width="8" height="8"/></svg>
<span>專案</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/archives/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
<span>歸檔</span></a></nav><div class=sidebar-footer><div class=controls><button class="control-btn theme-toggle" title=切換主題（淺色/深色） aria-label="Toggle theme">
<svg class="icon-sun" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".25"/></svg>
<svg class="icon-moon" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".25"/></svg>
</button>
<button class="control-btn lang-toggle" title=切換語言 aria-label="Toggle language">
<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"/><path d="M2 12h20"/><path d="M12 2a15.3 15.3.0 014 10 15.3 15.3.0 01-4 10A15.3 15.3.0 018 12a15.3 15.3.0 014-10z"/></svg></button></div><div class=social-links><a href=https://github.com/yu-codes target=_blank rel="noopener noreferrer" class=social-link title=GitHub><svg viewBox="0 0 24 24" fill="currentColor"><path d="M12 0C5.374.0.0 5.373.0 12c0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931.0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176.0.0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221.0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/></svg>
</a><a href=mailto:dylan.jhou1120@gmail.com class=social-link title=Email><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div></div></aside><div class=main-content><div class=topbar><div class=breadcrumb><a href=https://yu-codes.github.io/portfolio/zh/>首頁</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/>文章</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/others/>其他</a><span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/others/machine-learning/>機器學習</a><span class=separator>&#8250;</span>
<span>ML 數學經典面試題庫：10 章精選題與解法直覺</span></div></div><main class=content-area><article class=article-content><header class=article-header><h1>ML 數學經典面試題庫：10 章精選題與解法直覺</h1><div class=article-meta><span class=article-author><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20 21v-2a4 4 0 00-4-4H8a4 4 0 00-4 4v2"/><circle cx="12" cy="7" r="4"/></svg>
Yu-Han Jhou
</span><span class=article-updated><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>
最後更新: 2025-03-08</span></div></header><div class=article-body><h1 id=ml-數學經典面試題庫精選題與解法直覺>ML 數學經典面試題庫：精選題與解法直覺</h1><p>本章彙整AI 數學基礎的經典面試題，每章精選 10-15 題，涵蓋計算、推導、直覺解釋與實務應用。每題附上解法提示與常見誤區，幫助你在面試與實戰中脫穎而出。</p><hr><nav class=article-toc><span class=toc-title>目錄</span><nav id=TableOfContents><ul><li><a href=#m1-線性代數快攻>M1 線性代數快攻</a></li><li><a href=#m2-微積分與連鎖法則>M2 微積分與連鎖法則</a></li><li><a href=#m3-最適化基石>M3 最適化基石</a></li><li><a href=#m4-機率論-essentials>M4 機率論 Essentials</a></li><li><a href=#m5-統計推論-toolkit>M5 統計推論 Toolkit</a></li><li><a href=#m6-信息理論--損失函數>M6 信息理論 & 損失函數</a></li><li><a href=#m7-數值計算與穩定性>M7 數值計算與穩定性</a></li><li><a href=#m8-統計學在-ml-實務>M8 統計學在 ML 實務</a></li><li><a href=#m9-機率圖模型-選讀>M9 機率圖模型 (選讀)</a></li><li><a href=#解題技巧與常見誤區>解題技巧與常見誤區</a></li><li><a href=#結語>結語</a></li></ul></nav></nav><h2 id=m1-線性代數快攻>M1 線性代數快攻</h2><ol><li><strong>什麼是矩陣的 Rank？如何計算？</strong><ul><li><em>提示：行（或列）線性獨立數量，可用高斯消去法。</em></li></ul></li><li><strong>PCA 為何要用特徵分解或 SVD？</strong><ul><li><em>提示：找主成分方向，最大化資料變異。</em></li></ul></li><li>*<em>Hadamard 乘積與 Kronecker 乘積差異？舉例說明。</em></li><li><strong>如何判斷一組向量是否為基底？</strong><ul><li><em>提示：檢查線性獨立與張成空間。</em></li></ul></li><li><strong>廣播機制在 Numpy 如何運作？</strong><ul><li><em>提示：自動擴展維度，規則？</em></li></ul></li><li><strong>特徵值、特徵向量的幾何意義？</strong><ul><li><em>提示：變換後方向不變，縮放倍數。</em></li></ul></li><li><strong>SVD 分解的三個矩陣分別代表什麼？</strong><ul><li><em>提示：左奇異向量、奇異值、右奇異向量。</em></li></ul></li><li><strong>Rank 與資料降維的關係？</strong><ul><li><em>提示：Rank 決定最大可降維度。</em></li></ul></li><li><strong>如何用 Python 求解矩陣 Rank？</strong><ul><li><em>提示：np.linalg.matrix_rank。</em></li></ul></li><li><strong>PCA 如何選擇主成分數量？</strong><ul><li><em>提示：累積解釋變異量。</em></li></ul></li></ol><hr><h2 id=m2-微積分與連鎖法則>M2 微積分與連鎖法則</h2><ol><li><strong>極限的定義與在 ML 中的應用？</strong><ul><li><em>提示：收斂、損失函數極小化。</em></li></ul></li><li><strong>導數與梯度有何不同？</strong><ul><li><em>提示：單變數 vs 多變數。</em></li></ul></li><li><strong>Jacobian 矩陣在神經網路中的角色？</strong><ul><li><em>提示：多輸入多輸出偏導。</em></li></ul></li><li><strong>連鎖法則如何應用於反向傳播？</strong><ul><li><em>提示：逐層傳遞梯度。</em></li></ul></li><li><strong>泰勒展開在優化中的意義？</strong><ul><li><em>提示：近似損失曲面，牛頓法。</em></li></ul></li><li><strong>如何手算 $f(x) = x^3 + 2x$ 在 $x=2$ 的導數？</strong><ul><li><em>提示：微分規則。</em></li></ul></li><li><strong>偏導數與全導數差異？</strong><ul><li><em>提示：多變數函數。</em></li></ul></li><li><strong>梯度下降法的數學推導？</strong><ul><li><em>提示：沿負梯度方向更新。</em></li></ul></li><li><strong>什麼是鞍點？在優化中有何影響？</strong><ul><li><em>提示：一階導數為零但非極值。</em></li></ul></li><li><strong>自動微分的原理？</strong><ul><li><em>提示：鏈式法則、計算圖。</em></li></ul></li></ol><hr><h2 id=m3-最適化基石>M3 最適化基石</h2><ol><li><strong>凸函數的定義與圖形特徵？</strong><ul><li><em>提示：任意兩點連線不高於函數值。</em></li></ul></li><li><strong>Lagrange 乘子法的應用場景？</strong><ul><li><em>提示：有約束最適化。</em></li></ul></li><li><strong>SGD 與 Adam 差異？何時選用？</strong><ul><li><em>提示：收斂速度、適應性。</em></li></ul></li><li><strong>Learning Rate Schedule 有哪些？優缺點？</strong><ul><li><em>提示：Step, Cosine, Warm-up。</em></li></ul></li><li><strong>Momentum 如何幫助跳出局部極小？</strong><ul><li><em>提示：累積動量。</em></li></ul></li><li><strong>Mini-Batch 訓練的優勢？</strong><ul><li><em>提示：效率、泛化。</em></li></ul></li><li><strong>牛頓法與梯度下降法差異？</strong><ul><li><em>提示：二階導數、收斂速度。</em></li></ul></li><li><strong>如何選擇最佳學習率？</strong><ul><li><em>提示：實驗、學習率搜尋。</em></li></ul></li><li><strong>Adam 優化器的數學公式？</strong><ul><li><em>提示：一階、二階動量。</em></li></ul></li><li><strong>SGD 可能遇到哪些問題？</strong><ul><li><em>提示：震盪、收斂慢。</em></li></ul></li></ol><hr><h2 id=m4-機率論-essentials>M4 機率論 Essentials</h2><ol><li>*<em>PMF、PDF、CDF 差異？舉例說明。</em></li><li><strong>常態分布的數學公式與特性？</strong><ul><li><em>提示：均值、變異數、鐘型曲線。</em></li></ul></li><li><strong>條件機率的定義與應用？</strong><ul><li><em>提示：貝氏定理、生成模型。</em></li></ul></li><li><strong>全機率公式如何推導？</strong><ul><li><em>提示：分解複雜事件。</em></li></ul></li><li><strong>貝氏定理的直覺解釋？</strong><ul><li><em>提示：先驗、後驗。</em></li></ul></li><li><strong>獨立事件與條件獨立的差異？</strong><ul><li><em>提示：聯合機率。</em></li></ul></li><li><strong>Beta 分布的應用場景？</strong><ul><li><em>提示：機率建模、貝氏推論。</em></li></ul></li><li><strong>如何用 Python 產生高斯分布樣本？</strong><ul><li><em>提示：np.random.normal。</em></li></ul></li><li><strong>A 與 B 事件獨立，P(A|B)=?</strong><ul><li><em>提示：P(A)。</em></li></ul></li><li><strong>機率分布選擇對模型有何影響？</strong><ul><li><em>提示：假設、推論結果。</em></li></ul></li></ol><hr><h2 id=m5-統計推論-toolkit>M5 統計推論 Toolkit</h2><ol><li><strong>MLE、MAP、貝氏估計差異？</strong></li><li><strong>t-test、卡方檢定、ANOVA 適用情境？</strong></li><li><strong>Bootstrap 的原理與優缺點？</strong></li><li><strong>交叉驗證如何提升泛化能力？</strong></li><li><strong>p 值的意義與誤用？</strong></li><li><strong>如何計算 95% 信賴區間？</strong></li><li><strong>假設檢定的零假設與對立假設？</strong></li><li><strong>點估計與區間估計的差異？</strong></li><li><strong>何時用非參數檢定？</strong></li><li><strong>如何用 Python 做交叉驗證？</strong></li></ol><hr><h2 id=m6-信息理論--損失函數>M6 信息理論 & 損失函數</h2><ol><li><strong>熵、交叉熵、KL 散度的數學定義與差異？</strong></li><li><strong>KL 散度為何非對稱？有何影響？</strong></li><li><strong>JS 散度的應用場景？</strong></li><li><strong>Softmax + Cross-Entropy 為何好用？</strong></li><li><strong>資訊增益在決策樹的角色？</strong></li><li><strong>如何用 Python 計算交叉熵？</strong></li><li><strong>KL 散度在 VAE 的應用？</strong></li><li><strong>熵越大代表什麼？</strong></li><li><strong>交叉熵損失的梯度推導？</strong></li><li><strong>常見損失函數還有哪些？</strong></li></ol><hr><h2 id=m7-數值計算與穩定性>M7 數值計算與穩定性</h2><ol><li><strong>浮點誤差的來源與影響？</strong></li><li><strong>Underflow/Overflow 如何避免？</strong></li><li><strong>Log-Sum-Exp Trick 的數學推導？</strong></li><li><strong>Gradient Clipping 的原理與應用？</strong></li><li><strong>稀疏矩陣的存儲格式？</strong></li><li><strong>PyTorch 如何支援稀疏運算？</strong></li><li><strong>Softmax 計算時的數值陷阱？</strong></li><li><strong>如何檢查模型訓練時的數值穩定性？</strong></li><li><strong>稀疏矩陣乘法的加速技巧？</strong></li><li><strong>數值不穩定時的 debug 步驟？</strong></li></ol><hr><h2 id=m8-統計學在-ml-實務>M8 統計學在 ML 實務</h2><ol><li><strong>Bias-Variance Trade-off 如何可視化？</strong></li><li><strong>MSE、MAE、AUC 各自適用場景？</strong></li><li><strong>置信帶與預測區間的差異？</strong></li><li><strong>高 R² 可能有哪些陷阱？</strong></li><li><strong>如何用交叉驗證評估模型？</strong></li><li><strong>AUC 高但預測效果差的原因？</strong></li><li><strong>如何解釋模型的泛化能力？</strong></li><li><strong>置信帶如何計算？</strong></li><li><strong>混淆矩陣的意義？</strong></li><li><strong>如何用 Python 畫 ROC 曲線？</strong></li></ol><hr><h2 id=m9-機率圖模型-選讀>M9 機率圖模型 (選讀)</h2><ol><li><strong>Bayesian Network 如何分解聯合分布？</strong></li><li><strong>MRF 與 BN 差異？</strong></li><li><strong>EM 演算法的 E/M 步驟數學推導？</strong></li><li><strong>HMM 的前向-後向演算法流程？</strong></li><li><strong>GMM 如何自動分群？</strong></li><li><strong>PGM 在 NLP 的應用？</strong></li><li><strong>隱變量模型的直覺解釋？</strong></li><li><strong>EM 為何只保證局部最優？</strong></li><li><strong>如何用 Python 實作 HMM？</strong></li><li><strong>PGM 推理時遇到計算爆炸怎麼辦？</strong></li></ol><hr><h2 id=解題技巧與常見誤區>解題技巧與常見誤區</h2><ul><li><strong>計算題</strong>：先寫公式再帶數字，避免粗心。</li><li><strong>推導題</strong>：分步驟寫清楚，標明假設。</li><li><strong>直覺題</strong>：用圖解、生活例子輔助說明。</li><li><strong>實作題</strong>：熟悉 numpy、scikit-learn、pytorch 等常用 API。</li><li><strong>常見誤區</strong>：混淆定義、忽略假設、過度依賴單一指標。</li></ul><hr><h2 id=結語>結語</h2><p>本題庫涵蓋 AI 數學基礎的經典面試題與解法直覺。建議每題都動手推導、實作與解釋，並多練習口頭表達。祝你面試順利、學習愉快！</p></div><div class=article-tags><div class=tags><span class=tag>interview</span></div></div><footer class=article-footer><a href=/portfolio/zh/articles/others/machine-learning/ class=back-link>← 返回 機器學習</a></footer></article></main><footer class=site-footer><p>&copy; 2026 YuHan Jhou. All rights reserved.</p></footer></div></div><script src=https://yu-codes.github.io/portfolio/js/theme.js defer></script><script src=https://yu-codes.github.io/portfolio/js/roadmap.js defer></script><script src=https://yu-codes.github.io/portfolio/js/parallax.js defer></script><script src=https://yu-codes.github.io/portfolio/js/page-transition.js defer></script></body></html>