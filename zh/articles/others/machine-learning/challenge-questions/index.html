<!doctype html><html lang=zh class=html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>模型訓練與優化挑戰題庫：經典面試題與解法提示 - Yu's Portfolio & Learning Hub</title><meta name=description content="本章彙整模型訓練與優化主題的經典面試題，每章精選 10-15 題，涵蓋理論推導、實作、直覺解釋與白板題。每題附上解法提示與常見誤區，幫助你在面試與實戰中脫穎而出。
OPT1 損失函數百寶箱 MSE、MAE、Huber Loss 差異與適用場景？ Cross-Entropy Loss 數學推導？ Focal Loss 如何設計與調參？ Triplet/Contrastive/InfoNCE 適用場景？ 自訂 Loss 如何確保可導與穩定？ 分類任務誤用 MSE 有何後果？ 如何用 Python 實作自訂 Loss？ Focal Loss 參數設置原則？ InfoNCE 在自監督學習的作用？ Loss 數值不穩定時如何 debug？ OPT2 梯度下降家譜 SGD、Momentum、Nesterov、Adam、AdamW 更新規則？ Adam 為何收斂快但泛化差？ AdamW 與 Adam 的數學差異？ AdaGrad/RMSProp 適用場景？ Adaptive 優化器 weight decay 設置？ SGD 何時優於 Adam？ 如何用 Python 切換優化器？ Nesterov Momentum 的數學推導？ AdamP 有何創新？ 優化器選擇對訓練有何影響？ OPT3 學習率策略 Step Decay、Cosine Annealing、Cyclical LR 原理與差異？ Warm-up 如何提升訓練穩定性？ One-Cycle Policy 的優勢？ LR Finder 如何選最佳學習率？ 學習率策略對收斂與泛化的影響？ 如何用 Python 實作多種 scheduler？ Cyclical/One-Cycle 參數設置原則？ Warm-up 需搭配哪些模型？ 學習率設錯會有什麼後果？ Scheduler 與 optimizer 如何協同設計？ OPT4 正則化武器庫 L1/L2/Elastic Net 數學推導與適用場景？ Dropout/DropPath 原理與實作？ Early Stopping 如何設計與調參？ Label Smoothing/Confidence Penalty 差異？ 正則化過強/過弱會有什麼後果？ 如何用 Python 實作 Early Stopping？ Dropout 推論時如何處理？ Elastic Net 何時優於單一正則化？ Label Smoothing 對模型有何影響？ Confidence Penalty 如何提升泛化？ OPT5 參數初始化 & 正規化層 Xavier/He/LeCun 初始化數學推導？ BatchNorm/LayerNorm/GroupNorm/RMSNorm 差異？ Weight Standardization 原理與應用？ ScaleNorm 適用場景？ 初始化錯誤對訓練有何影響？ 如何用 Python 實作多種初始化？ GroupNorm 分組數如何選擇？ BatchNorm 在推論時如何運作？ LayerNorm 適合哪些模型？ ScaleNorm/Weight Standardization 有何優勢？ OPT6 數值穩定技巧 Log-Sum-Exp Trick 數學推導？ Softmax underflow/overflow 如何防呆？ Gradient Clipping Value vs Norm 差異？ FP16/BF16 混合精度優缺點？ 混合精度訓練常見陷阱？ 如何用 Python 實作數值穩定 softmax？ Gradient Clipping 參數設置原則？ 數值不穩定時如何 debug？ 混合精度下哪些運算需保留 float32？ 數值穩定性對模型訓練有何影響？ OPT7 資料增強 & 合成 MixUp、CutMix、Cutout 原理與適用場景？ NLP 資料增強常見方法？ SpecAug 如何提升語音模型？ RandAugment/CTAugment 如何自動搜尋策略？ 增強過度會有什麼問題？ 如何用 Python 實作 MixUp？ CutMix 標籤如何混合？ NLP 增強如何保證語意一致？ 增強策略如何評估效果？ 不同任務如何選擇增強方法？ OPT8 分散式與大規模訓練 Data/Model/Pipeline Parallel 差異與組合？ ZeRO Stage 1-3 原理與應用？ FSDP 與 ZeRO/ DDP 差異？ Gradient Accumulation 實作細節？ Checkpoint Sharding 如何加速恢復？ Elastic Training 如何提升容錯？ Megatron-LM 支援哪些並行方式？ 分散式訓練常見瓶頸與解法？ 如何用 Python 實作 DDP/FSDP？ 分散式訓練的資源管理挑戰？ OPT9 超參數尋優進階 Grid/Random/Bayesian 搜尋原理與差異？ Hyperband 如何加速搜尋？ PBT 的原理與優缺點？ 多目標優化如何設計？ HPO 結果如何確保可重現？ 搜尋空間設計原則？ 如何用 Python 實作 Optuna 搜尋？ Hyperband 早停策略設計？ 多目標優化的評估方法？ HPO 常見陷阱與 debug？ OPT10 訓練監控 & Debug TensorBoard/Weights & Biases 如何追蹤訓練指標？ Loss 爆炸/消失的數學原因？ Learning Curve 如何判斷過擬合/欠擬合？ Validation Gap 如何調整？ 如何用 Python 單元測試 Forward/Backward？ Loss 不降常見原因？ Gradient Clipping 何時啟用？ 多指標監控的好處？ 單元測試如何設計？ 訓練監控與 Debug 的最佳實踐？ OPT11 課程學習 & 自監督 Curriculum Learning 的設計原則？ MoCo/SimCLR/BYOL 原理與差異？ Self-Supervised pretext 任務有哪些？ Fine-tuning 策略如何選擇？ Anti-Curriculum 適用場景？ 如何用 Python 實作對比學習？ Curriculum 設計錯誤會有什麼後果？ 自監督學習如何提升小樣本表現？ Fine-tuning 過程如何避免過擬合？ Pretext 任務與下游任務如何對齊？ OPT12 Fairness, Robustness & 安全 FGSM/PGD 原理與數學推導？ 對抗訓練如何提升魯棒性？ Noise Injection/Feature Smoothing 應用場景？ 如何設計可重現性流程？ Checkpoint 管理的最佳實踐？ 對抗樣本如何生成？ Seed/Determinism 設置細節？ 對抗訓練與標準訓練的 trade-off？ 如何用 Python 實作 FGSM？ Feature Smoothing 數學原理與實作？ 解題技巧與常見誤區 計算題：先寫公式再帶數字，避免粗心。 推導題：分步驟寫清楚，標明假設。 直覺題：用圖解、生活例子輔助說明。 實作題：熟悉 numpy、torch、optuna 等常用 API。 常見誤區：混淆定義、忽略假設、過度依賴單一指標。 結語 本題庫涵蓋模型訓練與優化經典面試題與解法直覺。建議每題都動手推導、實作與解釋，並多練習口頭表達。祝你面試順利、學習愉快！
"><meta property="og:title" content="模型訓練與優化挑戰題庫：經典面試題與解法提示"><meta property="og:description" content="本章彙整模型訓練與優化主題的經典面試題，每章精選 10-15 題，涵蓋理論推導、實作、直覺解釋與白板題。每題附上解法提示與常見誤區，幫助你在面試與實戰中脫穎而出。
OPT1 損失函數百寶箱 MSE、MAE、Huber Loss 差異與適用場景？ Cross-Entropy Loss 數學推導？ Focal Loss 如何設計與調參？ Triplet/Contrastive/InfoNCE 適用場景？ 自訂 Loss 如何確保可導與穩定？ 分類任務誤用 MSE 有何後果？ 如何用 Python 實作自訂 Loss？ Focal Loss 參數設置原則？ InfoNCE 在自監督學習的作用？ Loss 數值不穩定時如何 debug？ OPT2 梯度下降家譜 SGD、Momentum、Nesterov、Adam、AdamW 更新規則？ Adam 為何收斂快但泛化差？ AdamW 與 Adam 的數學差異？ AdaGrad/RMSProp 適用場景？ Adaptive 優化器 weight decay 設置？ SGD 何時優於 Adam？ 如何用 Python 切換優化器？ Nesterov Momentum 的數學推導？ AdamP 有何創新？ 優化器選擇對訓練有何影響？ OPT3 學習率策略 Step Decay、Cosine Annealing、Cyclical LR 原理與差異？ Warm-up 如何提升訓練穩定性？ One-Cycle Policy 的優勢？ LR Finder 如何選最佳學習率？ 學習率策略對收斂與泛化的影響？ 如何用 Python 實作多種 scheduler？ Cyclical/One-Cycle 參數設置原則？ Warm-up 需搭配哪些模型？ 學習率設錯會有什麼後果？ Scheduler 與 optimizer 如何協同設計？ OPT4 正則化武器庫 L1/L2/Elastic Net 數學推導與適用場景？ Dropout/DropPath 原理與實作？ Early Stopping 如何設計與調參？ Label Smoothing/Confidence Penalty 差異？ 正則化過強/過弱會有什麼後果？ 如何用 Python 實作 Early Stopping？ Dropout 推論時如何處理？ Elastic Net 何時優於單一正則化？ Label Smoothing 對模型有何影響？ Confidence Penalty 如何提升泛化？ OPT5 參數初始化 & 正規化層 Xavier/He/LeCun 初始化數學推導？ BatchNorm/LayerNorm/GroupNorm/RMSNorm 差異？ Weight Standardization 原理與應用？ ScaleNorm 適用場景？ 初始化錯誤對訓練有何影響？ 如何用 Python 實作多種初始化？ GroupNorm 分組數如何選擇？ BatchNorm 在推論時如何運作？ LayerNorm 適合哪些模型？ ScaleNorm/Weight Standardization 有何優勢？ OPT6 數值穩定技巧 Log-Sum-Exp Trick 數學推導？ Softmax underflow/overflow 如何防呆？ Gradient Clipping Value vs Norm 差異？ FP16/BF16 混合精度優缺點？ 混合精度訓練常見陷阱？ 如何用 Python 實作數值穩定 softmax？ Gradient Clipping 參數設置原則？ 數值不穩定時如何 debug？ 混合精度下哪些運算需保留 float32？ 數值穩定性對模型訓練有何影響？ OPT7 資料增強 & 合成 MixUp、CutMix、Cutout 原理與適用場景？ NLP 資料增強常見方法？ SpecAug 如何提升語音模型？ RandAugment/CTAugment 如何自動搜尋策略？ 增強過度會有什麼問題？ 如何用 Python 實作 MixUp？ CutMix 標籤如何混合？ NLP 增強如何保證語意一致？ 增強策略如何評估效果？ 不同任務如何選擇增強方法？ OPT8 分散式與大規模訓練 Data/Model/Pipeline Parallel 差異與組合？ ZeRO Stage 1-3 原理與應用？ FSDP 與 ZeRO/ DDP 差異？ Gradient Accumulation 實作細節？ Checkpoint Sharding 如何加速恢復？ Elastic Training 如何提升容錯？ Megatron-LM 支援哪些並行方式？ 分散式訓練常見瓶頸與解法？ 如何用 Python 實作 DDP/FSDP？ 分散式訓練的資源管理挑戰？ OPT9 超參數尋優進階 Grid/Random/Bayesian 搜尋原理與差異？ Hyperband 如何加速搜尋？ PBT 的原理與優缺點？ 多目標優化如何設計？ HPO 結果如何確保可重現？ 搜尋空間設計原則？ 如何用 Python 實作 Optuna 搜尋？ Hyperband 早停策略設計？ 多目標優化的評估方法？ HPO 常見陷阱與 debug？ OPT10 訓練監控 & Debug TensorBoard/Weights & Biases 如何追蹤訓練指標？ Loss 爆炸/消失的數學原因？ Learning Curve 如何判斷過擬合/欠擬合？ Validation Gap 如何調整？ 如何用 Python 單元測試 Forward/Backward？ Loss 不降常見原因？ Gradient Clipping 何時啟用？ 多指標監控的好處？ 單元測試如何設計？ 訓練監控與 Debug 的最佳實踐？ OPT11 課程學習 & 自監督 Curriculum Learning 的設計原則？ MoCo/SimCLR/BYOL 原理與差異？ Self-Supervised pretext 任務有哪些？ Fine-tuning 策略如何選擇？ Anti-Curriculum 適用場景？ 如何用 Python 實作對比學習？ Curriculum 設計錯誤會有什麼後果？ 自監督學習如何提升小樣本表現？ Fine-tuning 過程如何避免過擬合？ Pretext 任務與下游任務如何對齊？ OPT12 Fairness, Robustness & 安全 FGSM/PGD 原理與數學推導？ 對抗訓練如何提升魯棒性？ Noise Injection/Feature Smoothing 應用場景？ 如何設計可重現性流程？ Checkpoint 管理的最佳實踐？ 對抗樣本如何生成？ Seed/Determinism 設置細節？ 對抗訓練與標準訓練的 trade-off？ 如何用 Python 實作 FGSM？ Feature Smoothing 數學原理與實作？ 解題技巧與常見誤區 計算題：先寫公式再帶數字，避免粗心。 推導題：分步驟寫清楚，標明假設。 直覺題：用圖解、生活例子輔助說明。 實作題：熟悉 numpy、torch、optuna 等常用 API。 常見誤區：混淆定義、忽略假設、過度依賴單一指標。 結語 本題庫涵蓋模型訓練與優化經典面試題與解法直覺。建議每題都動手推導、實作與解釋，並多練習口頭表達。祝你面試順利、學習愉快！
"><meta property="og:url" content="https://yu-codes.github.io/portfolio/zh/articles/others/machine-learning/challenge-questions/"><link rel=canonical href=https://yu-codes.github.io/portfolio/zh/articles/others/machine-learning/challenge-questions/><link rel=stylesheet href=https://yu-codes.github.io/portfolio/css/main.css></head><body class=body><div class=container><aside class=sidebar><div class=sidebar-header><h1 class=name>Yu</h1><p class=tagline>Developer, dreamer, debugger.</p></div><nav class=sidebar-nav><a href=https://yu-codes.github.io/portfolio/zh/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M3 9l9-7 9 7v11a2 2 0 01-2 2H5a2 2 0 01-2-2z"/><polyline points="9 22 9 12 15 12 15 22"/></svg>
<span>首頁</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/articles/ class="nav-item active"><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5.0 016.5 17H20"/><path d="M6.5 2H20v20H6.5A2.5 2.5.0 014 19.5v-15A2.5 2.5.0 016.5 2z"/></svg>
<span>文章</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/resume/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="12" y1="11" x2="12" y2="17"/><line x1="9" y1="14" x2="15" y2="14"/></svg>
<span>履歷</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/projects/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="3" width="8" height="8"/><rect x="13" y="3" width="8" height="8"/><rect x="3" y="13" width="8" height="8"/><rect x="13" y="13" width="8" height="8"/></svg>
<span>專案</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/archives/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
<span>歸檔</span></a></nav><div class=sidebar-footer><div class=controls><button class="control-btn theme-toggle" title=切換主題（淺色/深色） aria-label="Toggle theme">
<svg class="icon-sun" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".25"/></svg>
<svg class="icon-moon" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".25"/></svg>
</button>
<button class="control-btn lang-toggle" title=切換語言 aria-label="Toggle language">
<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"/><path d="M2 12h20"/><path d="M12 2a15.3 15.3.0 014 10 15.3 15.3.0 01-4 10A15.3 15.3.0 018 12a15.3 15.3.0 014-10z"/></svg></button></div><div class=social-links><a href=https://github.com/yu-codes target=_blank rel="noopener noreferrer" class=social-link title=GitHub><svg viewBox="0 0 24 24" fill="currentColor"><path d="M12 0C5.374.0.0 5.373.0 12c0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931.0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176.0.0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221.0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/></svg>
</a><a href=mailto:dylan.jhou1120@gmail.com class=social-link title=Email><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div></div></aside><div class=main-content><div class=topbar><div class=breadcrumb><a href=https://yu-codes.github.io/portfolio/zh/>首頁</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/>文章</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/others/>其他</a><span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/others/machine-learning/>機器學習</a><span class=separator>&#8250;</span>
<span>模型訓練與優化挑戰題庫：經典面試題與解法提示</span></div></div><main class=content-area><article class=article-content><header class=article-header><h1>模型訓練與優化挑戰題庫：經典面試題與解法提示</h1><div class=article-meta><span class=article-author><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20 21v-2a4 4 0 00-4-4H8a4 4 0 00-4 4v2"/><circle cx="12" cy="7" r="4"/></svg>
Yu-Han Jhou
</span><span class=article-updated><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>
最後更新: 2025-12-12</span></div></header><div class=article-body><p>本章彙整模型訓練與優化主題的經典面試題，每章精選 10-15 題，涵蓋理論推導、實作、直覺解釋與白板題。每題附上解法提示與常見誤區，幫助你在面試與實戰中脫穎而出。</p><hr><nav class=article-toc><span class=toc-title>目錄</span><nav id=TableOfContents><ul><li><a href=#opt1-損失函數百寶箱>OPT1 損失函數百寶箱</a></li><li><a href=#opt2-梯度下降家譜>OPT2 梯度下降家譜</a></li><li><a href=#opt3-學習率策略>OPT3 學習率策略</a></li><li><a href=#opt4-正則化武器庫>OPT4 正則化武器庫</a></li><li><a href=#opt5-參數初始化--正規化層>OPT5 參數初始化 & 正規化層</a></li><li><a href=#opt6-數值穩定技巧>OPT6 數值穩定技巧</a></li><li><a href=#opt7-資料增強--合成>OPT7 資料增強 & 合成</a></li><li><a href=#opt8-分散式與大規模訓練>OPT8 分散式與大規模訓練</a></li><li><a href=#opt9-超參數尋優進階>OPT9 超參數尋優進階</a></li><li><a href=#opt10-訓練監控--debug>OPT10 訓練監控 & Debug</a></li><li><a href=#opt11-課程學習--自監督>OPT11 課程學習 & 自監督</a></li><li><a href=#opt12-fairness-robustness--安全>OPT12 Fairness, Robustness & 安全</a></li><li><a href=#解題技巧與常見誤區>解題技巧與常見誤區</a></li><li><a href=#結語>結語</a></li></ul></nav></nav><h2 id=opt1-損失函數百寶箱>OPT1 損失函數百寶箱</h2><ol><li>MSE、MAE、Huber Loss 差異與適用場景？</li><li>Cross-Entropy Loss 數學推導？</li><li>Focal Loss 如何設計與調參？</li><li>Triplet/Contrastive/InfoNCE 適用場景？</li><li>自訂 Loss 如何確保可導與穩定？</li><li>分類任務誤用 MSE 有何後果？</li><li>如何用 Python 實作自訂 Loss？</li><li>Focal Loss 參數設置原則？</li><li>InfoNCE 在自監督學習的作用？</li><li>Loss 數值不穩定時如何 debug？</li></ol><hr><h2 id=opt2-梯度下降家譜>OPT2 梯度下降家譜</h2><ol><li>SGD、Momentum、Nesterov、Adam、AdamW 更新規則？</li><li>Adam 為何收斂快但泛化差？</li><li>AdamW 與 Adam 的數學差異？</li><li>AdaGrad/RMSProp 適用場景？</li><li>Adaptive 優化器 weight decay 設置？</li><li>SGD 何時優於 Adam？</li><li>如何用 Python 切換優化器？</li><li>Nesterov Momentum 的數學推導？</li><li>AdamP 有何創新？</li><li>優化器選擇對訓練有何影響？</li></ol><hr><h2 id=opt3-學習率策略>OPT3 學習率策略</h2><ol><li>Step Decay、Cosine Annealing、Cyclical LR 原理與差異？</li><li>Warm-up 如何提升訓練穩定性？</li><li>One-Cycle Policy 的優勢？</li><li>LR Finder 如何選最佳學習率？</li><li>學習率策略對收斂與泛化的影響？</li><li>如何用 Python 實作多種 scheduler？</li><li>Cyclical/One-Cycle 參數設置原則？</li><li>Warm-up 需搭配哪些模型？</li><li>學習率設錯會有什麼後果？</li><li>Scheduler 與 optimizer 如何協同設計？</li></ol><hr><h2 id=opt4-正則化武器庫>OPT4 正則化武器庫</h2><ol><li>L1/L2/Elastic Net 數學推導與適用場景？</li><li>Dropout/DropPath 原理與實作？</li><li>Early Stopping 如何設計與調參？</li><li>Label Smoothing/Confidence Penalty 差異？</li><li>正則化過強/過弱會有什麼後果？</li><li>如何用 Python 實作 Early Stopping？</li><li>Dropout 推論時如何處理？</li><li>Elastic Net 何時優於單一正則化？</li><li>Label Smoothing 對模型有何影響？</li><li>Confidence Penalty 如何提升泛化？</li></ol><hr><h2 id=opt5-參數初始化--正規化層>OPT5 參數初始化 & 正規化層</h2><ol><li>Xavier/He/LeCun 初始化數學推導？</li><li>BatchNorm/LayerNorm/GroupNorm/RMSNorm 差異？</li><li>Weight Standardization 原理與應用？</li><li>ScaleNorm 適用場景？</li><li>初始化錯誤對訓練有何影響？</li><li>如何用 Python 實作多種初始化？</li><li>GroupNorm 分組數如何選擇？</li><li>BatchNorm 在推論時如何運作？</li><li>LayerNorm 適合哪些模型？</li><li>ScaleNorm/Weight Standardization 有何優勢？</li></ol><hr><h2 id=opt6-數值穩定技巧>OPT6 數值穩定技巧</h2><ol><li>Log-Sum-Exp Trick 數學推導？</li><li>Softmax underflow/overflow 如何防呆？</li><li>Gradient Clipping Value vs Norm 差異？</li><li>FP16/BF16 混合精度優缺點？</li><li>混合精度訓練常見陷阱？</li><li>如何用 Python 實作數值穩定 softmax？</li><li>Gradient Clipping 參數設置原則？</li><li>數值不穩定時如何 debug？</li><li>混合精度下哪些運算需保留 float32？</li><li>數值穩定性對模型訓練有何影響？</li></ol><hr><h2 id=opt7-資料增強--合成>OPT7 資料增強 & 合成</h2><ol><li>MixUp、CutMix、Cutout 原理與適用場景？</li><li>NLP 資料增強常見方法？</li><li>SpecAug 如何提升語音模型？</li><li>RandAugment/CTAugment 如何自動搜尋策略？</li><li>增強過度會有什麼問題？</li><li>如何用 Python 實作 MixUp？</li><li>CutMix 標籤如何混合？</li><li>NLP 增強如何保證語意一致？</li><li>增強策略如何評估效果？</li><li>不同任務如何選擇增強方法？</li></ol><hr><h2 id=opt8-分散式與大規模訓練>OPT8 分散式與大規模訓練</h2><ol><li>Data/Model/Pipeline Parallel 差異與組合？</li><li>ZeRO Stage 1-3 原理與應用？</li><li>FSDP 與 ZeRO/ DDP 差異？</li><li>Gradient Accumulation 實作細節？</li><li>Checkpoint Sharding 如何加速恢復？</li><li>Elastic Training 如何提升容錯？</li><li>Megatron-LM 支援哪些並行方式？</li><li>分散式訓練常見瓶頸與解法？</li><li>如何用 Python 實作 DDP/FSDP？</li><li>分散式訓練的資源管理挑戰？</li></ol><hr><h2 id=opt9-超參數尋優進階>OPT9 超參數尋優進階</h2><ol><li>Grid/Random/Bayesian 搜尋原理與差異？</li><li>Hyperband 如何加速搜尋？</li><li>PBT 的原理與優缺點？</li><li>多目標優化如何設計？</li><li>HPO 結果如何確保可重現？</li><li>搜尋空間設計原則？</li><li>如何用 Python 實作 Optuna 搜尋？</li><li>Hyperband 早停策略設計？</li><li>多目標優化的評估方法？</li><li>HPO 常見陷阱與 debug？</li></ol><hr><h2 id=opt10-訓練監控--debug>OPT10 訓練監控 & Debug</h2><ol><li>TensorBoard/Weights & Biases 如何追蹤訓練指標？</li><li>Loss 爆炸/消失的數學原因？</li><li>Learning Curve 如何判斷過擬合/欠擬合？</li><li>Validation Gap 如何調整？</li><li>如何用 Python 單元測試 Forward/Backward？</li><li>Loss 不降常見原因？</li><li>Gradient Clipping 何時啟用？</li><li>多指標監控的好處？</li><li>單元測試如何設計？</li><li>訓練監控與 Debug 的最佳實踐？</li></ol><hr><h2 id=opt11-課程學習--自監督>OPT11 課程學習 & 自監督</h2><ol><li>Curriculum Learning 的設計原則？</li><li>MoCo/SimCLR/BYOL 原理與差異？</li><li>Self-Supervised pretext 任務有哪些？</li><li>Fine-tuning 策略如何選擇？</li><li>Anti-Curriculum 適用場景？</li><li>如何用 Python 實作對比學習？</li><li>Curriculum 設計錯誤會有什麼後果？</li><li>自監督學習如何提升小樣本表現？</li><li>Fine-tuning 過程如何避免過擬合？</li><li>Pretext 任務與下游任務如何對齊？</li></ol><hr><h2 id=opt12-fairness-robustness--安全>OPT12 Fairness, Robustness & 安全</h2><ol><li>FGSM/PGD 原理與數學推導？</li><li>對抗訓練如何提升魯棒性？</li><li>Noise Injection/Feature Smoothing 應用場景？</li><li>如何設計可重現性流程？</li><li>Checkpoint 管理的最佳實踐？</li><li>對抗樣本如何生成？</li><li>Seed/Determinism 設置細節？</li><li>對抗訓練與標準訓練的 trade-off？</li><li>如何用 Python 實作 FGSM？</li><li>Feature Smoothing 數學原理與實作？</li></ol><hr><h2 id=解題技巧與常見誤區>解題技巧與常見誤區</h2><ul><li><strong>計算題</strong>：先寫公式再帶數字，避免粗心。</li><li><strong>推導題</strong>：分步驟寫清楚，標明假設。</li><li><strong>直覺題</strong>：用圖解、生活例子輔助說明。</li><li><strong>實作題</strong>：熟悉 numpy、torch、optuna 等常用 API。</li><li><strong>常見誤區</strong>：混淆定義、忽略假設、過度依賴單一指標。</li></ul><hr><h2 id=結語>結語</h2><p>本題庫涵蓋模型訓練與優化經典面試題與解法直覺。建議每題都動手推導、實作與解釋，並多練習口頭表達。祝你面試順利、學習愉快！</p></div><div class=article-tags><div class=tags><span class=tag>interview</span></div></div><footer class=article-footer><a href=/portfolio/zh/articles/others/machine-learning/ class=back-link>← 返回 機器學習</a></footer></article></main><footer class=site-footer><p>&copy; 2026 YuHan Jhou. All rights reserved.</p></footer></div></div><script src=https://yu-codes.github.io/portfolio/js/theme.js defer></script><script src=https://yu-codes.github.io/portfolio/js/roadmap.js defer></script><script src=https://yu-codes.github.io/portfolio/js/parallax.js defer></script><script src=https://yu-codes.github.io/portfolio/js/page-transition.js defer></script></body></html>