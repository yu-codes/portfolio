<!doctype html><html lang=zh class=html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>機率圖模型全解析：Bayesian Network、MRF、EM 與隱變量模型 - Yu's Portfolio & Learning Hub</title><meta name=description content="機率圖模型（Probabilistic Graphical Models, PGM）是結合機率論與圖論的強大工具，能以視覺化方式描述複雜隨機變數間的依賴關係。從貝氏網路、馬可夫隨機場，到 EM 演算法與隱變量模型，這些理論是現代 AI、NLP、推薦系統、生成模型的基石。本篇將深入剖析 PGM 的數學結構、推理方法、應用場景與 Python 實作，並結合圖解、面試熱點與常見誤區，讓你徹底掌握這門 AI 必修課。
機率圖模型概觀 什麼是機率圖模型？ 用圖（節點=隨機變數，邊=依賴關係）來表示高維機率分布。 兩大類型： 有向圖（Bayesian Network, BN）：邊有方向，描述因果關係。 無向圖（Markov Random Field, MRF）：邊無方向，描述對稱依賴。 優勢 可視化複雜依賴結構 降低參數數量（條件獨立性） 支援高效推理與學習 Bayesian Network（貝氏網路） 結構與數學基礎 有向無環圖（DAG），每個節點的機率只依賴其父節點。 聯合分布可分解為： $$ P(X_1, &mldr;, X_n) = \prod_{i=1}^n P(X_i | Pa(X_i)) $$ 其中 $Pa(X_i)$ 為 $X_i$ 的父節點集合。 推理與學習 推理：給定部分變數，計算其他變數的條件機率（如貝氏推斷、信念傳播）。 結構學習：從資料自動學習圖結構與參數。 Python 實作 from pgmpy.models import BayesianNetwork from pgmpy.factors.discrete import TabularCPD model = BayesianNetwork([('Cloudy', 'Rain'), ('Rain', 'Sprinkler'), ('Sprinkler', 'WetGrass')]) cpd_cloudy = TabularCPD('Cloudy', 2, [[0.5], [0.5]]) # ...定義其他 CPD... model.add_cpds(cpd_cloudy) # ...推理與查詢... Markov Random Field（馬可夫隨機場） 結構與數學基礎 無向圖，節點間的依賴對稱。 聯合分布分解為潛在函數（potential function）之乘積： $$ P(X_1, &mldr;, X_n) = \frac{1}{Z} \prod_{C \in cliques} \psi_C(X_C) $$ 其中 $Z$ 為正規化常數。 應用場景 圖像分割（像素間關聯） NLP（詞性標註、命名實體識別） Python 實作 from pgmpy.models import MarkovModel model = MarkovModel() model.add_nodes_from(['A', 'B', 'C']) model.add_edges_from([('A', 'B'), ('B', 'C')]) # ...定義潛在函數與推理... EM 演算法核心概念 EM（Expectation-Maximization）流程 E 步驟：根據現有參數，計算隱變量的期望（後驗分布）。 M 步驟：最大化期望下的參數對數似然，更新參數。 重複 E/M 步驟直到收斂。 理論推導 適用於含有隱變量的最大概似估計問題。 常見於 GMM、HMM、主題模型等。 Python 實作（GMM） from sklearn.mixture import GaussianMixture import numpy as np X = np.random.randn(100, 2) gmm = GaussianMixture(n_components=2) gmm.fit(X) labels = gmm.predict(X) print(&#34;分群結果:&#34;, labels[:10]) 隱變量模型（HMM, GMM） HMM（隱馬可夫模型） 適用於序列資料（語音、文字、DNA）。 狀態不可見，僅觀察到輸出。 典型應用：語音辨識、詞性標註、時間序列預測。 HMM 結構 狀態轉移機率、觀察機率、初始機率 前向-後向演算法、Viterbi 演算法 GMM（高斯混合模型） 用多個高斯分布混合建模資料分布。 可自動分群、密度估計、異常偵測。 GMM 結構 每個分群一組均值、共變異數、權重 EM 演算法自動學習參數 PGM 在 AI 實務的應用 NLP：語音辨識、機器翻譯、主題模型（LDA） 圖像處理：圖像分割、超像素分群 推薦系統：用戶-物品關聯建模 生成模型：深度生成模型（如 VAE、GAN 的圖結構擴展） 理論直覺、圖解與常見誤區 直覺圖解 有向圖：因果推理、資訊流動有方向 無向圖：對稱依賴、局部一致性 常見誤區 誤以為所有依賴都能用有向圖表示（部分需用無向圖） 忽略條件獨立性，導致參數爆炸 EM 只保證局部最優，初始值敏感 常見面試熱點整理 熱點主題 面試常問問題 Bayesian Network 如何分解聯合分布？ MRF 何時用無向圖？ EM 演算法 推導與收斂性？ HMM/GMM 實際應用與推理？ 使用注意事項 PGM 適合高維、依賴複雜的資料建模，但計算量大時需近似推理（如 MCMC、變分法）。 EM 需多次初始化避免陷入壞局部最優。 HMM/GMM 需根據資料特性選擇狀態數、分群數。 延伸閱讀與資源 Probabilistic Graphical Models (Stanford) pgmpy 官方文件 StatQuest: HMM, GMM, EM 深度學習書：PGM 章節 結語 機率圖模型是 AI 理論與實務的強大工具。掌握 Bayesian Network、MRF、EM 與隱變量模型，不僅能讓你建構更靈活的生成模型，也能在 NLP、推薦、圖像等多領域發揮威力。下一章將帶來經典面試題庫與解法，敬請期待！
"><meta property="og:title" content="機率圖模型全解析：Bayesian Network、MRF、EM 與隱變量模型"><meta property="og:description" content="機率圖模型（Probabilistic Graphical Models, PGM）是結合機率論與圖論的強大工具，能以視覺化方式描述複雜隨機變數間的依賴關係。從貝氏網路、馬可夫隨機場，到 EM 演算法與隱變量模型，這些理論是現代 AI、NLP、推薦系統、生成模型的基石。本篇將深入剖析 PGM 的數學結構、推理方法、應用場景與 Python 實作，並結合圖解、面試熱點與常見誤區，讓你徹底掌握這門 AI 必修課。
機率圖模型概觀 什麼是機率圖模型？ 用圖（節點=隨機變數，邊=依賴關係）來表示高維機率分布。 兩大類型： 有向圖（Bayesian Network, BN）：邊有方向，描述因果關係。 無向圖（Markov Random Field, MRF）：邊無方向，描述對稱依賴。 優勢 可視化複雜依賴結構 降低參數數量（條件獨立性） 支援高效推理與學習 Bayesian Network（貝氏網路） 結構與數學基礎 有向無環圖（DAG），每個節點的機率只依賴其父節點。 聯合分布可分解為： $$ P(X_1, &mldr;, X_n) = \prod_{i=1}^n P(X_i | Pa(X_i)) $$ 其中 $Pa(X_i)$ 為 $X_i$ 的父節點集合。 推理與學習 推理：給定部分變數，計算其他變數的條件機率（如貝氏推斷、信念傳播）。 結構學習：從資料自動學習圖結構與參數。 Python 實作 from pgmpy.models import BayesianNetwork from pgmpy.factors.discrete import TabularCPD model = BayesianNetwork([('Cloudy', 'Rain'), ('Rain', 'Sprinkler'), ('Sprinkler', 'WetGrass')]) cpd_cloudy = TabularCPD('Cloudy', 2, [[0.5], [0.5]]) # ...定義其他 CPD... model.add_cpds(cpd_cloudy) # ...推理與查詢... Markov Random Field（馬可夫隨機場） 結構與數學基礎 無向圖，節點間的依賴對稱。 聯合分布分解為潛在函數（potential function）之乘積： $$ P(X_1, &mldr;, X_n) = \frac{1}{Z} \prod_{C \in cliques} \psi_C(X_C) $$ 其中 $Z$ 為正規化常數。 應用場景 圖像分割（像素間關聯） NLP（詞性標註、命名實體識別） Python 實作 from pgmpy.models import MarkovModel model = MarkovModel() model.add_nodes_from(['A', 'B', 'C']) model.add_edges_from([('A', 'B'), ('B', 'C')]) # ...定義潛在函數與推理... EM 演算法核心概念 EM（Expectation-Maximization）流程 E 步驟：根據現有參數，計算隱變量的期望（後驗分布）。 M 步驟：最大化期望下的參數對數似然，更新參數。 重複 E/M 步驟直到收斂。 理論推導 適用於含有隱變量的最大概似估計問題。 常見於 GMM、HMM、主題模型等。 Python 實作（GMM） from sklearn.mixture import GaussianMixture import numpy as np X = np.random.randn(100, 2) gmm = GaussianMixture(n_components=2) gmm.fit(X) labels = gmm.predict(X) print(&#34;分群結果:&#34;, labels[:10]) 隱變量模型（HMM, GMM） HMM（隱馬可夫模型） 適用於序列資料（語音、文字、DNA）。 狀態不可見，僅觀察到輸出。 典型應用：語音辨識、詞性標註、時間序列預測。 HMM 結構 狀態轉移機率、觀察機率、初始機率 前向-後向演算法、Viterbi 演算法 GMM（高斯混合模型） 用多個高斯分布混合建模資料分布。 可自動分群、密度估計、異常偵測。 GMM 結構 每個分群一組均值、共變異數、權重 EM 演算法自動學習參數 PGM 在 AI 實務的應用 NLP：語音辨識、機器翻譯、主題模型（LDA） 圖像處理：圖像分割、超像素分群 推薦系統：用戶-物品關聯建模 生成模型：深度生成模型（如 VAE、GAN 的圖結構擴展） 理論直覺、圖解與常見誤區 直覺圖解 有向圖：因果推理、資訊流動有方向 無向圖：對稱依賴、局部一致性 常見誤區 誤以為所有依賴都能用有向圖表示（部分需用無向圖） 忽略條件獨立性，導致參數爆炸 EM 只保證局部最優，初始值敏感 常見面試熱點整理 熱點主題 面試常問問題 Bayesian Network 如何分解聯合分布？ MRF 何時用無向圖？ EM 演算法 推導與收斂性？ HMM/GMM 實際應用與推理？ 使用注意事項 PGM 適合高維、依賴複雜的資料建模，但計算量大時需近似推理（如 MCMC、變分法）。 EM 需多次初始化避免陷入壞局部最優。 HMM/GMM 需根據資料特性選擇狀態數、分群數。 延伸閱讀與資源 Probabilistic Graphical Models (Stanford) pgmpy 官方文件 StatQuest: HMM, GMM, EM 深度學習書：PGM 章節 結語 機率圖模型是 AI 理論與實務的強大工具。掌握 Bayesian Network、MRF、EM 與隱變量模型，不僅能讓你建構更靈活的生成模型，也能在 NLP、推薦、圖像等多領域發揮威力。下一章將帶來經典面試題庫與解法，敬請期待！
"><meta property="og:url" content="https://yu-codes.github.io/portfolio/zh/articles/others/machine-learning/probabilistic-graphical-models-for-ai/"><link rel=canonical href=https://yu-codes.github.io/portfolio/zh/articles/others/machine-learning/probabilistic-graphical-models-for-ai/><link rel=stylesheet href=https://yu-codes.github.io/portfolio/css/main.css></head><body class=body><div class=container><aside class=sidebar><div class=sidebar-header><h1 class=name>Yu</h1><p class=tagline>Developer, dreamer, debugger.</p></div><nav class=sidebar-nav><a href=https://yu-codes.github.io/portfolio/zh/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M3 9l9-7 9 7v11a2 2 0 01-2 2H5a2 2 0 01-2-2z"/><polyline points="9 22 9 12 15 12 15 22"/></svg>
<span>首頁</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/articles/ class="nav-item active"><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5.0 016.5 17H20"/><path d="M6.5 2H20v20H6.5A2.5 2.5.0 014 19.5v-15A2.5 2.5.0 016.5 2z"/></svg>
<span>文章</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/resume/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="12" y1="11" x2="12" y2="17"/><line x1="9" y1="14" x2="15" y2="14"/></svg>
<span>履歷</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/projects/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="3" width="8" height="8"/><rect x="13" y="3" width="8" height="8"/><rect x="3" y="13" width="8" height="8"/><rect x="13" y="13" width="8" height="8"/></svg>
<span>專案</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/archives/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
<span>歸檔</span></a></nav><div class=sidebar-footer><div class=controls><button class="control-btn theme-toggle" title=切換主題（淺色/深色） aria-label="Toggle theme">
<svg class="icon-sun" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".25"/></svg>
<svg class="icon-moon" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".25"/></svg>
</button>
<button class="control-btn lang-toggle" title=切換語言 aria-label="Toggle language">
<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"/><path d="M2 12h20"/><path d="M12 2a15.3 15.3.0 014 10 15.3 15.3.0 01-4 10A15.3 15.3.0 018 12a15.3 15.3.0 014-10z"/></svg></button></div><div class=social-links><a href=https://github.com/yu-codes target=_blank rel="noopener noreferrer" class=social-link title=GitHub><svg viewBox="0 0 24 24" fill="currentColor"><path d="M12 0C5.374.0.0 5.373.0 12c0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931.0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176.0.0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221.0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/></svg>
</a><a href=mailto:dylan.jhou1120@gmail.com class=social-link title=Email><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div></div></aside><div class=main-content><div class=topbar><div class=breadcrumb><a href=https://yu-codes.github.io/portfolio/zh/>首頁</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/>文章</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/others/>其他</a><span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/others/machine-learning/>機器學習</a><span class=separator>&#8250;</span>
<span>機率圖模型全解析：Bayesian Network、MRF、EM 與隱變量模型</span></div></div><main class=content-area><article class=article-content><header class=article-header><h1>機率圖模型全解析：Bayesian Network、MRF、EM 與隱變量模型</h1><div class=article-meta><span class=article-author><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20 21v-2a4 4 0 00-4-4H8a4 4 0 00-4 4v2"/><circle cx="12" cy="7" r="4"/></svg>
Yu-Han Jhou
</span><span class=article-updated><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>
最後更新: 2025-02-13</span></div></header><div class=article-body><p>機率圖模型（Probabilistic Graphical Models, PGM）是結合機率論與圖論的強大工具，能以視覺化方式描述複雜隨機變數間的依賴關係。從貝氏網路、馬可夫隨機場，到 EM 演算法與隱變量模型，這些理論是現代 AI、NLP、推薦系統、生成模型的基石。本篇將深入剖析 PGM 的數學結構、推理方法、應用場景與 Python 實作，並結合圖解、面試熱點與常見誤區，讓你徹底掌握這門 AI 必修課。</p><hr><nav class=article-toc><span class=toc-title>目錄</span><nav id=TableOfContents><ul><li><a href=#機率圖模型概觀>機率圖模型概觀</a><ul><li><a href=#什麼是機率圖模型>什麼是機率圖模型？</a></li><li><a href=#優勢>優勢</a></li></ul></li><li><a href=#bayesian-network貝氏網路>Bayesian Network（貝氏網路）</a><ul><li><a href=#結構與數學基礎>結構與數學基礎</a></li><li><a href=#推理與學習>推理與學習</a></li><li><a href=#python-實作>Python 實作</a></li></ul></li><li><a href=#markov-random-field馬可夫隨機場>Markov Random Field（馬可夫隨機場）</a><ul><li><a href=#結構與數學基礎-1>結構與數學基礎</a></li><li><a href=#應用場景>應用場景</a></li><li><a href=#python-實作-1>Python 實作</a></li></ul></li><li><a href=#em-演算法核心概念>EM 演算法核心概念</a><ul><li><a href=#emexpectation-maximization流程>EM（Expectation-Maximization）流程</a></li><li><a href=#理論推導>理論推導</a></li><li><a href=#python-實作gmm>Python 實作（GMM）</a></li></ul></li><li><a href=#隱變量模型hmm-gmm>隱變量模型（HMM, GMM）</a><ul><li><a href=#hmm隱馬可夫模型>HMM（隱馬可夫模型）</a></li><li><a href=#gmm高斯混合模型>GMM（高斯混合模型）</a></li></ul></li><li><a href=#pgm-在-ai-實務的應用>PGM 在 AI 實務的應用</a></li><li><a href=#理論直覺圖解與常見誤區>理論直覺、圖解與常見誤區</a><ul><li><a href=#直覺圖解>直覺圖解</a></li><li><a href=#常見誤區>常見誤區</a></li></ul></li><li><a href=#常見面試熱點整理>常見面試熱點整理</a></li><li><a href=#使用注意事項>使用注意事項</a></li><li><a href=#延伸閱讀與資源>延伸閱讀與資源</a></li><li><a href=#結語>結語</a></li></ul></nav></nav><h2 id=機率圖模型概觀>機率圖模型概觀</h2><h3 id=什麼是機率圖模型>什麼是機率圖模型？</h3><ul><li>用圖（節點=隨機變數，邊=依賴關係）來表示高維機率分布。</li><li>兩大類型：<ul><li><strong>有向圖（Bayesian Network, BN）</strong>：邊有方向，描述因果關係。</li><li><strong>無向圖（Markov Random Field, MRF）</strong>：邊無方向，描述對稱依賴。</li></ul></li></ul><h3 id=優勢>優勢</h3><ul><li>可視化複雜依賴結構</li><li>降低參數數量（條件獨立性）</li><li>支援高效推理與學習</li></ul><hr><h2 id=bayesian-network貝氏網路>Bayesian Network（貝氏網路）</h2><h3 id=結構與數學基礎>結構與數學基礎</h3><ul><li>有向無環圖（DAG），每個節點的機率只依賴其父節點。</li><li>聯合分布可分解為：
$$
P(X_1, &mldr;, X_n) = \prod_{i=1}^n P(X_i | Pa(X_i))
$$
其中 $Pa(X_i)$ 為 $X_i$ 的父節點集合。</li></ul><h3 id=推理與學習>推理與學習</h3><ul><li><strong>推理</strong>：給定部分變數，計算其他變數的條件機率（如貝氏推斷、信念傳播）。</li><li><strong>結構學習</strong>：從資料自動學習圖結構與參數。</li></ul><h3 id=python-實作>Python 實作</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pgmpy.models <span style=color:#f92672>import</span> BayesianNetwork
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pgmpy.factors.discrete <span style=color:#f92672>import</span> TabularCPD
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> BayesianNetwork([(<span style=color:#e6db74>&#39;Cloudy&#39;</span>, <span style=color:#e6db74>&#39;Rain&#39;</span>), (<span style=color:#e6db74>&#39;Rain&#39;</span>, <span style=color:#e6db74>&#39;Sprinkler&#39;</span>), (<span style=color:#e6db74>&#39;Sprinkler&#39;</span>, <span style=color:#e6db74>&#39;WetGrass&#39;</span>)])
</span></span><span style=display:flex><span>cpd_cloudy <span style=color:#f92672>=</span> TabularCPD(<span style=color:#e6db74>&#39;Cloudy&#39;</span>, <span style=color:#ae81ff>2</span>, [[<span style=color:#ae81ff>0.5</span>], [<span style=color:#ae81ff>0.5</span>]])
</span></span><span style=display:flex><span><span style=color:#75715e># ...定義其他 CPD...</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>add_cpds(cpd_cloudy)
</span></span><span style=display:flex><span><span style=color:#75715e># ...推理與查詢...</span>
</span></span></code></pre></div><hr><h2 id=markov-random-field馬可夫隨機場>Markov Random Field（馬可夫隨機場）</h2><h3 id=結構與數學基礎-1>結構與數學基礎</h3><ul><li>無向圖，節點間的依賴對稱。</li><li>聯合分布分解為潛在函數（potential function）之乘積：
$$
P(X_1, &mldr;, X_n) = \frac{1}{Z} \prod_{C \in cliques} \psi_C(X_C)
$$
其中 $Z$ 為正規化常數。</li></ul><h3 id=應用場景>應用場景</h3><ul><li>圖像分割（像素間關聯）</li><li>NLP（詞性標註、命名實體識別）</li></ul><h3 id=python-實作-1>Python 實作</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pgmpy.models <span style=color:#f92672>import</span> MarkovModel
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> MarkovModel()
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>add_nodes_from([<span style=color:#e6db74>&#39;A&#39;</span>, <span style=color:#e6db74>&#39;B&#39;</span>, <span style=color:#e6db74>&#39;C&#39;</span>])
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>add_edges_from([(<span style=color:#e6db74>&#39;A&#39;</span>, <span style=color:#e6db74>&#39;B&#39;</span>), (<span style=color:#e6db74>&#39;B&#39;</span>, <span style=color:#e6db74>&#39;C&#39;</span>)])
</span></span><span style=display:flex><span><span style=color:#75715e># ...定義潛在函數與推理...</span>
</span></span></code></pre></div><hr><h2 id=em-演算法核心概念>EM 演算法核心概念</h2><h3 id=emexpectation-maximization流程>EM（Expectation-Maximization）流程</h3><ol><li><strong>E 步驟</strong>：根據現有參數，計算隱變量的期望（後驗分布）。</li><li><strong>M 步驟</strong>：最大化期望下的參數對數似然，更新參數。</li><li>重複 E/M 步驟直到收斂。</li></ol><h3 id=理論推導>理論推導</h3><ul><li>適用於含有隱變量的最大概似估計問題。</li><li>常見於 GMM、HMM、主題模型等。</li></ul><h3 id=python-實作gmm>Python 實作（GMM）</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.mixture <span style=color:#f92672>import</span> GaussianMixture
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>gmm <span style=color:#f92672>=</span> GaussianMixture(n_components<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>gmm<span style=color:#f92672>.</span>fit(X)
</span></span><span style=display:flex><span>labels <span style=color:#f92672>=</span> gmm<span style=color:#f92672>.</span>predict(X)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;分群結果:&#34;</span>, labels[:<span style=color:#ae81ff>10</span>])
</span></span></code></pre></div><hr><h2 id=隱變量模型hmm-gmm>隱變量模型（HMM, GMM）</h2><h3 id=hmm隱馬可夫模型>HMM（隱馬可夫模型）</h3><ul><li>適用於序列資料（語音、文字、DNA）。</li><li>狀態不可見，僅觀察到輸出。</li><li>典型應用：語音辨識、詞性標註、時間序列預測。</li></ul><h4 id=hmm-結構>HMM 結構</h4><ul><li>狀態轉移機率、觀察機率、初始機率</li><li>前向-後向演算法、Viterbi 演算法</li></ul><h3 id=gmm高斯混合模型>GMM（高斯混合模型）</h3><ul><li>用多個高斯分布混合建模資料分布。</li><li>可自動分群、密度估計、異常偵測。</li></ul><h4 id=gmm-結構>GMM 結構</h4><ul><li>每個分群一組均值、共變異數、權重</li><li>EM 演算法自動學習參數</li></ul><hr><h2 id=pgm-在-ai-實務的應用>PGM 在 AI 實務的應用</h2><ul><li>NLP：語音辨識、機器翻譯、主題模型（LDA）</li><li>圖像處理：圖像分割、超像素分群</li><li>推薦系統：用戶-物品關聯建模</li><li>生成模型：深度生成模型（如 VAE、GAN 的圖結構擴展）</li></ul><hr><h2 id=理論直覺圖解與常見誤區>理論直覺、圖解與常見誤區</h2><h3 id=直覺圖解>直覺圖解</h3><ul><li>有向圖：因果推理、資訊流動有方向</li><li>無向圖：對稱依賴、局部一致性</li></ul><h3 id=常見誤區>常見誤區</h3><ul><li>誤以為所有依賴都能用有向圖表示（部分需用無向圖）</li><li>忽略條件獨立性，導致參數爆炸</li><li>EM 只保證局部最優，初始值敏感</li></ul><hr><h2 id=常見面試熱點整理>常見面試熱點整理</h2><table><thead><tr><th>熱點主題</th><th>面試常問問題</th></tr></thead><tbody><tr><td>Bayesian Network</td><td>如何分解聯合分布？</td></tr><tr><td>MRF</td><td>何時用無向圖？</td></tr><tr><td>EM 演算法</td><td>推導與收斂性？</td></tr><tr><td>HMM/GMM</td><td>實際應用與推理？</td></tr></tbody></table><hr><h2 id=使用注意事項>使用注意事項</h2><ul><li>PGM 適合高維、依賴複雜的資料建模，但計算量大時需近似推理（如 MCMC、變分法）。</li><li>EM 需多次初始化避免陷入壞局部最優。</li><li>HMM/GMM 需根據資料特性選擇狀態數、分群數。</li></ul><hr><h2 id=延伸閱讀與資源>延伸閱讀與資源</h2><ul><li><a href=https://web.stanford.edu/class/cs228/>Probabilistic Graphical Models (Stanford)</a></li><li><a href=https://pgmpy.org/>pgmpy 官方文件</a></li><li><a href="https://www.youtube.com/playlist?list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1">StatQuest: HMM, GMM, EM</a></li><li><a href=https://www.deeplearningbook.org/contents/graphical.html>深度學習書：PGM 章節</a></li></ul><hr><h2 id=結語>結語</h2><p>機率圖模型是 AI 理論與實務的強大工具。掌握 Bayesian Network、MRF、EM 與隱變量模型，不僅能讓你建構更靈活的生成模型，也能在 NLP、推薦、圖像等多領域發揮威力。下一章將帶來經典面試題庫與解法，敬請期待！</p></div><div class=article-tags><div class=tags><span class=tag>Bayesian Network</span>
<span class=tag>Markov Random Field</span>
<span class=tag>EM</span>
<span class=tag>HMM</span>
<span class=tag>GMM</span></div></div><footer class=article-footer><a href=/portfolio/zh/articles/others/machine-learning/ class=back-link>← 返回 機器學習</a></footer></article></main><footer class=site-footer><p>&copy; 2026 YuHan Jhou. All rights reserved.</p></footer></div></div><script src=https://yu-codes.github.io/portfolio/js/theme.js defer></script><script src=https://yu-codes.github.io/portfolio/js/roadmap.js defer></script><script src=https://yu-codes.github.io/portfolio/js/parallax.js defer></script><script src=https://yu-codes.github.io/portfolio/js/page-transition.js defer></script></body></html>