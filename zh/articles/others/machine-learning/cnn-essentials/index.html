<!doctype html><html lang=zh class=html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>卷積網路精要：CNN 結構、演進與應用全解析 - Yu's Portfolio & Learning Hub</title><meta name=description content='卷積神經網路（CNN）是現代深度學習的基石，廣泛應用於影像辨識、語音處理、NLP 等領域。本章將從卷積與池化的直覺出發，帶你理解經典結構（AlexNet、VGG、ResNet、EfficientNet）、各種 Block 差異，以及 CNN 在 NLP/時序資料的變體，結合理論、圖解、Python 實作與面試熱點，幫助你全面掌握 CNN。
卷積、池化、轉置卷積直覺 卷積（Convolution） 用小型權重核（filter）滑動提取區域特徵，參數共享、局部連接。 優點：大幅減少參數、提升平移不變性。 池化（Pooling） 降低特徵圖維度，提升模型魯棒性。 常見：Max Pooling、Average Pooling。 轉置卷積（Transposed Convolution） 用於上採樣（如生成模型、語意分割），將特徵圖放大。 import torch import torch.nn as nn conv = nn.Conv2d(3, 16, kernel_size=3, padding=1) pool = nn.MaxPool2d(2) deconv = nn.ConvTranspose2d(16, 3, kernel_size=2, stride=2) x = torch.randn(1, 3, 32, 32) y = pool(conv(x)) z = deconv(y) print("卷積後 shape:", y.shape, "轉置卷積後 shape:", z.shape) 經典結構演進：AlexNet → VGG → ResNet → EfficientNet AlexNet 2012 年 ImageNet 冠軍，深度 CNN 崛起。 多層卷積+ReLU+Dropout，首次用 GPU 訓練。 VGG 結構簡單，堆疊多個 3x3 卷積層。 參數量大，易於理解與遷移。 ResNet 引入殘差連接（Residual Connection），解決深層網路梯度消失。 可訓練超過 100 層，ImageNet 長青樹。 EfficientNet 用複合縮放（Compound Scaling）同時調整深度、寬度、解析度。 參數效率高，效能領先。 Residual / Dense / Inception Block 比較 Block 類型 結構特點 優點 代表網路 Residual 跳接殘差 解梯度消失 ResNet Dense 全層連接 特徵重用 DenseNet Inception 多尺度卷積 捕捉多種特徵 GoogLeNet/Inception CNN 在 NLP / 時序資料的變體 TCN（Temporal Convolutional Network） 用 1D 卷積處理序列，支援長距依賴。 應用：語音、時序預測。 WaveNet Google 提出，生成語音波形，採用因果卷積與殘差結構。 Python 實作：簡單 CNN import torch.nn as nn class SimpleCNN(nn.Module): def __init__(self): super().__init__() self.conv = nn.Conv2d(1, 8, 3, padding=1) self.pool = nn.MaxPool2d(2) self.fc = nn.Linear(8*14*14, 10) def forward(self, x): x = self.pool(torch.relu(self.conv(x))) x = x.view(x.size(0), -1) return self.fc(x) model = SimpleCNN() print(model) 理論直覺、應用場景與常見誤區 應用場景 影像辨識、物件偵測、語音處理、NLP（文本分類、情感分析）、時序預測 常見誤區 忽略 padding/stride 設定，導致特徵圖尺寸錯誤 轉置卷積未正確初始化，產生棋盤效應 過度堆疊卷積層，未加殘差連接導致梯度消失 面試熱點與經典問題 主題 常見問題 卷積 參數共享有何好處？ 池化 Max vs Avg Pooling 差異？ ResNet 殘差連接如何幫助訓練？ EfficientNet 複合縮放原理？ CNN 變體 TCN/WaveNet 適用場景？ 使用注意事項 卷積層後建議加 BatchNorm、激活函數 池化層可減少過擬合，但過度會損失細節 深層網路建議用殘差/稠密連接提升訓練穩定性 延伸閱讀與資源 Deep Learning Book: Convolutional Networks PyTorch CNN 官方文件 EfficientNet 論文 WaveNet 論文 經典面試題與解法提示 卷積層參數量如何計算？ 池化層有何作用？何時用 Max/Avg？ ResNet 殘差連接數學推導？ EfficientNet 複合縮放如何設計？ Inception Block 為何能捕捉多尺度特徵？ TCN 與 RNN 差異？ 轉置卷積常見問題與解法？ CNN 在 NLP 的應用有哪些？ 如何用 Python 實作簡單 CNN？ DenseNet 為何特徵重用？ 結語 CNN 是深度學習的核心。熟悉卷積、池化、經典結構與變體，能讓你在影像、語音、NLP 等多領域發揮深度學習威力。下一章將進入循環與序列模型，敬請期待！
'><meta property="og:title" content="卷積網路精要：CNN 結構、演進與應用全解析"><meta property="og:description" content='卷積神經網路（CNN）是現代深度學習的基石，廣泛應用於影像辨識、語音處理、NLP 等領域。本章將從卷積與池化的直覺出發，帶你理解經典結構（AlexNet、VGG、ResNet、EfficientNet）、各種 Block 差異，以及 CNN 在 NLP/時序資料的變體，結合理論、圖解、Python 實作與面試熱點，幫助你全面掌握 CNN。
卷積、池化、轉置卷積直覺 卷積（Convolution） 用小型權重核（filter）滑動提取區域特徵，參數共享、局部連接。 優點：大幅減少參數、提升平移不變性。 池化（Pooling） 降低特徵圖維度，提升模型魯棒性。 常見：Max Pooling、Average Pooling。 轉置卷積（Transposed Convolution） 用於上採樣（如生成模型、語意分割），將特徵圖放大。 import torch import torch.nn as nn conv = nn.Conv2d(3, 16, kernel_size=3, padding=1) pool = nn.MaxPool2d(2) deconv = nn.ConvTranspose2d(16, 3, kernel_size=2, stride=2) x = torch.randn(1, 3, 32, 32) y = pool(conv(x)) z = deconv(y) print("卷積後 shape:", y.shape, "轉置卷積後 shape:", z.shape) 經典結構演進：AlexNet → VGG → ResNet → EfficientNet AlexNet 2012 年 ImageNet 冠軍，深度 CNN 崛起。 多層卷積+ReLU+Dropout，首次用 GPU 訓練。 VGG 結構簡單，堆疊多個 3x3 卷積層。 參數量大，易於理解與遷移。 ResNet 引入殘差連接（Residual Connection），解決深層網路梯度消失。 可訓練超過 100 層，ImageNet 長青樹。 EfficientNet 用複合縮放（Compound Scaling）同時調整深度、寬度、解析度。 參數效率高，效能領先。 Residual / Dense / Inception Block 比較 Block 類型 結構特點 優點 代表網路 Residual 跳接殘差 解梯度消失 ResNet Dense 全層連接 特徵重用 DenseNet Inception 多尺度卷積 捕捉多種特徵 GoogLeNet/Inception CNN 在 NLP / 時序資料的變體 TCN（Temporal Convolutional Network） 用 1D 卷積處理序列，支援長距依賴。 應用：語音、時序預測。 WaveNet Google 提出，生成語音波形，採用因果卷積與殘差結構。 Python 實作：簡單 CNN import torch.nn as nn class SimpleCNN(nn.Module): def __init__(self): super().__init__() self.conv = nn.Conv2d(1, 8, 3, padding=1) self.pool = nn.MaxPool2d(2) self.fc = nn.Linear(8*14*14, 10) def forward(self, x): x = self.pool(torch.relu(self.conv(x))) x = x.view(x.size(0), -1) return self.fc(x) model = SimpleCNN() print(model) 理論直覺、應用場景與常見誤區 應用場景 影像辨識、物件偵測、語音處理、NLP（文本分類、情感分析）、時序預測 常見誤區 忽略 padding/stride 設定，導致特徵圖尺寸錯誤 轉置卷積未正確初始化，產生棋盤效應 過度堆疊卷積層，未加殘差連接導致梯度消失 面試熱點與經典問題 主題 常見問題 卷積 參數共享有何好處？ 池化 Max vs Avg Pooling 差異？ ResNet 殘差連接如何幫助訓練？ EfficientNet 複合縮放原理？ CNN 變體 TCN/WaveNet 適用場景？ 使用注意事項 卷積層後建議加 BatchNorm、激活函數 池化層可減少過擬合，但過度會損失細節 深層網路建議用殘差/稠密連接提升訓練穩定性 延伸閱讀與資源 Deep Learning Book: Convolutional Networks PyTorch CNN 官方文件 EfficientNet 論文 WaveNet 論文 經典面試題與解法提示 卷積層參數量如何計算？ 池化層有何作用？何時用 Max/Avg？ ResNet 殘差連接數學推導？ EfficientNet 複合縮放如何設計？ Inception Block 為何能捕捉多尺度特徵？ TCN 與 RNN 差異？ 轉置卷積常見問題與解法？ CNN 在 NLP 的應用有哪些？ 如何用 Python 實作簡單 CNN？ DenseNet 為何特徵重用？ 結語 CNN 是深度學習的核心。熟悉卷積、池化、經典結構與變體，能讓你在影像、語音、NLP 等多領域發揮深度學習威力。下一章將進入循環與序列模型，敬請期待！
'><meta property="og:url" content="https://yu-codes.github.io/portfolio/zh/articles/others/machine-learning/cnn-essentials/"><link rel=canonical href=https://yu-codes.github.io/portfolio/zh/articles/others/machine-learning/cnn-essentials/><link rel=stylesheet href=https://yu-codes.github.io/portfolio/css/main.css></head><body class=body><div class=container><aside class=sidebar><div class=sidebar-header><h1 class=name>Yu</h1><p class=tagline>Developer, dreamer, debugger.</p></div><nav class=sidebar-nav><a href=https://yu-codes.github.io/portfolio/zh/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M3 9l9-7 9 7v11a2 2 0 01-2 2H5a2 2 0 01-2-2z"/><polyline points="9 22 9 12 15 12 15 22"/></svg>
<span>首頁</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/articles/ class="nav-item active"><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5.0 016.5 17H20"/><path d="M6.5 2H20v20H6.5A2.5 2.5.0 014 19.5v-15A2.5 2.5.0 016.5 2z"/></svg>
<span>文章</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/resume/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="12" y1="11" x2="12" y2="17"/><line x1="9" y1="14" x2="15" y2="14"/></svg>
<span>履歷</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/projects/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="3" width="8" height="8"/><rect x="13" y="3" width="8" height="8"/><rect x="3" y="13" width="8" height="8"/><rect x="13" y="13" width="8" height="8"/></svg>
<span>專案</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/archives/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
<span>歸檔</span></a></nav><div class=sidebar-footer><div class=controls><button class="control-btn theme-toggle" title=切換主題（淺色/深色） aria-label="Toggle theme">
<svg class="icon-sun" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".25"/></svg>
<svg class="icon-moon" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".25"/></svg>
</button>
<button class="control-btn lang-toggle" title=切換語言 aria-label="Toggle language">
<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"/><path d="M2 12h20"/><path d="M12 2a15.3 15.3.0 014 10 15.3 15.3.0 01-4 10A15.3 15.3.0 018 12a15.3 15.3.0 014-10z"/></svg></button></div><div class=social-links><a href=https://github.com/yu-codes target=_blank rel="noopener noreferrer" class=social-link title=GitHub><svg viewBox="0 0 24 24" fill="currentColor"><path d="M12 0C5.374.0.0 5.373.0 12c0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931.0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176.0.0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221.0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/></svg>
</a><a href=mailto:dylan.jhou1120@gmail.com class=social-link title=Email><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div></div></aside><div class=main-content><div class=topbar><div class=breadcrumb><a href=https://yu-codes.github.io/portfolio/zh/>首頁</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/>文章</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/others/>其他</a><span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/others/machine-learning/>機器學習</a><span class=separator>&#8250;</span>
<span>卷積網路精要：CNN 結構、演進與應用全解析</span></div></div><main class=content-area><article class=article-content><header class=article-header><h1>卷積網路精要：CNN 結構、演進與應用全解析</h1><div class=article-meta><span class=article-author><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20 21v-2a4 4 0 00-4-4H8a4 4 0 00-4 4v2"/><circle cx="12" cy="7" r="4"/></svg>
Yu-Han Jhou
</span><span class=article-updated><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>
最後更新: 2025-05-28</span></div></header><div class=article-body><p>卷積神經網路（CNN）是現代深度學習的基石，廣泛應用於影像辨識、語音處理、NLP 等領域。本章將從卷積與池化的直覺出發，帶你理解經典結構（AlexNet、VGG、ResNet、EfficientNet）、各種 Block 差異，以及 CNN 在 NLP/時序資料的變體，結合理論、圖解、Python 實作與面試熱點，幫助你全面掌握 CNN。</p><hr><nav class=article-toc><span class=toc-title>目錄</span><nav id=TableOfContents><ul><li><a href=#卷積池化轉置卷積直覺>卷積、池化、轉置卷積直覺</a><ul><li><a href=#卷積convolution>卷積（Convolution）</a></li><li><a href=#池化pooling>池化（Pooling）</a></li><li><a href=#轉置卷積transposed-convolution>轉置卷積（Transposed Convolution）</a></li></ul></li><li><a href=#經典結構演進alexnet--vgg--resnet--efficientnet>經典結構演進：AlexNet → VGG → ResNet → EfficientNet</a><ul><li><a href=#alexnet>AlexNet</a></li><li><a href=#vgg>VGG</a></li><li><a href=#resnet>ResNet</a></li><li><a href=#efficientnet>EfficientNet</a></li></ul></li><li><a href=#residual--dense--inception-block-比較>Residual / Dense / Inception Block 比較</a></li><li><a href=#cnn-在-nlp--時序資料的變體>CNN 在 NLP / 時序資料的變體</a><ul><li><a href=#tcntemporal-convolutional-network>TCN（Temporal Convolutional Network）</a></li><li><a href=#wavenet>WaveNet</a></li></ul></li><li><a href=#python-實作簡單-cnn>Python 實作：簡單 CNN</a></li><li><a href=#理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</a><ul><li><a href=#應用場景>應用場景</a></li><li><a href=#常見誤區>常見誤區</a></li></ul></li><li><a href=#面試熱點與經典問題>面試熱點與經典問題</a></li><li><a href=#使用注意事項>使用注意事項</a></li><li><a href=#延伸閱讀與資源>延伸閱讀與資源</a></li><li><a href=#經典面試題與解法提示>經典面試題與解法提示</a></li><li><a href=#結語>結語</a></li></ul></nav></nav><h2 id=卷積池化轉置卷積直覺>卷積、池化、轉置卷積直覺</h2><h3 id=卷積convolution>卷積（Convolution）</h3><ul><li>用小型權重核（filter）滑動提取區域特徵，參數共享、局部連接。</li><li>優點：大幅減少參數、提升平移不變性。</li></ul><h3 id=池化pooling>池化（Pooling）</h3><ul><li>降低特徵圖維度，提升模型魯棒性。</li><li>常見：Max Pooling、Average Pooling。</li></ul><h3 id=轉置卷積transposed-convolution>轉置卷積（Transposed Convolution）</h3><ul><li>用於上採樣（如生成模型、語意分割），將特徵圖放大。</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>conv <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>16</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>pool <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>MaxPool2d(<span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>deconv <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>ConvTranspose2d(<span style=color:#ae81ff>16</span>, <span style=color:#ae81ff>3</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>32</span>, <span style=color:#ae81ff>32</span>)
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> pool(conv(x))
</span></span><span style=display:flex><span>z <span style=color:#f92672>=</span> deconv(y)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;卷積後 shape:&#34;</span>, y<span style=color:#f92672>.</span>shape, <span style=color:#e6db74>&#34;轉置卷積後 shape:&#34;</span>, z<span style=color:#f92672>.</span>shape)
</span></span></code></pre></div><hr><h2 id=經典結構演進alexnet--vgg--resnet--efficientnet>經典結構演進：AlexNet → VGG → ResNet → EfficientNet</h2><h3 id=alexnet>AlexNet</h3><ul><li>2012 年 ImageNet 冠軍，深度 CNN 崛起。</li><li>多層卷積+ReLU+Dropout，首次用 GPU 訓練。</li></ul><h3 id=vgg>VGG</h3><ul><li>結構簡單，堆疊多個 3x3 卷積層。</li><li>參數量大，易於理解與遷移。</li></ul><h3 id=resnet>ResNet</h3><ul><li>引入殘差連接（Residual Connection），解決深層網路梯度消失。</li><li>可訓練超過 100 層，ImageNet 長青樹。</li></ul><h3 id=efficientnet>EfficientNet</h3><ul><li>用複合縮放（Compound Scaling）同時調整深度、寬度、解析度。</li><li>參數效率高，效能領先。</li></ul><hr><h2 id=residual--dense--inception-block-比較>Residual / Dense / Inception Block 比較</h2><table><thead><tr><th>Block 類型</th><th>結構特點</th><th>優點</th><th>代表網路</th></tr></thead><tbody><tr><td>Residual</td><td>跳接殘差</td><td>解梯度消失</td><td>ResNet</td></tr><tr><td>Dense</td><td>全層連接</td><td>特徵重用</td><td>DenseNet</td></tr><tr><td>Inception</td><td>多尺度卷積</td><td>捕捉多種特徵</td><td>GoogLeNet/Inception</td></tr></tbody></table><hr><h2 id=cnn-在-nlp--時序資料的變體>CNN 在 NLP / 時序資料的變體</h2><h3 id=tcntemporal-convolutional-network>TCN（Temporal Convolutional Network）</h3><ul><li>用 1D 卷積處理序列，支援長距依賴。</li><li>應用：語音、時序預測。</li></ul><h3 id=wavenet>WaveNet</h3><ul><li>Google 提出，生成語音波形，採用因果卷積與殘差結構。</li></ul><hr><h2 id=python-實作簡單-cnn>Python 實作：簡單 CNN</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>SimpleCNN</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__init__</span>(self):
</span></span><span style=display:flex><span>        super()<span style=color:#f92672>.</span><span style=color:#a6e22e>__init__</span>()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>conv <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>8</span>, <span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>pool <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>MaxPool2d(<span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>fc <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>8</span><span style=color:#f92672>*</span><span style=color:#ae81ff>14</span><span style=color:#f92672>*</span><span style=color:#ae81ff>14</span>, <span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>pool(torch<span style=color:#f92672>.</span>relu(self<span style=color:#f92672>.</span>conv(x)))
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> x<span style=color:#f92672>.</span>view(x<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>), <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>fc(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> SimpleCNN()
</span></span><span style=display:flex><span>print(model)
</span></span></code></pre></div><hr><h2 id=理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</h2><h3 id=應用場景>應用場景</h3><ul><li>影像辨識、物件偵測、語音處理、NLP（文本分類、情感分析）、時序預測</li></ul><h3 id=常見誤區>常見誤區</h3><ul><li>忽略 padding/stride 設定，導致特徵圖尺寸錯誤</li><li>轉置卷積未正確初始化，產生棋盤效應</li><li>過度堆疊卷積層，未加殘差連接導致梯度消失</li></ul><hr><h2 id=面試熱點與經典問題>面試熱點與經典問題</h2><table><thead><tr><th>主題</th><th>常見問題</th></tr></thead><tbody><tr><td>卷積</td><td>參數共享有何好處？</td></tr><tr><td>池化</td><td>Max vs Avg Pooling 差異？</td></tr><tr><td>ResNet</td><td>殘差連接如何幫助訓練？</td></tr><tr><td>EfficientNet</td><td>複合縮放原理？</td></tr><tr><td>CNN 變體</td><td>TCN/WaveNet 適用場景？</td></tr></tbody></table><hr><h2 id=使用注意事項>使用注意事項</h2><ul><li>卷積層後建議加 BatchNorm、激活函數</li><li>池化層可減少過擬合，但過度會損失細節</li><li>深層網路建議用殘差/稠密連接提升訓練穩定性</li></ul><hr><h2 id=延伸閱讀與資源>延伸閱讀與資源</h2><ul><li><a href=https://www.deeplearningbook.org/contents/convnets.html>Deep Learning Book: Convolutional Networks</a></li><li><a href=https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html>PyTorch CNN 官方文件</a></li><li><a href=https://arxiv.org/abs/1905.11946>EfficientNet 論文</a></li><li><a href=https://arxiv.org/abs/1609.03499>WaveNet 論文</a></li></ul><hr><h2 id=經典面試題與解法提示>經典面試題與解法提示</h2><ol><li>卷積層參數量如何計算？</li><li>池化層有何作用？何時用 Max/Avg？</li><li>ResNet 殘差連接數學推導？</li><li>EfficientNet 複合縮放如何設計？</li><li>Inception Block 為何能捕捉多尺度特徵？</li><li>TCN 與 RNN 差異？</li><li>轉置卷積常見問題與解法？</li><li>CNN 在 NLP 的應用有哪些？</li><li>如何用 Python 實作簡單 CNN？</li><li>DenseNet 為何特徵重用？</li></ol><hr><h2 id=結語>結語</h2><p>CNN 是深度學習的核心。熟悉卷積、池化、經典結構與變體，能讓你在影像、語音、NLP 等多領域發揮深度學習威力。下一章將進入循環與序列模型，敬請期待！</p></div><div class=article-tags><div class=tags><span class=tag>cnn</span>
<span class=tag>convolution</span>
<span class=tag>pooling</span></div></div><footer class=article-footer><a href=/portfolio/zh/articles/others/machine-learning/ class=back-link>← 返回 機器學習</a></footer></article></main><footer class=site-footer><p>&copy; 2026 YuHan Jhou. All rights reserved.</p></footer></div></div><script src=https://yu-codes.github.io/portfolio/js/theme.js defer></script><script src=https://yu-codes.github.io/portfolio/js/roadmap.js defer></script><script src=https://yu-codes.github.io/portfolio/js/parallax.js defer></script><script src=https://yu-codes.github.io/portfolio/js/page-transition.js defer></script></body></html>