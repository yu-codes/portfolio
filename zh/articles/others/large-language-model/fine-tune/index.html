<!doctype html><html lang=zh class=html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>å¤§å‹èªè¨€æ¨¡å‹ Fine-Tuning å®Œæ•´æŒ‡å—ï¼šPEFTã€LoRAã€è³‡æ–™æº–å‚™èˆ‡ç›®éŒ„æ¶æ§‹å¯¦ä½œ - Yu's Portfolio & Learning Hub</title><meta name=description content="è‡ªå¾ ChatGPT å•ä¸–å¾Œï¼Œå¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLM, Large Language Modelï¼‰çš„ä½¿ç”¨è¶Šä¾†è¶Šæ™®åŠï¼Œä½†çœŸæ­£èƒ½æŒæ¡**å¦‚ä½•é‡å°ç‰¹å®šä»»å‹™é€²è¡Œå¾®èª¿ï¼ˆfine-tuningï¼‰**çš„å·¥ç¨‹å¸«ä»ç„¶ç¨€å°‘ã€‚
æœ¬æ–‡å°‡å¾è§€å¿µå…¥é–€ã€å¾®èª¿é¡å‹ã€è³‡æ–™æº–å‚™ï¼Œåˆ° Hugging Face + PEFT + LoRA çš„å¯¦ä½œèˆ‡å°ˆæ¡ˆç›®éŒ„æ¶æ§‹ï¼Œå¸¶ä½ å®Œæ•´æŒæ¡ LLM çš„å¾®èª¿èƒ½åŠ›ã€‚
ğŸ§  ç‚ºä½•éœ€è¦å¾®èª¿å¤§å‹èªè¨€æ¨¡å‹ï¼Ÿ ğŸ” LLM çš„é€šç”¨èƒ½åŠ›å¼·ï¼Œä½†å°ç‰¹å®šé ˜åŸŸçŸ¥è­˜ä»æœ‰é™ï¼ˆä¾‹å¦‚é‡‘èã€é†«ç™‚ã€ä¼æ¥­å…§éƒ¨è³‡æ–™ï¼‰ ğŸ¯ Fine-tuning èƒ½è®“æ¨¡å‹å°ˆæ³¨åœ¨ ç‰¹å®šä»»å‹™ æˆ– ç‰¹å®šèªèª¿ ğŸ’¡ å¾®èª¿å¾Œå¯ç¯€çœæ¨è«–æˆæœ¬ã€æå‡å›æ‡‰ä¸€è‡´æ€§ã€æ”¯æ´ç‰¹å®šæ ¼å¼ç”Ÿæˆ ğŸ”„ å¾®èª¿é¡å‹æ¦‚è¦½ï¼ˆå¾ç°¡åˆ°é›£ï¼‰ é¡å‹ èªªæ˜ Prompt Tuning åªè¨“ç·´ prompt prefixï¼Œæ•ˆèƒ½è¼ƒå·®ä½†å¿«é€Ÿè¼•ä¾¿ LoRA / Adapter Tuning éƒ¨åˆ†åƒæ•¸å¯è¨“ç·´ï¼Œè¼•é‡ã€æ•ˆç‡ä½³ï¼ˆæ¨è–¦ï¼‰ Full Fine-Tuning è¨“ç·´æ‰€æœ‰åƒæ•¸ï¼Œæ•ˆæœæœ€ä½³ä½†éœ€é«˜ç®—åŠ› ğŸ§° ä»€éº¼æ˜¯ PEFTï¼Ÿä»€éº¼æ˜¯ LoRAï¼Ÿ âœ… PEFTï¼ˆParameter-Efficient Fine-Tuningï¼‰ PEFT æ˜¯ Hugging Face æä¾›çš„å·¥å…·å¥—ä»¶ï¼Œæ”¯æ´å„ç¨® åªèª¿æ•´éƒ¨åˆ†åƒæ•¸çš„å¾®èª¿ç­–ç•¥ï¼Œå¤§å¹…é™ä½è¨˜æ†¶é«”èˆ‡è¨“ç·´æˆæœ¬ã€‚
æ”¯æ´æ–¹æ³•ï¼š
LoRAï¼ˆæœ€å¸¸ç”¨ï¼‰ Prompt Tuning Prefix Tuning AdaLoRA å®˜æ–¹ repo: https://github.com/huggingface/peft
âœ… LoRAï¼ˆLow-Rank Adaptationï¼‰ LoRA æ˜¯ä¸€ç¨®å°‡åŸå§‹æ¨¡å‹åƒæ•¸å‡çµï¼Œåªåœ¨æŸäº›å±¤æ’å…¥ä½ç§©çŸ©é™£é€²è¡Œè¨“ç·´çš„æ–¹æ³•ã€‚
"><meta property="og:title" content="å¤§å‹èªè¨€æ¨¡å‹ Fine-Tuning å®Œæ•´æŒ‡å—ï¼šPEFTã€LoRAã€è³‡æ–™æº–å‚™èˆ‡ç›®éŒ„æ¶æ§‹å¯¦ä½œ"><meta property="og:description" content="è‡ªå¾ ChatGPT å•ä¸–å¾Œï¼Œå¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLM, Large Language Modelï¼‰çš„ä½¿ç”¨è¶Šä¾†è¶Šæ™®åŠï¼Œä½†çœŸæ­£èƒ½æŒæ¡**å¦‚ä½•é‡å°ç‰¹å®šä»»å‹™é€²è¡Œå¾®èª¿ï¼ˆfine-tuningï¼‰**çš„å·¥ç¨‹å¸«ä»ç„¶ç¨€å°‘ã€‚
æœ¬æ–‡å°‡å¾è§€å¿µå…¥é–€ã€å¾®èª¿é¡å‹ã€è³‡æ–™æº–å‚™ï¼Œåˆ° Hugging Face + PEFT + LoRA çš„å¯¦ä½œèˆ‡å°ˆæ¡ˆç›®éŒ„æ¶æ§‹ï¼Œå¸¶ä½ å®Œæ•´æŒæ¡ LLM çš„å¾®èª¿èƒ½åŠ›ã€‚
ğŸ§  ç‚ºä½•éœ€è¦å¾®èª¿å¤§å‹èªè¨€æ¨¡å‹ï¼Ÿ ğŸ” LLM çš„é€šç”¨èƒ½åŠ›å¼·ï¼Œä½†å°ç‰¹å®šé ˜åŸŸçŸ¥è­˜ä»æœ‰é™ï¼ˆä¾‹å¦‚é‡‘èã€é†«ç™‚ã€ä¼æ¥­å…§éƒ¨è³‡æ–™ï¼‰ ğŸ¯ Fine-tuning èƒ½è®“æ¨¡å‹å°ˆæ³¨åœ¨ ç‰¹å®šä»»å‹™ æˆ– ç‰¹å®šèªèª¿ ğŸ’¡ å¾®èª¿å¾Œå¯ç¯€çœæ¨è«–æˆæœ¬ã€æå‡å›æ‡‰ä¸€è‡´æ€§ã€æ”¯æ´ç‰¹å®šæ ¼å¼ç”Ÿæˆ ğŸ”„ å¾®èª¿é¡å‹æ¦‚è¦½ï¼ˆå¾ç°¡åˆ°é›£ï¼‰ é¡å‹ èªªæ˜ Prompt Tuning åªè¨“ç·´ prompt prefixï¼Œæ•ˆèƒ½è¼ƒå·®ä½†å¿«é€Ÿè¼•ä¾¿ LoRA / Adapter Tuning éƒ¨åˆ†åƒæ•¸å¯è¨“ç·´ï¼Œè¼•é‡ã€æ•ˆç‡ä½³ï¼ˆæ¨è–¦ï¼‰ Full Fine-Tuning è¨“ç·´æ‰€æœ‰åƒæ•¸ï¼Œæ•ˆæœæœ€ä½³ä½†éœ€é«˜ç®—åŠ› ğŸ§° ä»€éº¼æ˜¯ PEFTï¼Ÿä»€éº¼æ˜¯ LoRAï¼Ÿ âœ… PEFTï¼ˆParameter-Efficient Fine-Tuningï¼‰ PEFT æ˜¯ Hugging Face æä¾›çš„å·¥å…·å¥—ä»¶ï¼Œæ”¯æ´å„ç¨® åªèª¿æ•´éƒ¨åˆ†åƒæ•¸çš„å¾®èª¿ç­–ç•¥ï¼Œå¤§å¹…é™ä½è¨˜æ†¶é«”èˆ‡è¨“ç·´æˆæœ¬ã€‚
æ”¯æ´æ–¹æ³•ï¼š
LoRAï¼ˆæœ€å¸¸ç”¨ï¼‰ Prompt Tuning Prefix Tuning AdaLoRA å®˜æ–¹ repo: https://github.com/huggingface/peft
âœ… LoRAï¼ˆLow-Rank Adaptationï¼‰ LoRA æ˜¯ä¸€ç¨®å°‡åŸå§‹æ¨¡å‹åƒæ•¸å‡çµï¼Œåªåœ¨æŸäº›å±¤æ’å…¥ä½ç§©çŸ©é™£é€²è¡Œè¨“ç·´çš„æ–¹æ³•ã€‚
"><meta property="og:url" content="https://yu-codes.github.io/portfolio/zh/articles/others/large-language-model/fine-tune/"><link rel=canonical href=https://yu-codes.github.io/portfolio/zh/articles/others/large-language-model/fine-tune/><link rel=stylesheet href=https://yu-codes.github.io/portfolio/css/main.css></head><body class=body><div class=container><aside class=sidebar><div class=sidebar-header><h1 class=name>Yu</h1><p class=tagline>Developer, dreamer, debugger.</p></div><nav class=sidebar-nav><a href=https://yu-codes.github.io/portfolio/zh/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M3 9l9-7 9 7v11a2 2 0 01-2 2H5a2 2 0 01-2-2z"/><polyline points="9 22 9 12 15 12 15 22"/></svg>
<span>é¦–é </span>
</a><a href=https://yu-codes.github.io/portfolio/zh/articles/ class="nav-item active"><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5.0 016.5 17H20"/><path d="M6.5 2H20v20H6.5A2.5 2.5.0 014 19.5v-15A2.5 2.5.0 016.5 2z"/></svg>
<span>æ–‡ç« </span>
</a><a href=https://yu-codes.github.io/portfolio/zh/resume/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="12" y1="11" x2="12" y2="17"/><line x1="9" y1="14" x2="15" y2="14"/></svg>
<span>å±¥æ­·</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/projects/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="3" width="8" height="8"/><rect x="13" y="3" width="8" height="8"/><rect x="3" y="13" width="8" height="8"/><rect x="13" y="13" width="8" height="8"/></svg>
<span>å°ˆæ¡ˆ</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/archives/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
<span>æ­¸æª”</span></a></nav><div class=sidebar-footer><div class=controls><button class="control-btn theme-toggle" title=åˆ‡æ›ä¸»é¡Œï¼ˆæ·ºè‰²/æ·±è‰²ï¼‰ aria-label="Toggle theme">
<svg class="icon-sun" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".25"/></svg>
<svg class="icon-moon" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".25"/></svg>
</button>
<button class="control-btn lang-toggle" title=åˆ‡æ›èªè¨€ aria-label="Toggle language">
<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"/><path d="M2 12h20"/><path d="M12 2a15.3 15.3.0 014 10 15.3 15.3.0 01-4 10A15.3 15.3.0 018 12a15.3 15.3.0 014-10z"/></svg></button></div><div class=social-links><a href=https://github.com/yu-codes target=_blank rel="noopener noreferrer" class=social-link title=GitHub><svg viewBox="0 0 24 24" fill="currentColor"><path d="M12 0C5.374.0.0 5.373.0 12c0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931.0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176.0.0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221.0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/></svg>
</a><a href=mailto:dylan.jhou1120@gmail.com class=social-link title=Email><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div></div></aside><div class=main-content><div class=topbar><div class=breadcrumb><a href=https://yu-codes.github.io/portfolio/zh/>é¦–é </a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/>æ–‡ç« </a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/others/>å…¶ä»–</a><span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/others/large-language-model/>å¤§å‹èªè¨€æ¨¡å‹</a><span class=separator>&#8250;</span>
<span>å¤§å‹èªè¨€æ¨¡å‹ Fine-Tuning å®Œæ•´æŒ‡å—ï¼šPEFTã€LoRAã€è³‡æ–™æº–å‚™èˆ‡ç›®éŒ„æ¶æ§‹å¯¦ä½œ</span></div></div><main class=content-area><article class=article-content><header class=article-header><h1>å¤§å‹èªè¨€æ¨¡å‹ Fine-Tuning å®Œæ•´æŒ‡å—ï¼šPEFTã€LoRAã€è³‡æ–™æº–å‚™èˆ‡ç›®éŒ„æ¶æ§‹å¯¦ä½œ</h1><div class=article-meta><span class=article-author><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20 21v-2a4 4 0 00-4-4H8a4 4 0 00-4 4v2"/><circle cx="12" cy="7" r="4"/></svg>
Yu-Han Jhou
</span><span class=article-updated><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>
æœ€å¾Œæ›´æ–°: 2025-06-17</span></div></header><div class=article-body><p>è‡ªå¾ ChatGPT å•ä¸–å¾Œï¼Œå¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLM, Large Language Modelï¼‰çš„ä½¿ç”¨è¶Šä¾†è¶Šæ™®åŠï¼Œä½†çœŸæ­£èƒ½æŒæ¡**å¦‚ä½•é‡å°ç‰¹å®šä»»å‹™é€²è¡Œå¾®èª¿ï¼ˆfine-tuningï¼‰**çš„å·¥ç¨‹å¸«ä»ç„¶ç¨€å°‘ã€‚</p><blockquote><p>æœ¬æ–‡å°‡å¾è§€å¿µå…¥é–€ã€å¾®èª¿é¡å‹ã€è³‡æ–™æº–å‚™ï¼Œåˆ° Hugging Face + PEFT + LoRA çš„å¯¦ä½œèˆ‡å°ˆæ¡ˆç›®éŒ„æ¶æ§‹ï¼Œå¸¶ä½ å®Œæ•´æŒæ¡ LLM çš„å¾®èª¿èƒ½åŠ›ã€‚</p></blockquote><hr><nav class=article-toc><span class=toc-title>ç›®éŒ„</span><nav id=TableOfContents><ul><li><a href=#-ç‚ºä½•éœ€è¦å¾®èª¿å¤§å‹èªè¨€æ¨¡å‹>ğŸ§  ç‚ºä½•éœ€è¦å¾®èª¿å¤§å‹èªè¨€æ¨¡å‹ï¼Ÿ</a></li><li><a href=#-å¾®èª¿é¡å‹æ¦‚è¦½å¾ç°¡åˆ°é›£>ğŸ”„ å¾®èª¿é¡å‹æ¦‚è¦½ï¼ˆå¾ç°¡åˆ°é›£ï¼‰</a></li><li><a href=#-ä»€éº¼æ˜¯-peftä»€éº¼æ˜¯-lora>ğŸ§° ä»€éº¼æ˜¯ PEFTï¼Ÿä»€éº¼æ˜¯ LoRAï¼Ÿ</a><ul><li><a href=#-peftparameter-efficient-fine-tuning>âœ… PEFTï¼ˆParameter-Efficient Fine-Tuningï¼‰</a></li><li><a href=#-loralow-rank-adaptation>âœ… LoRAï¼ˆLow-Rank Adaptationï¼‰</a></li></ul></li><li><a href=#-å°ˆæ¡ˆç›®éŒ„æ¶æ§‹è¨­è¨ˆå¯¦æˆ°æ¨è–¦>ğŸ—‚ï¸ å°ˆæ¡ˆç›®éŒ„æ¶æ§‹è¨­è¨ˆï¼ˆå¯¦æˆ°æ¨è–¦ï¼‰</a></li><li><a href=#-å¯¦ä½œæµç¨‹æ•™å­¸ä½¿ç”¨-hugging-face--peft--lora>ğŸ§ª å¯¦ä½œæµç¨‹æ•™å­¸ï¼šä½¿ç”¨ Hugging Face + PEFT + LoRA</a><ul><li><a href=#1-å®‰è£å¿…è¦å¥—ä»¶>1ï¸âƒ£ å®‰è£å¿…è¦å¥—ä»¶</a></li><li><a href=#2-å»ºç«‹è¨“ç·´è³‡æ–™æ ¼å¼ç‚º-jsonl>2ï¸âƒ£ å»ºç«‹è¨“ç·´è³‡æ–™ï¼ˆæ ¼å¼ç‚º jsonlï¼‰</a></li><li><a href=#3-è¨“ç·´è…³æœ¬ç°¡åŒ–ç‰ˆæœ¬>3ï¸âƒ£ è¨“ç·´è…³æœ¬ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰</a></li></ul></li><li><a href=#-å¦‚ä½•ä½¿ç”¨å¾®èª¿å¾Œçš„-lora-æ¨¡å‹>ğŸ“¤ å¦‚ä½•ä½¿ç”¨å¾®èª¿å¾Œçš„ LoRA æ¨¡å‹ï¼Ÿ</a></li><li><a href=#-æ¨¡å‹ä¸Šå‚³è‡³-hugging-face>ğŸ“¦ æ¨¡å‹ä¸Šå‚³è‡³ Hugging Face</a></li><li><a href=#-å¯¦å‹™å»ºè­°èˆ‡æœ€ä½³å¯¦è¸>âœ… å¯¦å‹™å»ºè­°èˆ‡æœ€ä½³å¯¦è¸</a></li><li><a href=#-å»¶ä¼¸è³‡æºæ¨è–¦>ğŸ“˜ å»¶ä¼¸è³‡æºæ¨è–¦</a></li><li><a href=#-çµèª>âœ… çµèª</a></li></ul></nav></nav><h2 id=-ç‚ºä½•éœ€è¦å¾®èª¿å¤§å‹èªè¨€æ¨¡å‹>ğŸ§  ç‚ºä½•éœ€è¦å¾®èª¿å¤§å‹èªè¨€æ¨¡å‹ï¼Ÿ</h2><ul><li>ğŸ” LLM çš„é€šç”¨èƒ½åŠ›å¼·ï¼Œä½†å°ç‰¹å®šé ˜åŸŸçŸ¥è­˜ä»æœ‰é™ï¼ˆä¾‹å¦‚é‡‘èã€é†«ç™‚ã€ä¼æ¥­å…§éƒ¨è³‡æ–™ï¼‰</li><li>ğŸ¯ Fine-tuning èƒ½è®“æ¨¡å‹å°ˆæ³¨åœ¨ <strong>ç‰¹å®šä»»å‹™</strong> æˆ– <strong>ç‰¹å®šèªèª¿</strong></li><li>ğŸ’¡ å¾®èª¿å¾Œå¯ç¯€çœæ¨è«–æˆæœ¬ã€æå‡å›æ‡‰ä¸€è‡´æ€§ã€æ”¯æ´ç‰¹å®šæ ¼å¼ç”Ÿæˆ</li></ul><hr><h2 id=-å¾®èª¿é¡å‹æ¦‚è¦½å¾ç°¡åˆ°é›£>ğŸ”„ å¾®èª¿é¡å‹æ¦‚è¦½ï¼ˆå¾ç°¡åˆ°é›£ï¼‰</h2><table><thead><tr><th>é¡å‹</th><th>èªªæ˜</th></tr></thead><tbody><tr><td>Prompt Tuning</td><td>åªè¨“ç·´ prompt prefixï¼Œæ•ˆèƒ½è¼ƒå·®ä½†å¿«é€Ÿè¼•ä¾¿</td></tr><tr><td>LoRA / Adapter Tuning</td><td>éƒ¨åˆ†åƒæ•¸å¯è¨“ç·´ï¼Œè¼•é‡ã€æ•ˆç‡ä½³ï¼ˆæ¨è–¦ï¼‰</td></tr><tr><td>Full Fine-Tuning</td><td>è¨“ç·´æ‰€æœ‰åƒæ•¸ï¼Œæ•ˆæœæœ€ä½³ä½†éœ€é«˜ç®—åŠ›</td></tr></tbody></table><hr><h2 id=-ä»€éº¼æ˜¯-peftä»€éº¼æ˜¯-lora>ğŸ§° ä»€éº¼æ˜¯ PEFTï¼Ÿä»€éº¼æ˜¯ LoRAï¼Ÿ</h2><h3 id=-peftparameter-efficient-fine-tuning>âœ… PEFTï¼ˆParameter-Efficient Fine-Tuningï¼‰</h3><p>PEFT æ˜¯ Hugging Face æä¾›çš„å·¥å…·å¥—ä»¶ï¼Œæ”¯æ´å„ç¨® <strong>åªèª¿æ•´éƒ¨åˆ†åƒæ•¸çš„å¾®èª¿ç­–ç•¥</strong>ï¼Œå¤§å¹…é™ä½è¨˜æ†¶é«”èˆ‡è¨“ç·´æˆæœ¬ã€‚</p><p>æ”¯æ´æ–¹æ³•ï¼š</p><ul><li>LoRAï¼ˆæœ€å¸¸ç”¨ï¼‰</li><li>Prompt Tuning</li><li>Prefix Tuning</li><li>AdaLoRA</li></ul><p>å®˜æ–¹ repo: <a href=https://github.com/huggingface/peft>https://github.com/huggingface/peft</a></p><hr><h3 id=-loralow-rank-adaptation>âœ… LoRAï¼ˆLow-Rank Adaptationï¼‰</h3><blockquote><p>LoRA æ˜¯ä¸€ç¨®å°‡åŸå§‹æ¨¡å‹åƒæ•¸å‡çµï¼Œåªåœ¨æŸäº›å±¤æ’å…¥ä½ç§©çŸ©é™£é€²è¡Œè¨“ç·´çš„æ–¹æ³•ã€‚</p></blockquote><ul><li>å¤§å¹…é™ä½ VRAM ä½¿ç”¨é‡</li><li>å¯èˆ‡åŸå§‹æ¨¡å‹åˆä½µæˆ–åˆ†é›¢å„²å­˜</li><li>å°æ–¼ LLaMAã€Falconã€Mistralã€GPT2 ç­‰æ¶æ§‹ç‰¹åˆ¥æœ‰æ•ˆ</li></ul><hr><h2 id=-å°ˆæ¡ˆç›®éŒ„æ¶æ§‹è¨­è¨ˆå¯¦æˆ°æ¨è–¦>ğŸ—‚ï¸ å°ˆæ¡ˆç›®éŒ„æ¶æ§‹è¨­è¨ˆï¼ˆå¯¦æˆ°æ¨è–¦ï¼‰</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>llm-finetune/
</span></span><span style=display:flex><span>â”œâ”€â”€ config/
</span></span><span style=display:flex><span>â”‚   â””â”€â”€ lora_config.json          <span style=color:#75715e># PEFT è¨­å®š</span>
</span></span><span style=display:flex><span>â”œâ”€â”€ data/
</span></span><span style=display:flex><span>â”‚   â””â”€â”€ train.jsonl               <span style=color:#75715e># è¼¸å…¥è³‡æ–™é›†</span>
</span></span><span style=display:flex><span>â”œâ”€â”€ scripts/
</span></span><span style=display:flex><span>â”‚   â””â”€â”€ run_finetune.py          <span style=color:#75715e># ä¸»è¨“ç·´è…³æœ¬</span>
</span></span><span style=display:flex><span>â”œâ”€â”€ checkpoints/
</span></span><span style=display:flex><span>â”‚   â””â”€â”€ adapter_model/           <span style=color:#75715e># å„²å­˜å¾®èª¿å¾Œåƒæ•¸ï¼ˆå¦‚ LoRA adapterï¼‰</span>
</span></span><span style=display:flex><span>â”œâ”€â”€ logs/
</span></span><span style=display:flex><span>â”‚   â””â”€â”€ training.log
</span></span><span style=display:flex><span>â”œâ”€â”€ requirements.txt
</span></span><span style=display:flex><span>â””â”€â”€ README.md
</span></span></code></pre></div><hr><h2 id=-å¯¦ä½œæµç¨‹æ•™å­¸ä½¿ç”¨-hugging-face--peft--lora>ğŸ§ª å¯¦ä½œæµç¨‹æ•™å­¸ï¼šä½¿ç”¨ Hugging Face + PEFT + LoRA</h2><h3 id=1-å®‰è£å¿…è¦å¥—ä»¶>1ï¸âƒ£ å®‰è£å¿…è¦å¥—ä»¶</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>pip install transformers datasets peft accelerate
</span></span></code></pre></div><hr><h3 id=2-å»ºç«‹è¨“ç·´è³‡æ–™æ ¼å¼ç‚º-jsonl>2ï¸âƒ£ å»ºç«‹è¨“ç·´è³‡æ–™ï¼ˆæ ¼å¼ç‚º jsonlï¼‰</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{<span style=color:#f92672>&#34;instruction&#34;</span>: <span style=color:#e6db74>&#34;ç¿»è­¯æˆè‹±æ–‡ï¼šæˆ‘æ„›ä½ &#34;</span>, <span style=color:#f92672>&#34;input&#34;</span>: <span style=color:#e6db74>&#34;&#34;</span>, <span style=color:#f92672>&#34;output&#34;</span>: <span style=color:#e6db74>&#34;I love you&#34;</span>}
</span></span><span style=display:flex><span>{<span style=color:#f92672>&#34;instruction&#34;</span>: <span style=color:#e6db74>&#34;è§£é‡‹ä»€éº¼æ˜¯ AIï¼Ÿ&#34;</span>, <span style=color:#f92672>&#34;input&#34;</span>: <span style=color:#e6db74>&#34;&#34;</span>, <span style=color:#f92672>&#34;output&#34;</span>: <span style=color:#e6db74>&#34;AI æ˜¯äººå·¥æ™ºæ…§çš„ç¸®å¯«...&#34;</span>}
</span></span></code></pre></div><hr><h3 id=3-è¨“ç·´è…³æœ¬ç°¡åŒ–ç‰ˆæœ¬>3ï¸âƒ£ è¨“ç·´è…³æœ¬ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> transformers <span style=color:#f92672>import</span> AutoModelForCausalLM, AutoTokenizer, TrainingArguments
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> peft <span style=color:#f92672>import</span> get_peft_model, LoraConfig, TaskType
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> datasets <span style=color:#f92672>import</span> load_dataset
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model_name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;tiiuae/falcon-7b&#34;</span>  <span style=color:#75715e># å¯æ›¿æ›æˆ llama2ã€gpt2 ç­‰</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> AutoModelForCausalLM<span style=color:#f92672>.</span>from_pretrained(model_name)
</span></span><span style=display:flex><span>tokenizer <span style=color:#f92672>=</span> AutoTokenizer<span style=color:#f92672>.</span>from_pretrained(model_name)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>peft_config <span style=color:#f92672>=</span> LoraConfig(
</span></span><span style=display:flex><span>    task_type<span style=color:#f92672>=</span>TaskType<span style=color:#f92672>.</span>CAUSAL_LM,
</span></span><span style=display:flex><span>    inference_mode<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>,
</span></span><span style=display:flex><span>    r<span style=color:#f92672>=</span><span style=color:#ae81ff>8</span>,
</span></span><span style=display:flex><span>    lora_alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>,
</span></span><span style=display:flex><span>    lora_dropout<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> get_peft_model(model, peft_config)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># è¼‰å…¥è³‡æ–™ï¼ˆéœ€è™•ç† tokenizationï¼‰</span>
</span></span><span style=display:flex><span>dataset <span style=color:#f92672>=</span> load_dataset(<span style=color:#e6db74>&#34;json&#34;</span>, data_files<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;data/train.jsonl&#34;</span>)[<span style=color:#e6db74>&#34;train&#34;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># è¨“ç·´åƒæ•¸</span>
</span></span><span style=display:flex><span>args <span style=color:#f92672>=</span> TrainingArguments(
</span></span><span style=display:flex><span>    output_dir<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;checkpoints&#34;</span>,
</span></span><span style=display:flex><span>    per_device_train_batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>,
</span></span><span style=display:flex><span>    num_train_epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>,
</span></span><span style=display:flex><span>    logging_dir<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;logs&#34;</span>,
</span></span><span style=display:flex><span>    save_strategy<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;epoch&#34;</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># é–‹å§‹è¨“ç·´</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> transformers <span style=color:#f92672>import</span> Trainer
</span></span><span style=display:flex><span>trainer <span style=color:#f92672>=</span> Trainer(
</span></span><span style=display:flex><span>    model<span style=color:#f92672>=</span>model,
</span></span><span style=display:flex><span>    args<span style=color:#f92672>=</span>args,
</span></span><span style=display:flex><span>    train_dataset<span style=color:#f92672>=</span>dataset
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>trainer<span style=color:#f92672>.</span>train()
</span></span></code></pre></div><hr><h2 id=-å¦‚ä½•ä½¿ç”¨å¾®èª¿å¾Œçš„-lora-æ¨¡å‹>ğŸ“¤ å¦‚ä½•ä½¿ç”¨å¾®èª¿å¾Œçš„ LoRA æ¨¡å‹ï¼Ÿ</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> peft <span style=color:#f92672>import</span> PeftModel
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>base_model <span style=color:#f92672>=</span> AutoModelForCausalLM<span style=color:#f92672>.</span>from_pretrained(<span style=color:#e6db74>&#34;tiiuae/falcon-7b&#34;</span>)
</span></span><span style=display:flex><span>lora_model <span style=color:#f92672>=</span> PeftModel<span style=color:#f92672>.</span>from_pretrained(base_model, <span style=color:#e6db74>&#34;checkpoints/adapter_model&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># æ¨è«–</span>
</span></span><span style=display:flex><span>output <span style=color:#f92672>=</span> lora_model<span style=color:#f92672>.</span>generate(<span style=color:#f92672>...</span>)
</span></span></code></pre></div><hr><h2 id=-æ¨¡å‹ä¸Šå‚³è‡³-hugging-face>ğŸ“¦ æ¨¡å‹ä¸Šå‚³è‡³ Hugging Face</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>from huggingface_hub import HfApi
</span></span><span style=display:flex><span>api <span style=color:#f92672>=</span> HfApi<span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>api.upload_folder<span style=color:#f92672>(</span>folder_path<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;checkpoints/adapter_model&#34;</span>, repo_id<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;your-username/your-model&#34;</span><span style=color:#f92672>)</span>
</span></span></code></pre></div><hr><h2 id=-å¯¦å‹™å»ºè­°èˆ‡æœ€ä½³å¯¦è¸>âœ… å¯¦å‹™å»ºè­°èˆ‡æœ€ä½³å¯¦è¸</h2><ul><li>ğŸ”’ ä½¿ç”¨ <code>bnb</code> æˆ– <code>8bit</code> æ¨¡å‹ç¯€çœè¨˜æ†¶é«”ï¼ˆbitsandbytesï¼‰</li><li>ğŸš€ ä½¿ç”¨ <code>accelerate</code> é€²è¡Œå¤šå¡åˆ†æ•£è¨“ç·´</li><li>ğŸ“‹ å°è³‡æ–™é›†å¯ç”¨ <code>gradient checkpointing</code> é™ä½é¡¯å­˜æ¶ˆè€—</li><li>ğŸ§ª æ¸¬è©¦ prompt ä¸€è‡´æ€§ã€å›ç­”é•·åº¦èˆ‡æ ¼å¼æº–ç¢ºåº¦</li></ul><hr><h2 id=-å»¶ä¼¸è³‡æºæ¨è–¦>ğŸ“˜ å»¶ä¼¸è³‡æºæ¨è–¦</h2><ul><li><a href=https://huggingface.co/docs/peft/index>Hugging Face PEFT å®˜æ–¹æ–‡ä»¶</a></li><li><a href=https://arxiv.org/abs/2106.09685>LoRA åŸå§‹è«–æ–‡</a></li><li><a href=https://github.com/huggingface/transformers/tree/main/examples>LLaMAã€GPT2 ç­‰å¾®èª¿å¯¦ä¾‹</a></li></ul><hr><h2 id=-çµèª>âœ… çµèª</h2><p>å¾®èª¿å¤§å‹èªè¨€æ¨¡å‹å·²ç¶“ä¸å†æ˜¯åªæœ‰å¤§å…¬å¸èƒ½åšçš„äº‹ã€‚é€é LoRA èˆ‡ PEFTï¼Œä½ å¯ä»¥ç”¨å–®å¼µ GPUã€ç”šè‡³ Colab å°±å¾®èª¿å‡ºé©åˆè‡ªå·±çš„ä»»å‹™æ¨¡å‹ã€‚å¸Œæœ›é€™ç¯‡æ–‡ç« èƒ½è®“ä½ è·¨å‡ºç¬¬ä¸€æ­¥ï¼Œåœ¨ LLM çš„ä¸–ç•Œä¸­æ‰“é€ å±¬æ–¼è‡ªå·±çš„æ™ºæ…§ç³»çµ±ã€‚</p></div><div class=article-tags><div class=tags><span class=tag>Fine-Tune</span>
<span class=tag>PEFT</span>
<span class=tag>LoRA</span>
<span class=tag>Hugging Face</span>
<span class=tag>Transformers</span></div></div><footer class=article-footer><a href=/portfolio/zh/articles/others/large-language-model/ class=back-link>â† è¿”å› å¤§å‹èªè¨€æ¨¡å‹</a></footer></article></main><footer class=site-footer><p>&copy; 2026 YuHan Jhou. All rights reserved.</p></footer></div></div><script src=https://yu-codes.github.io/portfolio/js/theme.js defer></script><script src=https://yu-codes.github.io/portfolio/js/roadmap.js defer></script><script src=https://yu-codes.github.io/portfolio/js/parallax.js defer></script><script src=https://yu-codes.github.io/portfolio/js/page-transition.js defer></script></body></html>