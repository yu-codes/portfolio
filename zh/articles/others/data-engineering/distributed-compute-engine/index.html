<!doctype html><html lang=zh class=html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>分散式計算引擎全攻略：Spark、Flink、Beam、Shuffle、Skew 與調優實戰 - Yu's Portfolio & Learning Hub</title><meta name=description content='分散式計算引擎是大數據處理的核心。從 Spark Core/SQL/Structured Streaming，到 Flink、Beam 的流批一體，再到 Shuffle、Broadcast、Skew 等調優技巧，這些技術決定了資料處理的效率、可擴展性與穩定性。本章將深入原理、架構圖解、實戰調優、面試熱點與常見誤區，幫助你打造高效能數據平台。
Spark Core / SQL / Structured Streaming Spark Core RDD（彈性分散式資料集）為基礎，支援 Map/Reduce、分區、容錯 適合複雜轉換、低階控制 Spark SQL DataFrame/Dataset API，支援 SQL 查詢、優化器（Catalyst） 適合 ETL、資料探索、BI 報表 Structured Streaming 以 DataFrame 為基礎的流式處理，支援 Exactly-once、Window 聚合 支援與 Kafka、Kinesis、文件系統整合 from pyspark.sql import SparkSession spark = SparkSession.builder.appName("demo").getOrCreate() df = spark.read.parquet("data.parquet") df.groupBy("col").count().show() Flink vs. Beam：Event Time & Watermark Flink 原生流批一體，支援 Event Time、Window、狀態管理 Watermark 機制處理亂序資料，保證準確性 適合低延遲、複雜流式分析 Beam 統一批次/流式 API，支援多執行引擎（Flink、Spark、Dataflow） 強調可攜性與跨平台 引擎 流批一體 Event Time Watermark 適用場景 Spark 部分 支援 有限 ETL、批次分析 Flink 原生 強 強 實時流式、複雜事件 Beam 統一 API 強 強 跨平台、雲端 Shuffle、Broadcast、Skew 調優 Shuffle 分散式運算中資料重分區，常見於 groupBy、join Shuffle 過多會導致磁碟 I/O、網路壅塞 Broadcast 小表廣播到所有節點，避免大表 shuffle 適合小型維度表 join Skew（資料傾斜） 單一分區資料量過大，導致部分節點瓶頸 解法：Salting、動態分區、Skew Join # Spark Broadcast Join small_df = spark.read.parquet("dim.parquet") large_df = spark.read.parquet("fact.parquet") from pyspark.sql.functions import broadcast result = large_df.join(broadcast(small_df), "key") 實戰調優與資源管理 合理設置分區數（partition），避免過多/過少 調整 shuffle buffer、executor memory、core 數 監控 DAG、Stage、Task 執行情況，定位瓶頸 使用 Spark UI/Flink Dashboard 進行資源與任務監控 理論直覺、應用場景與常見誤區 應用場景 ETL、批次分析、即時流式處理、複雜事件監控、資料湖建設 常見誤區 Shuffle 過多導致效能瓶頸 Broadcast Join 濫用導致記憶體爆炸 Skew 未處理導致部分節點拖慢全局 分區數設置不當，資源利用率低 面試熱點與經典問題 主題 常見問題 Spark vs Flink 架構與適用場景？ Structured Streaming Exactly-once 如何實現？ Shuffle 原理與效能影響？ Broadcast 何時用？有何風險？ Skew 如何偵測與解決？ 使用注意事項 分區、Shuffle、Broadcast 需根據資料量與節點資源調整 流式處理需設計 Watermark 與容錯機制 調優建議結合監控工具與實驗 延伸閱讀與資源 Apache Spark 官方文件 Apache Flink 官方文件 Apache Beam 官方文件 Spark 調優指南 Flink 調優指南 經典面試題與解法提示 Spark/Flink/Beam 架構與適用場景？ Structured Streaming 如何實現 Exactly-once？ Shuffle 原理與效能瓶頸？ Broadcast Join 何時適用？風險？ Skew 偵測與解決方法？ 分區數如何設置？ Spark/Flink 資源管理與調優技巧？ Shuffle/Broadcast/Skew 如何聯合調優？ Spark UI/Flink Dashboard 如何定位瓶頸？ 如何用 Python 實作 Broadcast Join？ 結語 分散式計算引擎是大數據處理的核心。熟悉 Spark、Flink、Beam、Shuffle、Broadcast、Skew 與調優技巧，能讓你打造高效能、可擴展的數據平台。下一章將進入 Pandas 與新世代加速工具，敬請期待！
'><meta property="og:title" content="分散式計算引擎全攻略：Spark、Flink、Beam、Shuffle、Skew 與調優實戰"><meta property="og:description" content='分散式計算引擎是大數據處理的核心。從 Spark Core/SQL/Structured Streaming，到 Flink、Beam 的流批一體，再到 Shuffle、Broadcast、Skew 等調優技巧，這些技術決定了資料處理的效率、可擴展性與穩定性。本章將深入原理、架構圖解、實戰調優、面試熱點與常見誤區，幫助你打造高效能數據平台。
Spark Core / SQL / Structured Streaming Spark Core RDD（彈性分散式資料集）為基礎，支援 Map/Reduce、分區、容錯 適合複雜轉換、低階控制 Spark SQL DataFrame/Dataset API，支援 SQL 查詢、優化器（Catalyst） 適合 ETL、資料探索、BI 報表 Structured Streaming 以 DataFrame 為基礎的流式處理，支援 Exactly-once、Window 聚合 支援與 Kafka、Kinesis、文件系統整合 from pyspark.sql import SparkSession spark = SparkSession.builder.appName("demo").getOrCreate() df = spark.read.parquet("data.parquet") df.groupBy("col").count().show() Flink vs. Beam：Event Time & Watermark Flink 原生流批一體，支援 Event Time、Window、狀態管理 Watermark 機制處理亂序資料，保證準確性 適合低延遲、複雜流式分析 Beam 統一批次/流式 API，支援多執行引擎（Flink、Spark、Dataflow） 強調可攜性與跨平台 引擎 流批一體 Event Time Watermark 適用場景 Spark 部分 支援 有限 ETL、批次分析 Flink 原生 強 強 實時流式、複雜事件 Beam 統一 API 強 強 跨平台、雲端 Shuffle、Broadcast、Skew 調優 Shuffle 分散式運算中資料重分區，常見於 groupBy、join Shuffle 過多會導致磁碟 I/O、網路壅塞 Broadcast 小表廣播到所有節點，避免大表 shuffle 適合小型維度表 join Skew（資料傾斜） 單一分區資料量過大，導致部分節點瓶頸 解法：Salting、動態分區、Skew Join # Spark Broadcast Join small_df = spark.read.parquet("dim.parquet") large_df = spark.read.parquet("fact.parquet") from pyspark.sql.functions import broadcast result = large_df.join(broadcast(small_df), "key") 實戰調優與資源管理 合理設置分區數（partition），避免過多/過少 調整 shuffle buffer、executor memory、core 數 監控 DAG、Stage、Task 執行情況，定位瓶頸 使用 Spark UI/Flink Dashboard 進行資源與任務監控 理論直覺、應用場景與常見誤區 應用場景 ETL、批次分析、即時流式處理、複雜事件監控、資料湖建設 常見誤區 Shuffle 過多導致效能瓶頸 Broadcast Join 濫用導致記憶體爆炸 Skew 未處理導致部分節點拖慢全局 分區數設置不當，資源利用率低 面試熱點與經典問題 主題 常見問題 Spark vs Flink 架構與適用場景？ Structured Streaming Exactly-once 如何實現？ Shuffle 原理與效能影響？ Broadcast 何時用？有何風險？ Skew 如何偵測與解決？ 使用注意事項 分區、Shuffle、Broadcast 需根據資料量與節點資源調整 流式處理需設計 Watermark 與容錯機制 調優建議結合監控工具與實驗 延伸閱讀與資源 Apache Spark 官方文件 Apache Flink 官方文件 Apache Beam 官方文件 Spark 調優指南 Flink 調優指南 經典面試題與解法提示 Spark/Flink/Beam 架構與適用場景？ Structured Streaming 如何實現 Exactly-once？ Shuffle 原理與效能瓶頸？ Broadcast Join 何時適用？風險？ Skew 偵測與解決方法？ 分區數如何設置？ Spark/Flink 資源管理與調優技巧？ Shuffle/Broadcast/Skew 如何聯合調優？ Spark UI/Flink Dashboard 如何定位瓶頸？ 如何用 Python 實作 Broadcast Join？ 結語 分散式計算引擎是大數據處理的核心。熟悉 Spark、Flink、Beam、Shuffle、Broadcast、Skew 與調優技巧，能讓你打造高效能、可擴展的數據平台。下一章將進入 Pandas 與新世代加速工具，敬請期待！
'><meta property="og:url" content="https://yu-codes.github.io/portfolio/zh/articles/others/data-engineering/distributed-compute-engine/"><link rel=canonical href=https://yu-codes.github.io/portfolio/zh/articles/others/data-engineering/distributed-compute-engine/><link rel=stylesheet href=https://yu-codes.github.io/portfolio/css/main.css></head><body class=body><div class=container><aside class=sidebar><div class=sidebar-header><h1 class=name>Yu</h1><p class=tagline>Developer, dreamer, debugger.</p></div><nav class=sidebar-nav><a href=https://yu-codes.github.io/portfolio/zh/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M3 9l9-7 9 7v11a2 2 0 01-2 2H5a2 2 0 01-2-2z"/><polyline points="9 22 9 12 15 12 15 22"/></svg>
<span>首頁</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/articles/ class="nav-item active"><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5.0 016.5 17H20"/><path d="M6.5 2H20v20H6.5A2.5 2.5.0 014 19.5v-15A2.5 2.5.0 016.5 2z"/></svg>
<span>文章</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/resume/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="12" y1="11" x2="12" y2="17"/><line x1="9" y1="14" x2="15" y2="14"/></svg>
<span>履歷</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/projects/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="3" width="8" height="8"/><rect x="13" y="3" width="8" height="8"/><rect x="3" y="13" width="8" height="8"/><rect x="13" y="13" width="8" height="8"/></svg>
<span>專案</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/archives/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
<span>歸檔</span></a></nav><div class=sidebar-footer><div class=controls><button class="control-btn theme-toggle" title=切換主題（淺色/深色） aria-label="Toggle theme">
<svg class="icon-sun" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".25"/></svg>
<svg class="icon-moon" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".25"/></svg>
</button>
<button class="control-btn lang-toggle" title=切換語言 aria-label="Toggle language">
<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"/><path d="M2 12h20"/><path d="M12 2a15.3 15.3.0 014 10 15.3 15.3.0 01-4 10A15.3 15.3.0 018 12a15.3 15.3.0 014-10z"/></svg></button></div><div class=social-links><a href=https://github.com/yu-codes target=_blank rel="noopener noreferrer" class=social-link title=GitHub><svg viewBox="0 0 24 24" fill="currentColor"><path d="M12 0C5.374.0.0 5.373.0 12c0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931.0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176.0.0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221.0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/></svg>
</a><a href=mailto:dylan.jhou1120@gmail.com class=social-link title=Email><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div></div></aside><div class=main-content><div class=topbar><div class=breadcrumb><a href=https://yu-codes.github.io/portfolio/zh/>首頁</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/>文章</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/others/>其他</a><span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/others/data-engineering/>資料工程</a><span class=separator>&#8250;</span>
<span>分散式計算引擎全攻略：Spark、Flink、Beam、Shuffle、Skew 與調優實戰</span></div></div><main class=content-area><article class=article-content><header class=article-header><h1>分散式計算引擎全攻略：Spark、Flink、Beam、Shuffle、Skew 與調優實戰</h1><div class=article-meta><span class=article-author><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20 21v-2a4 4 0 00-4-4H8a4 4 0 00-4 4v2"/><circle cx="12" cy="7" r="4"/></svg>
Yu-Han Jhou
</span><span class=article-updated><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>
最後更新: 2025-01-05</span></div></header><div class=article-body><p>分散式計算引擎是大數據處理的核心。從 Spark Core/SQL/Structured Streaming，到 Flink、Beam 的流批一體，再到 Shuffle、Broadcast、Skew 等調優技巧，這些技術決定了資料處理的效率、可擴展性與穩定性。本章將深入原理、架構圖解、實戰調優、面試熱點與常見誤區，幫助你打造高效能數據平台。</p><hr><nav class=article-toc><span class=toc-title>目錄</span><nav id=TableOfContents><ul><li><a href=#spark-core--sql--structured-streaming>Spark Core / SQL / Structured Streaming</a><ul><li><a href=#spark-core>Spark Core</a></li><li><a href=#spark-sql>Spark SQL</a></li><li><a href=#structured-streaming>Structured Streaming</a></li></ul></li><li><a href=#flink-vs-beamevent-time--watermark>Flink vs. Beam：Event Time & Watermark</a><ul><li><a href=#flink>Flink</a></li><li><a href=#beam>Beam</a></li></ul></li><li><a href=#shufflebroadcastskew-調優>Shuffle、Broadcast、Skew 調優</a><ul><li><a href=#shuffle>Shuffle</a></li><li><a href=#broadcast>Broadcast</a></li><li><a href=#skew資料傾斜>Skew（資料傾斜）</a></li></ul></li><li><a href=#實戰調優與資源管理>實戰調優與資源管理</a></li><li><a href=#理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</a><ul><li><a href=#應用場景>應用場景</a></li><li><a href=#常見誤區>常見誤區</a></li></ul></li><li><a href=#面試熱點與經典問題>面試熱點與經典問題</a></li><li><a href=#使用注意事項>使用注意事項</a></li><li><a href=#延伸閱讀與資源>延伸閱讀與資源</a></li><li><a href=#經典面試題與解法提示>經典面試題與解法提示</a></li><li><a href=#結語>結語</a></li></ul></nav></nav><h2 id=spark-core--sql--structured-streaming>Spark Core / SQL / Structured Streaming</h2><h3 id=spark-core>Spark Core</h3><ul><li>RDD（彈性分散式資料集）為基礎，支援 Map/Reduce、分區、容錯</li><li>適合複雜轉換、低階控制</li></ul><h3 id=spark-sql>Spark SQL</h3><ul><li>DataFrame/Dataset API，支援 SQL 查詢、優化器（Catalyst）</li><li>適合 ETL、資料探索、BI 報表</li></ul><h3 id=structured-streaming>Structured Streaming</h3><ul><li>以 DataFrame 為基礎的流式處理，支援 Exactly-once、Window 聚合</li><li>支援與 Kafka、Kinesis、文件系統整合</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.sql <span style=color:#f92672>import</span> SparkSession
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>spark <span style=color:#f92672>=</span> SparkSession<span style=color:#f92672>.</span>builder<span style=color:#f92672>.</span>appName(<span style=color:#e6db74>&#34;demo&#34;</span>)<span style=color:#f92672>.</span>getOrCreate()
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>read<span style=color:#f92672>.</span>parquet(<span style=color:#e6db74>&#34;data.parquet&#34;</span>)
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>groupBy(<span style=color:#e6db74>&#34;col&#34;</span>)<span style=color:#f92672>.</span>count()<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><hr><h2 id=flink-vs-beamevent-time--watermark>Flink vs. Beam：Event Time & Watermark</h2><h3 id=flink>Flink</h3><ul><li>原生流批一體，支援 Event Time、Window、狀態管理</li><li>Watermark 機制處理亂序資料，保證準確性</li><li>適合低延遲、複雜流式分析</li></ul><h3 id=beam>Beam</h3><ul><li>統一批次/流式 API，支援多執行引擎（Flink、Spark、Dataflow）</li><li>強調可攜性與跨平台</li></ul><table><thead><tr><th>引擎</th><th>流批一體</th><th>Event Time</th><th>Watermark</th><th>適用場景</th></tr></thead><tbody><tr><td>Spark</td><td>部分</td><td>支援</td><td>有限</td><td>ETL、批次分析</td></tr><tr><td>Flink</td><td>原生</td><td>強</td><td>強</td><td>實時流式、複雜事件</td></tr><tr><td>Beam</td><td>統一 API</td><td>強</td><td>強</td><td>跨平台、雲端</td></tr></tbody></table><hr><h2 id=shufflebroadcastskew-調優>Shuffle、Broadcast、Skew 調優</h2><h3 id=shuffle>Shuffle</h3><ul><li>分散式運算中資料重分區，常見於 groupBy、join</li><li>Shuffle 過多會導致磁碟 I/O、網路壅塞</li></ul><h3 id=broadcast>Broadcast</h3><ul><li>小表廣播到所有節點，避免大表 shuffle</li><li>適合小型維度表 join</li></ul><h3 id=skew資料傾斜>Skew（資料傾斜）</h3><ul><li>單一分區資料量過大，導致部分節點瓶頸</li><li>解法：Salting、動態分區、Skew Join</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Spark Broadcast Join</span>
</span></span><span style=display:flex><span>small_df <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>read<span style=color:#f92672>.</span>parquet(<span style=color:#e6db74>&#34;dim.parquet&#34;</span>)
</span></span><span style=display:flex><span>large_df <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>read<span style=color:#f92672>.</span>parquet(<span style=color:#e6db74>&#34;fact.parquet&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.sql.functions <span style=color:#f92672>import</span> broadcast
</span></span><span style=display:flex><span>result <span style=color:#f92672>=</span> large_df<span style=color:#f92672>.</span>join(broadcast(small_df), <span style=color:#e6db74>&#34;key&#34;</span>)
</span></span></code></pre></div><hr><h2 id=實戰調優與資源管理>實戰調優與資源管理</h2><ul><li>合理設置分區數（partition），避免過多/過少</li><li>調整 shuffle buffer、executor memory、core 數</li><li>監控 DAG、Stage、Task 執行情況，定位瓶頸</li><li>使用 Spark UI/Flink Dashboard 進行資源與任務監控</li></ul><hr><h2 id=理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</h2><h3 id=應用場景>應用場景</h3><ul><li>ETL、批次分析、即時流式處理、複雜事件監控、資料湖建設</li></ul><h3 id=常見誤區>常見誤區</h3><ul><li>Shuffle 過多導致效能瓶頸</li><li>Broadcast Join 濫用導致記憶體爆炸</li><li>Skew 未處理導致部分節點拖慢全局</li><li>分區數設置不當，資源利用率低</li></ul><hr><h2 id=面試熱點與經典問題>面試熱點與經典問題</h2><table><thead><tr><th>主題</th><th>常見問題</th></tr></thead><tbody><tr><td>Spark vs Flink</td><td>架構與適用場景？</td></tr><tr><td>Structured Streaming</td><td>Exactly-once 如何實現？</td></tr><tr><td>Shuffle</td><td>原理與效能影響？</td></tr><tr><td>Broadcast</td><td>何時用？有何風險？</td></tr><tr><td>Skew</td><td>如何偵測與解決？</td></tr></tbody></table><hr><h2 id=使用注意事項>使用注意事項</h2><ul><li>分區、Shuffle、Broadcast 需根據資料量與節點資源調整</li><li>流式處理需設計 Watermark 與容錯機制</li><li>調優建議結合監控工具與實驗</li></ul><hr><h2 id=延伸閱讀與資源>延伸閱讀與資源</h2><ul><li><a href=https://spark.apache.org/docs/latest/>Apache Spark 官方文件</a></li><li><a href=https://nightlies.apache.org/flink/flink-docs-release-1.17/>Apache Flink 官方文件</a></li><li><a href=https://beam.apache.org/documentation/>Apache Beam 官方文件</a></li><li><a href=https://spark.apache.org/docs/latest/tuning.html>Spark 調優指南</a></li><li><a href=https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/ops/tuning/>Flink 調優指南</a></li></ul><hr><h2 id=經典面試題與解法提示>經典面試題與解法提示</h2><ol><li>Spark/Flink/Beam 架構與適用場景？</li><li>Structured Streaming 如何實現 Exactly-once？</li><li>Shuffle 原理與效能瓶頸？</li><li>Broadcast Join 何時適用？風險？</li><li>Skew 偵測與解決方法？</li><li>分區數如何設置？</li><li>Spark/Flink 資源管理與調優技巧？</li><li>Shuffle/Broadcast/Skew 如何聯合調優？</li><li>Spark UI/Flink Dashboard 如何定位瓶頸？</li><li>如何用 Python 實作 Broadcast Join？</li></ol><hr><h2 id=結語>結語</h2><p>分散式計算引擎是大數據處理的核心。熟悉 Spark、Flink、Beam、Shuffle、Broadcast、Skew 與調優技巧，能讓你打造高效能、可擴展的數據平台。下一章將進入 Pandas 與新世代加速工具，敬請期待！</p></div><div class=article-tags><div class=tags><span class=tag>Spark</span>
<span class=tag>Flink</span>
<span class=tag>Beam</span>
<span class=tag>Structured Streaming</span>
<span class=tag>Shuffle</span>
<span class=tag>Broadcast</span>
<span class=tag>Skew</span></div></div><footer class=article-footer><a href=/portfolio/zh/articles/others/data-engineering/ class=back-link>← 返回 資料工程</a></footer></article></main><footer class=site-footer><p>&copy; 2026 YuHan Jhou. All rights reserved.</p></footer></div></div><script src=https://yu-codes.github.io/portfolio/js/theme.js defer></script><script src=https://yu-codes.github.io/portfolio/js/roadmap.js defer></script><script src=https://yu-codes.github.io/portfolio/js/parallax.js defer></script><script src=https://yu-codes.github.io/portfolio/js/page-transition.js defer></script></body></html>