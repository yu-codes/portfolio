<!doctype html><html lang=zh class=html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>資料採集與 Ingestion 全攻略：API、Webhook、CDC、Kafka、Schema 設計與實戰 - Yu's Portfolio & Learning Hub</title><meta name=description content="資料採集與 Ingestion 是數據工程的第一哩路，直接影響資料質量、延遲與下游處理效率。本章將深入 API/Webhook/CDC/File Drop 等資料來源，Kafka/Kinesis/PubSub 的 Partition Key 設計，Schema on Read/Write 策略，並結合實戰案例、圖解、面試熱點與常見誤區，幫助你打造高效穩健的資料流入管線。
API / Webhook / CDC / File Drop API 主動拉取資料，適合定時同步、第三方服務整合 支援 REST、GraphQL、gRPC 等協議 需考慮認證、速率限制、錯誤重試 可用 ETL 工具（如 Airbyte、Fivetran）自動化 API 抽取 支援分頁、增量同步、異常監控與自動補償 常見場景：金融報價、社群資料、第三方 SaaS 整合 Webhook 被動接收資料，事件驅動，適合即時通知 常用於支付、訂單、IoT 事件 需設計重試、簽名驗證、去重機制 可結合 Serverless（如 AWS Lambda）自動處理 支援事件溯源、重放、異常告警 常見場景：金流通知、物流狀態、即時警報 Change Data Capture（CDC） 監控資料庫變更（如 binlog），實時同步到下游 工具：Debezium、AWS DMS、Oracle GoldenGate 適合資料庫遷移、實時 ETL、資料湖同步 支援全量+增量同步，需監控延遲與資料一致性 需處理 schema 變更、主鍵衝突、補償機制 常見場景：多活資料同步、即時報表、資料湖建設 File Drop 透過 SFTP、雲端儲存（S3/GCS）上傳檔案 適合批次資料、外部供應商交換 需設計檔案命名規則、到檔通知、重複檢查 可結合 Lambda/SNS 實現自動觸發 支援檔案驗證（checksum）、自動歸檔、異常補償 常見場景：金融對帳、批次資料交換、外部資料導入 Kafka／Kinesis／Pub/Sub 設計 Partition Key Partition Key 設計原則 決定資料分佈與消費順序，影響負載均衡與吞吐量 常見設計：用戶 ID、訂單號、地區等 熱點分佈（如熱門用戶）需避免單分區過載 可用 hash、range、複合 key 動態分配 動態調整分區數，需考慮資料重分佈與消費者重平衡 監控分區延遲、消費速率，及時調整策略 Kafka 實戰 Producer 發送訊息時指定 key，確保同 key 資料進同一分區 消費者可根據分區並行處理，提升吞吐 支援多 topic、跨資料中心同步、Exactly-once 語意 需設計死信佇列（DLQ）、重試與補償機制 from kafka import KafkaProducer producer = KafkaProducer(bootstrap_servers='localhost:9092') producer.send('orders', key=b'user_123', value=b'order_data') Kinesis / PubSub Kinesis：Partition Key 決定 Shard，需考慮熱點與分片數 支援自動擴容、分片合併，需監控 Shard 利用率 Pub/Sub：支援 Ordering Key，確保同 key 有序消費 支援 Dead Letter Topic、重試與監控 Schema on Read vs. Write Schema on Write 資料寫入時即驗證格式，保證資料一致性 適合強結構化需求（如資料倉庫、金融交易） 支援 schema registry、版本控管、資料驗證 需設計 schema 變更流程與相容性檢查 Schema on Read 資料寫入時不驗證格式，讀取時再解析 適合半結構化/多樣性資料（如資料湖、IoT） 支援多格式共存、彈性探索、資料湖治理 需設計讀取時 schema 驗證、異常補償 策略 優點 缺點 適用場景 Schema on Write 資料一致性高，易治理 彈性低，需預先定義 倉庫、金融、報表 Schema on Read 彈性高，支援多格式 讀取時易出錯，治理難 資料湖、IoT、探索 實戰案例：多源資料流入設計 結合 API 拉取、Webhook 事件、CDC 實時同步、File Drop 批次補數 Kafka 作為統一訊息匯流排，設計合理 Partition Key 與多 topic 下游 ETL 根據資料型態選擇 Schema on Read/Write 策略 監控資料延遲、丟失、重複，設計告警、補償與死信佇列 實作資料 lineage、資料驗證、異常自動補救 理論直覺、應用場景與常見誤區 應用場景 金融交易、IoT 資料流、電商訂單、第三方 API 整合、資料湖建設、跨國多活同步 常見誤區 Partition Key 設計不當導致分區傾斜、消費瓶頸 Webhook 未設計重試與去重，資料丟失或重複 CDC 未監控延遲與資料一致性，schema 變更未驗證 File Drop 檔案命名/驗證不嚴謹，導致資料遺失 Schema on Read 濫用，導致資料治理困難與查詢失敗 面試熱點與經典問題 主題 常見問題 API vs Webhook 適用場景與設計差異？ CDC 如何確保資料一致性？ Partition Key 如何避免分區熱點？ Schema 策略 何時選用 Read/Write？ Kafka 如何設計高吞吐資料流？ 使用注意事項 資料流入需設計監控、告警與補償流程 Partition Key 需根據資料分佈動態調整 延伸閱讀與資源 Kafka 官方文件 Debezium CDC 教學 Schema on Read vs Write AWS Kinesis Best Practices 經典面試題與解法提示 API、Webhook、CDC、File Drop 各自適用場景？ Kafka Partition Key 如何設計避免熱點？ Schema on Read/Write 差異與選型？ Webhook 如何設計去重與重試？ CDC 如何確保資料一致性與低延遲？ 多源資料流入如何統一治理？ Partition Key 動態調整策略？ Kafka 消費者如何實現高吞吐？ Schema on Read 濫用會有什麼風險？ 如何設計資料流入的監控與補償？ 結語 資料採集與 Ingestion 是數據工程的基石。熟悉多種資料來源、Partition Key 設計與 Schema 策略，能讓你打造高效穩健的資料流入管線。下一章將進入 ETL vs. ELT Pipeline，敬請期待！
"><meta property="og:title" content="資料採集與 Ingestion 全攻略：API、Webhook、CDC、Kafka、Schema 設計與實戰"><meta property="og:description" content="資料採集與 Ingestion 是數據工程的第一哩路，直接影響資料質量、延遲與下游處理效率。本章將深入 API/Webhook/CDC/File Drop 等資料來源，Kafka/Kinesis/PubSub 的 Partition Key 設計，Schema on Read/Write 策略，並結合實戰案例、圖解、面試熱點與常見誤區，幫助你打造高效穩健的資料流入管線。
API / Webhook / CDC / File Drop API 主動拉取資料，適合定時同步、第三方服務整合 支援 REST、GraphQL、gRPC 等協議 需考慮認證、速率限制、錯誤重試 可用 ETL 工具（如 Airbyte、Fivetran）自動化 API 抽取 支援分頁、增量同步、異常監控與自動補償 常見場景：金融報價、社群資料、第三方 SaaS 整合 Webhook 被動接收資料，事件驅動，適合即時通知 常用於支付、訂單、IoT 事件 需設計重試、簽名驗證、去重機制 可結合 Serverless（如 AWS Lambda）自動處理 支援事件溯源、重放、異常告警 常見場景：金流通知、物流狀態、即時警報 Change Data Capture（CDC） 監控資料庫變更（如 binlog），實時同步到下游 工具：Debezium、AWS DMS、Oracle GoldenGate 適合資料庫遷移、實時 ETL、資料湖同步 支援全量+增量同步，需監控延遲與資料一致性 需處理 schema 變更、主鍵衝突、補償機制 常見場景：多活資料同步、即時報表、資料湖建設 File Drop 透過 SFTP、雲端儲存（S3/GCS）上傳檔案 適合批次資料、外部供應商交換 需設計檔案命名規則、到檔通知、重複檢查 可結合 Lambda/SNS 實現自動觸發 支援檔案驗證（checksum）、自動歸檔、異常補償 常見場景：金融對帳、批次資料交換、外部資料導入 Kafka／Kinesis／Pub/Sub 設計 Partition Key Partition Key 設計原則 決定資料分佈與消費順序，影響負載均衡與吞吐量 常見設計：用戶 ID、訂單號、地區等 熱點分佈（如熱門用戶）需避免單分區過載 可用 hash、range、複合 key 動態分配 動態調整分區數，需考慮資料重分佈與消費者重平衡 監控分區延遲、消費速率，及時調整策略 Kafka 實戰 Producer 發送訊息時指定 key，確保同 key 資料進同一分區 消費者可根據分區並行處理，提升吞吐 支援多 topic、跨資料中心同步、Exactly-once 語意 需設計死信佇列（DLQ）、重試與補償機制 from kafka import KafkaProducer producer = KafkaProducer(bootstrap_servers='localhost:9092') producer.send('orders', key=b'user_123', value=b'order_data') Kinesis / PubSub Kinesis：Partition Key 決定 Shard，需考慮熱點與分片數 支援自動擴容、分片合併，需監控 Shard 利用率 Pub/Sub：支援 Ordering Key，確保同 key 有序消費 支援 Dead Letter Topic、重試與監控 Schema on Read vs. Write Schema on Write 資料寫入時即驗證格式，保證資料一致性 適合強結構化需求（如資料倉庫、金融交易） 支援 schema registry、版本控管、資料驗證 需設計 schema 變更流程與相容性檢查 Schema on Read 資料寫入時不驗證格式，讀取時再解析 適合半結構化/多樣性資料（如資料湖、IoT） 支援多格式共存、彈性探索、資料湖治理 需設計讀取時 schema 驗證、異常補償 策略 優點 缺點 適用場景 Schema on Write 資料一致性高，易治理 彈性低，需預先定義 倉庫、金融、報表 Schema on Read 彈性高，支援多格式 讀取時易出錯，治理難 資料湖、IoT、探索 實戰案例：多源資料流入設計 結合 API 拉取、Webhook 事件、CDC 實時同步、File Drop 批次補數 Kafka 作為統一訊息匯流排，設計合理 Partition Key 與多 topic 下游 ETL 根據資料型態選擇 Schema on Read/Write 策略 監控資料延遲、丟失、重複，設計告警、補償與死信佇列 實作資料 lineage、資料驗證、異常自動補救 理論直覺、應用場景與常見誤區 應用場景 金融交易、IoT 資料流、電商訂單、第三方 API 整合、資料湖建設、跨國多活同步 常見誤區 Partition Key 設計不當導致分區傾斜、消費瓶頸 Webhook 未設計重試與去重，資料丟失或重複 CDC 未監控延遲與資料一致性，schema 變更未驗證 File Drop 檔案命名/驗證不嚴謹，導致資料遺失 Schema on Read 濫用，導致資料治理困難與查詢失敗 面試熱點與經典問題 主題 常見問題 API vs Webhook 適用場景與設計差異？ CDC 如何確保資料一致性？ Partition Key 如何避免分區熱點？ Schema 策略 何時選用 Read/Write？ Kafka 如何設計高吞吐資料流？ 使用注意事項 資料流入需設計監控、告警與補償流程 Partition Key 需根據資料分佈動態調整 延伸閱讀與資源 Kafka 官方文件 Debezium CDC 教學 Schema on Read vs Write AWS Kinesis Best Practices 經典面試題與解法提示 API、Webhook、CDC、File Drop 各自適用場景？ Kafka Partition Key 如何設計避免熱點？ Schema on Read/Write 差異與選型？ Webhook 如何設計去重與重試？ CDC 如何確保資料一致性與低延遲？ 多源資料流入如何統一治理？ Partition Key 動態調整策略？ Kafka 消費者如何實現高吞吐？ Schema on Read 濫用會有什麼風險？ 如何設計資料流入的監控與補償？ 結語 資料採集與 Ingestion 是數據工程的基石。熟悉多種資料來源、Partition Key 設計與 Schema 策略，能讓你打造高效穩健的資料流入管線。下一章將進入 ETL vs. ELT Pipeline，敬請期待！
"><meta property="og:url" content="https://yu-codes.github.io/portfolio/zh/articles/others/data-engineering/data-ingestion/"><link rel=canonical href=https://yu-codes.github.io/portfolio/zh/articles/others/data-engineering/data-ingestion/><link rel=stylesheet href=https://yu-codes.github.io/portfolio/css/main.css></head><body class=body><div class=container><aside class=sidebar><div class=sidebar-header><h1 class=name>Yu</h1><p class=tagline>Developer, dreamer, debugger.</p></div><nav class=sidebar-nav><a href=https://yu-codes.github.io/portfolio/zh/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M3 9l9-7 9 7v11a2 2 0 01-2 2H5a2 2 0 01-2-2z"/><polyline points="9 22 9 12 15 12 15 22"/></svg>
<span>首頁</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/articles/ class="nav-item active"><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5.0 016.5 17H20"/><path d="M6.5 2H20v20H6.5A2.5 2.5.0 014 19.5v-15A2.5 2.5.0 016.5 2z"/></svg>
<span>文章</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/resume/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="12" y1="11" x2="12" y2="17"/><line x1="9" y1="14" x2="15" y2="14"/></svg>
<span>履歷</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/projects/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="3" width="8" height="8"/><rect x="13" y="3" width="8" height="8"/><rect x="3" y="13" width="8" height="8"/><rect x="13" y="13" width="8" height="8"/></svg>
<span>專案</span>
</a><a href=https://yu-codes.github.io/portfolio/zh/archives/ class=nav-item><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
<span>歸檔</span></a></nav><div class=sidebar-footer><div class=controls><button class="control-btn theme-toggle" title=切換主題（淺色/深色） aria-label="Toggle theme">
<svg class="icon-sun" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".25"/></svg>
<svg class="icon-moon" viewBox="0 0 24 24" fill="none"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="1.5" fill="none"/><path d="M12 3a9 9 0 000 18" fill="currentColor" opacity=".9"/><path d="M12 3a9 9 0 010 18" fill="currentColor" opacity=".25"/></svg>
</button>
<button class="control-btn lang-toggle" title=切換語言 aria-label="Toggle language">
<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"/><path d="M2 12h20"/><path d="M12 2a15.3 15.3.0 014 10 15.3 15.3.0 01-4 10A15.3 15.3.0 018 12a15.3 15.3.0 014-10z"/></svg></button></div><div class=social-links><a href=https://github.com/yu-codes target=_blank rel="noopener noreferrer" class=social-link title=GitHub><svg viewBox="0 0 24 24" fill="currentColor"><path d="M12 0C5.374.0.0 5.373.0 12c0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931.0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176.0.0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221.0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/></svg>
</a><a href=mailto:dylan.jhou1120@gmail.com class=social-link title=Email><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div></div></aside><div class=main-content><div class=topbar><div class=breadcrumb><a href=https://yu-codes.github.io/portfolio/zh/>首頁</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/>文章</a>
<span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/others/>其他</a><span class=separator>&#8250;</span>
<a href=https://yu-codes.github.io/portfolio/zh/articles/others/data-engineering/>資料工程</a><span class=separator>&#8250;</span>
<span>資料採集與 Ingestion 全攻略：API、Webhook、CDC、Kafka、Schema 設計與實戰</span></div></div><main class=content-area><article class=article-content><header class=article-header><h1>資料採集與 Ingestion 全攻略：API、Webhook、CDC、Kafka、Schema 設計與實戰</h1><div class=article-meta><span class=article-author><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20 21v-2a4 4 0 00-4-4H8a4 4 0 00-4 4v2"/><circle cx="12" cy="7" r="4"/></svg>
Yu-Han Jhou
</span><span class=article-updated><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>
最後更新: 2025-10-07</span></div></header><div class=article-body><p>資料採集與 Ingestion 是數據工程的第一哩路，直接影響資料質量、延遲與下游處理效率。本章將深入 API/Webhook/CDC/File Drop 等資料來源，Kafka/Kinesis/PubSub 的 Partition Key 設計，Schema on Read/Write 策略，並結合實戰案例、圖解、面試熱點與常見誤區，幫助你打造高效穩健的資料流入管線。</p><hr><nav class=article-toc><span class=toc-title>目錄</span><nav id=TableOfContents><ul><li><a href=#api--webhook--cdc--file-drop>API / Webhook / CDC / File Drop</a><ul><li><a href=#api>API</a></li><li><a href=#webhook>Webhook</a></li><li><a href=#change-data-capturecdc>Change Data Capture（CDC）</a></li><li><a href=#file-drop>File Drop</a></li></ul></li><li><a href=#kafkakinesispubsub-設計-partition-key>Kafka／Kinesis／Pub/Sub 設計 Partition Key</a><ul><li><a href=#partition-key-設計原則>Partition Key 設計原則</a></li><li><a href=#kafka-實戰>Kafka 實戰</a></li><li><a href=#kinesis--pubsub>Kinesis / PubSub</a></li></ul></li><li><a href=#schema-on-read-vs-write>Schema on Read vs. Write</a><ul><li><a href=#schema-on-write>Schema on Write</a></li><li><a href=#schema-on-read>Schema on Read</a></li></ul></li><li><a href=#實戰案例多源資料流入設計>實戰案例：多源資料流入設計</a></li><li><a href=#理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</a><ul><li><a href=#應用場景>應用場景</a></li><li><a href=#常見誤區>常見誤區</a></li></ul></li><li><a href=#面試熱點與經典問題>面試熱點與經典問題</a></li><li><a href=#使用注意事項>使用注意事項</a></li><li><a href=#延伸閱讀與資源>延伸閱讀與資源</a></li><li><a href=#經典面試題與解法提示>經典面試題與解法提示</a></li><li><a href=#結語>結語</a></li></ul></nav></nav><h2 id=api--webhook--cdc--file-drop>API / Webhook / CDC / File Drop</h2><h3 id=api>API</h3><ul><li>主動拉取資料，適合定時同步、第三方服務整合</li><li>支援 REST、GraphQL、gRPC 等協議</li><li>需考慮認證、速率限制、錯誤重試</li><li>可用 ETL 工具（如 Airbyte、Fivetran）自動化 API 抽取</li><li>支援分頁、增量同步、異常監控與自動補償</li><li>常見場景：金融報價、社群資料、第三方 SaaS 整合</li></ul><h3 id=webhook>Webhook</h3><ul><li>被動接收資料，事件驅動，適合即時通知</li><li>常用於支付、訂單、IoT 事件</li><li>需設計重試、簽名驗證、去重機制</li><li>可結合 Serverless（如 AWS Lambda）自動處理</li><li>支援事件溯源、重放、異常告警</li><li>常見場景：金流通知、物流狀態、即時警報</li></ul><h3 id=change-data-capturecdc>Change Data Capture（CDC）</h3><ul><li>監控資料庫變更（如 binlog），實時同步到下游</li><li>工具：Debezium、AWS DMS、Oracle GoldenGate</li><li>適合資料庫遷移、實時 ETL、資料湖同步</li><li>支援全量+增量同步，需監控延遲與資料一致性</li><li>需處理 schema 變更、主鍵衝突、補償機制</li><li>常見場景：多活資料同步、即時報表、資料湖建設</li></ul><h3 id=file-drop>File Drop</h3><ul><li>透過 SFTP、雲端儲存（S3/GCS）上傳檔案</li><li>適合批次資料、外部供應商交換</li><li>需設計檔案命名規則、到檔通知、重複檢查</li><li>可結合 Lambda/SNS 實現自動觸發</li><li>支援檔案驗證（checksum）、自動歸檔、異常補償</li><li>常見場景：金融對帳、批次資料交換、外部資料導入</li></ul><hr><h2 id=kafkakinesispubsub-設計-partition-key>Kafka／Kinesis／Pub/Sub 設計 Partition Key</h2><h3 id=partition-key-設計原則>Partition Key 設計原則</h3><ul><li>決定資料分佈與消費順序，影響負載均衡與吞吐量</li><li>常見設計：用戶 ID、訂單號、地區等</li><li>熱點分佈（如熱門用戶）需避免單分區過載</li><li>可用 hash、range、複合 key 動態分配</li><li>動態調整分區數，需考慮資料重分佈與消費者重平衡</li><li>監控分區延遲、消費速率，及時調整策略</li></ul><h3 id=kafka-實戰>Kafka 實戰</h3><ul><li>Producer 發送訊息時指定 key，確保同 key 資料進同一分區</li><li>消費者可根據分區並行處理，提升吞吐</li><li>支援多 topic、跨資料中心同步、Exactly-once 語意</li><li>需設計死信佇列（DLQ）、重試與補償機制</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> kafka <span style=color:#f92672>import</span> KafkaProducer
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>producer <span style=color:#f92672>=</span> KafkaProducer(bootstrap_servers<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;localhost:9092&#39;</span>)
</span></span><span style=display:flex><span>producer<span style=color:#f92672>.</span>send(<span style=color:#e6db74>&#39;orders&#39;</span>, key<span style=color:#f92672>=</span><span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;user_123&#39;</span>, value<span style=color:#f92672>=</span><span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;order_data&#39;</span>)
</span></span></code></pre></div><h3 id=kinesis--pubsub>Kinesis / PubSub</h3><ul><li>Kinesis：Partition Key 決定 Shard，需考慮熱點與分片數</li><li>支援自動擴容、分片合併，需監控 Shard 利用率</li><li>Pub/Sub：支援 Ordering Key，確保同 key 有序消費</li><li>支援 Dead Letter Topic、重試與監控</li></ul><hr><h2 id=schema-on-read-vs-write>Schema on Read vs. Write</h2><h3 id=schema-on-write>Schema on Write</h3><ul><li>資料寫入時即驗證格式，保證資料一致性</li><li>適合強結構化需求（如資料倉庫、金融交易）</li><li>支援 schema registry、版本控管、資料驗證</li><li>需設計 schema 變更流程與相容性檢查</li></ul><h3 id=schema-on-read>Schema on Read</h3><ul><li>資料寫入時不驗證格式，讀取時再解析</li><li>適合半結構化/多樣性資料（如資料湖、IoT）</li><li>支援多格式共存、彈性探索、資料湖治理</li><li>需設計讀取時 schema 驗證、異常補償</li></ul><table><thead><tr><th>策略</th><th>優點</th><th>缺點</th><th>適用場景</th></tr></thead><tbody><tr><td>Schema on Write</td><td>資料一致性高，易治理</td><td>彈性低，需預先定義</td><td>倉庫、金融、報表</td></tr><tr><td>Schema on Read</td><td>彈性高，支援多格式</td><td>讀取時易出錯，治理難</td><td>資料湖、IoT、探索</td></tr></tbody></table><hr><h2 id=實戰案例多源資料流入設計>實戰案例：多源資料流入設計</h2><ul><li>結合 API 拉取、Webhook 事件、CDC 實時同步、File Drop 批次補數</li><li>Kafka 作為統一訊息匯流排，設計合理 Partition Key 與多 topic</li><li>下游 ETL 根據資料型態選擇 Schema on Read/Write 策略</li><li>監控資料延遲、丟失、重複，設計告警、補償與死信佇列</li><li>實作資料 lineage、資料驗證、異常自動補救</li></ul><hr><h2 id=理論直覺應用場景與常見誤區>理論直覺、應用場景與常見誤區</h2><h3 id=應用場景>應用場景</h3><ul><li>金融交易、IoT 資料流、電商訂單、第三方 API 整合、資料湖建設、跨國多活同步</li></ul><h3 id=常見誤區>常見誤區</h3><ul><li>Partition Key 設計不當導致分區傾斜、消費瓶頸</li><li>Webhook 未設計重試與去重，資料丟失或重複</li><li>CDC 未監控延遲與資料一致性，schema 變更未驗證</li><li>File Drop 檔案命名/驗證不嚴謹，導致資料遺失</li><li>Schema on Read 濫用，導致資料治理困難與查詢失敗</li></ul><hr><h2 id=面試熱點與經典問題>面試熱點與經典問題</h2><table><thead><tr><th>主題</th><th>常見問題</th></tr></thead><tbody><tr><td>API vs Webhook</td><td>適用場景與設計差異？</td></tr><tr><td>CDC</td><td>如何確保資料一致性？</td></tr><tr><td>Partition Key</td><td>如何避免分區熱點？</td></tr><tr><td>Schema 策略</td><td>何時選用 Read/Write？</td></tr><tr><td>Kafka</td><td>如何設計高吞吐資料流？</td></tr></tbody></table><hr><h2 id=使用注意事項>使用注意事項</h2><ul><li>資料流入需設計監控、告警與補償流程</li><li>Partition Key 需根據資料分佈動態調整</li></ul><h2 id=延伸閱讀與資源>延伸閱讀與資源</h2><ul><li><a href=https://kafka.apache.org/documentation/>Kafka 官方文件</a></li><li><a href=https://debezium.io/documentation/>Debezium CDC 教學</a></li><li><a href=https://www.confluent.io/blog/schema-on-read-vs-schema-on-write/>Schema on Read vs Write</a></li><li><a href=https://docs.aws.amazon.com/streams/latest/dev/best-practices.html>AWS Kinesis Best Practices</a></li></ul><hr><h2 id=經典面試題與解法提示>經典面試題與解法提示</h2><ol><li>API、Webhook、CDC、File Drop 各自適用場景？</li><li>Kafka Partition Key 如何設計避免熱點？</li><li>Schema on Read/Write 差異與選型？</li><li>Webhook 如何設計去重與重試？</li><li>CDC 如何確保資料一致性與低延遲？</li><li>多源資料流入如何統一治理？</li><li>Partition Key 動態調整策略？</li><li>Kafka 消費者如何實現高吞吐？</li><li>Schema on Read 濫用會有什麼風險？</li><li>如何設計資料流入的監控與補償？</li></ol><hr><h2 id=結語>結語</h2><p>資料採集與 Ingestion 是數據工程的基石。熟悉多種資料來源、Partition Key 設計與 Schema 策略，能讓你打造高效穩健的資料流入管線。下一章將進入 ETL vs. ELT Pipeline，敬請期待！</p></div><div class=article-tags><div class=tags><span class=tag>Data Ingestion</span>
<span class=tag>API</span>
<span class=tag>Webhook</span>
<span class=tag>CDC</span>
<span class=tag>Kafka</span>
<span class=tag>Kinesis</span>
<span class=tag>PubSub</span>
<span class=tag>Partition Key</span>
<span class=tag>Schema on Read</span>
<span class=tag>Schema on Write</span></div></div><footer class=article-footer><a href=/portfolio/zh/articles/others/data-engineering/ class=back-link>← 返回 資料工程</a></footer></article></main><footer class=site-footer><p>&copy; 2026 YuHan Jhou. All rights reserved.</p></footer></div></div><script src=https://yu-codes.github.io/portfolio/js/theme.js defer></script><script src=https://yu-codes.github.io/portfolio/js/roadmap.js defer></script><script src=https://yu-codes.github.io/portfolio/js/parallax.js defer></script><script src=https://yu-codes.github.io/portfolio/js/page-transition.js defer></script></body></html>